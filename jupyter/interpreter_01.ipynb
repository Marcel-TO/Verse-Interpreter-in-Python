{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verse Interpreter development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essential installs:\n",
    "- `pip3 install .....`\n",
    "\n",
    "\n",
    "This version is used to test the first steps for the verse interpreter. The final version will be used as a full python file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR-TYPE ENUMERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ErrorType(Enum):\n",
    "    SyntaxError = 'Wrong Syntax at'\n",
    "    SemanticError = 'Wrong Semantics at'\n",
    "    UnkownError = 'Operation Failure'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGGER CLASSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self):{}\n",
    "        \n",
    "    def __log__(self, string:str):{}\n",
    "\n",
    "    def __log_error__(self,string:str, type:ErrorType):{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Console_Logger(Logger):\n",
    "\n",
    "    def __log__(self, string:str):\n",
    "        print(string)\n",
    "\n",
    "    def __log_error__(self,string:str, type:ErrorType):       \n",
    "        print(\"ERROR| \" + type.value + \": \" + string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import string\n",
    "\n",
    "# class syntax\n",
    "\n",
    "class TokenTypes(Enum):\n",
    "    # Data\n",
    "    INTEGER = int\n",
    "    IDENTIFIER = string #Names/Variables\n",
    "    INT_TYPE = \"int\"\n",
    "    TUPLE_TYPE = \"tuple\"\n",
    "    ARRAY_TYPE = \"array\"\n",
    "    # Aritmetics\n",
    "    PLUS = \"+\"\n",
    "    MINUS = \"-\"\n",
    "    MULTIPLY = \"*\"\n",
    "    DIVIDE = \"/\"\n",
    "    GREATER = \">\"\n",
    "    GREATEREQ = \">=\"\n",
    "    LOWER = \"<\"\n",
    "    LOWEREQ = \"<=\"\n",
    "    CHOICE = \"|\"\n",
    "    # Mehtods\n",
    "    FOR = \"for\"\n",
    "    IF = \"if\"\n",
    "    THEN = \"then\"\n",
    "    ELSE = \"else\"\n",
    "    LBRACKET = \"(\"\n",
    "    RBRACKET = \")\"\n",
    "    # Else\n",
    "    EOF = None\n",
    "    COLON = \":\"\n",
    "    COMMA=\",\"\n",
    "    SemiColon =\";\"\n",
    "    BINDING =\":=\"\n",
    "    SLB = \"[\"\n",
    "    SRB = \"]\"\n",
    "    CLB = \"{\"\n",
    "    CRB = \"}\"\n",
    "    EQUAL = \"=\"\n",
    "    SCOPE = \":\"\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['halloo wie geht', 'ws', 'efaf', ' aefe ', ' eeerwre']\n"
     ]
    }
   ],
   "source": [
    "class FileReader:\n",
    "    def __init__(self):{}\n",
    "\n",
    "    \n",
    "    def get_Lines(self, name:str):\n",
    "       \n",
    "        try:\n",
    "            f = open('..\\modules\\{}'.format(name),'r')\n",
    "            lines = f.read().split(\"\\n\")\n",
    "            return (lines,True)\n",
    "        except:\n",
    "            return ([],False)\n",
    "        \n",
    "       \n",
    "\n",
    "   \n",
    "reader = FileReader()\n",
    "segments,read_success = reader.get_Lines('example.txt')\n",
    "print(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "     def __init__(self, type: TokenTypes,value):\n",
    "        self.value = value\n",
    "        self.type = type\n",
    "\n",
    "     def __info__(self):\n",
    "         return \"{}:{}\".format(self.type, self.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lexicon:\n",
    "    def __init__(self, input: string):\n",
    "        self.input = input\n",
    "        self.index = 0\n",
    "        self.current_char = self.input[self.index]\n",
    "    \n",
    "    # moves the pointer a character forward\n",
    "    def forward(self) -> None:\n",
    "        self.index += 1\n",
    "\n",
    "        # checks if index is out of range\n",
    "        if (self.index >= len(self.input)):\n",
    "            self.current_char = None\n",
    "            return\n",
    "        \n",
    "        self.current_char = self.input[self.index]\n",
    "    \n",
    "    def backward(self) -> None:\n",
    "        self.index -= 1\n",
    "\n",
    "        # checks if index is out of range\n",
    "        if self.index < 0:\n",
    "            self.current_char = None\n",
    "            return\n",
    "        \n",
    "        self.current_char = self.input[self.index]\n",
    "    \n",
    "    def get_int(self) -> int:\n",
    "        if self.index >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.input[self.index]\n",
    "\n",
    "        # checks if there are multiple digits\n",
    "        while True:\n",
    "            self.forward()\n",
    "\n",
    "            if self.index < len(self.input) and self.input[self.index] != None and self.input[self.index].isnumeric():\n",
    "                result += self.input[self.index]\n",
    "            else:\n",
    "                self.backward()\n",
    "                break\n",
    "\n",
    "        return int(result)\n",
    "    \n",
    "    def get_var(self) -> string:\n",
    "        if self.index >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.input[self.index]\n",
    "\n",
    "        # checks if there is a longer variable name\n",
    "        while True:\n",
    "            self.forward()\n",
    "\n",
    "            if self.index < len(self.input) and self.input[self.index] != None and self.input[self.index].isalpha():\n",
    "                result += self.input[self.index]\n",
    "            else:\n",
    "                self.backward()\n",
    "                break\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_token(self, char: string) -> Token:\n",
    "        token = self.check_for_tokentypes(char)\n",
    "\n",
    "        if token.type != TokenTypes.EOF:\n",
    "            return token\n",
    "        \n",
    "        if char == None:\n",
    "            return token\n",
    "            \n",
    "        # skip spaces.\n",
    "        if char == ' ':\n",
    "            self.forward()\n",
    "            return self.get_token(self.current_char)\n",
    "\n",
    "        # checks if the current character is a number.\n",
    "        if char.isnumeric():\n",
    "            result = self.get_int()\n",
    "            return Token(TokenTypes.INTEGER, result)\n",
    "        \n",
    "        if char.isalpha():\n",
    "            result = self.get_var()\n",
    "            token = self.check_for_tokentypes(result)\n",
    "                  \n",
    "        return token\n",
    "\n",
    "    def check_for_tokentypes(self, char: string) -> Token:\n",
    "         # checks if the current character is a supported token type.\n",
    "        match char:\n",
    "            case TokenTypes.DIVIDE.value:\n",
    "                return Token(TokenTypes.DIVIDE, TokenTypes.DIVIDE.value)\n",
    "            case TokenTypes.MULTIPLY.value:\n",
    "                return Token(TokenTypes.MULTIPLY, TokenTypes.MULTIPLY.value)\n",
    "            case TokenTypes.PLUS.value:\n",
    "                return Token(TokenTypes.PLUS, TokenTypes.PLUS.value)\n",
    "            case TokenTypes.MINUS.value:\n",
    "                return Token(TokenTypes.MINUS, TokenTypes.MINUS.value)\n",
    "            case TokenTypes.LBRACKET.value:\n",
    "                return Token(TokenTypes.LBRACKET, TokenTypes.LBRACKET.value)\n",
    "            case TokenTypes.RBRACKET.value:\n",
    "                return Token(TokenTypes.RBRACKET, TokenTypes.RBRACKET.value)\n",
    "            case TokenTypes.EQUAL.value:\n",
    "                return Token(TokenTypes.EQUAL, TokenTypes.EQUAL.value)\n",
    "            case TokenTypes.GREATER.value:\n",
    "                return Token(TokenTypes.GREATER, TokenTypes.GREATER.value)\n",
    "            case TokenTypes.LOWER.value:\n",
    "                return Token(TokenTypes.LOWER, TokenTypes.LOWER.value)\n",
    "            case TokenTypes.FOR.value:\n",
    "                return Token(TokenTypes.FOR, TokenTypes.FOR.value) \n",
    "            case _:\n",
    "                return Token(TokenTypes.EOF, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( is of the tokentype: TokenTypes.LBRACKET\n",
      "for is of the tokentype: TokenTypes.FOR\n",
      "123 is of the tokentype: TokenTypes.INTEGER\n",
      "> is of the tokentype: TokenTypes.GREATER\n",
      "= is of the tokentype: TokenTypes.EQUAL\n",
      "5 is of the tokentype: TokenTypes.INTEGER\n",
      "* is of the tokentype: TokenTypes.MULTIPLY\n",
      "23 is of the tokentype: TokenTypes.INTEGER\n",
      ") is of the tokentype: TokenTypes.RBRACKET\n"
     ]
    }
   ],
   "source": [
    "lexer = lexicon(\"(for 123 >= 5 * 23)\")\n",
    "\n",
    "while lexer.current_char is not None:\n",
    "    token = lexer.get_token(lexer.current_char)\n",
    "    print(str(token.value) + \" is of the tokentype: \" + str(token.type))\n",
    "    lexer.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNode:\n",
    "    def __init__(self, token) -> None:\n",
    "        self.token = token\n",
    "    \n",
    "    def visit(self, node):\n",
    "        if isinstance(node, OperatorNode):\n",
    "            return self.visit_operatorNode(node)\n",
    "        \n",
    "        if isinstance(node, UnaryNode):\n",
    "            return self.visit_unaryNode(node)\n",
    "        \n",
    "        return self.visit_numberNode(node)\n",
    "    \n",
    "\n",
    "    def visit_unaryNode(self, node):\n",
    "        match node.token.type:\n",
    "            case TokenTypes.MINUS:\n",
    "                return -1 * self.visit(node.node)\n",
    "            case TokenTypes.PLUS:\n",
    "                return 1 * self.visit(node.node)\n",
    "            \n",
    "\n",
    "        \n",
    "    def visit_operatorNode(self, node):\n",
    "        match node.token.type:\n",
    "            case TokenTypes.DIVIDE:\n",
    "                return self.visit(node.leftNode) // self.visit(node.rightNode)\n",
    "            case TokenTypes.MULTIPLY:\n",
    "                return self.visit(node.leftNode) * self.visit(node.rightNode)\n",
    "            case TokenTypes.PLUS:\n",
    "                return self.visit(node.leftNode) + self.visit(node.rightNode)\n",
    "            case TokenTypes.MINUS:\n",
    "                return self.visit(node.leftNode) - self.visit(node.rightNode)   \n",
    "            case TokenTypes.EQUAL:\n",
    "                if(self.visit(node.leftNode) == self.visit(node.rightNode)):\n",
    "                    return self.visit(node.leftNode)\n",
    "                return \"\"\n",
    "            case TokenTypes.GREATER:\n",
    "                if(self.visit(node.leftNode) > self.visit(node.rightNode)):\n",
    "                    return self.visit(node.leftNode)\n",
    "                return \"\"\n",
    "            case TokenTypes.LOWER:\n",
    "                 if(self.visit(node.leftNode) < self.visit(node.rightNode)):\n",
    "                    return self.visit(node.leftNode)\n",
    "                 return \"\"   \n",
    "\n",
    "    def visit_numberNode(self, node):\n",
    "        return node.value\n",
    "\n",
    "\n",
    "class BlockNode(BaseNode):\n",
    "    def __init__(self, node:list[BaseNode]) -> None:\n",
    "        self.node = node\n",
    "\n",
    "class Program(BaseNode):\n",
    "    def __init__(self, node:list[BlockNode]) -> None:\n",
    "        self.node = node\n",
    "\n",
    "\n",
    "class ScopeNode(BaseNode):\n",
    "    def __init__(self,token:Token, nodes:list[BaseNode]) -> None:\n",
    "        super().__init__(token)\n",
    "        self.nodes = nodes\n",
    "\n",
    "class NumberNode(BaseNode):\n",
    "    def __init__(self, token:Token) -> None:\n",
    "        super().__init__(token)\n",
    "        self.value = token.value\n",
    "\n",
    "class OperatorNode(BaseNode):\n",
    "    def __init__(self, token:Token, leftNode: BaseNode, rightNode: BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.leftNode = leftNode\n",
    "        self.rightNode = rightNode\n",
    "\n",
    "class UnaryNode(BaseNode):\n",
    "     def __init__(self, token:Token, node) -> None:\n",
    "        super().__init__(token)\n",
    "        self.node = node\n",
    "\n",
    "class ScopeNode(BaseNode):\n",
    "    def __init__(self, token:Token, nodes:list[BaseNode], type) -> None: #Change into Variable/IdentifierNode\n",
    "        super().__init__(token)\n",
    "        self.nodes = nodes\n",
    "        self.type = type\n",
    "\n",
    "class TypeNode(BaseNode):\n",
    "    def __init__(self, token:Token, type) -> None: \n",
    "        super().__init__(token)\n",
    "        self.type = type\n",
    "\n",
    "class TypeNodeSequence(TypeNode):\n",
    "    def __init__(self, token:Token, nodes:list[TypeNode], type) -> None: \n",
    "        super().__init__(token)\n",
    "        self.nodes = nodes\n",
    "        self.type = type\n",
    "\n",
    "\n",
    "class ArgumentsNode(): #Doesnt need BaseNode since it doesn't have token\n",
    "    def __init__(self, nodes:list[BaseNode]) -> None: \n",
    "        self.nodes = nodes\n",
    "\n",
    "class FuncCallNode():\n",
    "    def __init__(self,identifier:BaseNode, args:ArgumentsNode) -> None: #instead of BaseNode maybe IdentifierNode\n",
    "        self.args = args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class that takes a parsed node, containes information if node could have been parsed\n",
    "class ParsedNode:\n",
    "    def __init__(self, node:BaseNode, hasSyntaxError:bool ):\n",
    "        self.node = node\n",
    "        self.hasSyntaxError = hasSyntaxError\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, lexer: lexicon):\n",
    "       self.logger: Logger = Console_Logger()\n",
    "       self.end = False\n",
    "       self.lexer = lexer\n",
    "       self.current_token = lexer.get_token(self.lexer.current_char)\n",
    "       \n",
    "\n",
    "    def parse(self) -> ParsedNode:     \n",
    "        node = self.program().node\n",
    "        return node\n",
    "       \n",
    "  \n",
    "\n",
    "    def program(self) -> ParsedNode:\n",
    "        return self.expr()\n",
    "\n",
    "    def block(self) -> ParsedNode:\n",
    "        pass\n",
    "\n",
    "    def statement_list(self):\n",
    "        pass\n",
    "\n",
    "    def statement(self):\n",
    "        pass\n",
    "\n",
    "    def func_call(self) -> ParsedNode:\n",
    "        # RULE --> IDENTIFIER LB (func_call_param)? RB  NOT IMPLEMENTED\n",
    "        node = self.Identifier()\n",
    "\n",
    "        if(self.current_token.type == TokenTypes.LBRACKET):\n",
    "            self.forward()\n",
    "            if(self.current_token.type != TokenTypes.RBRACKET):\n",
    "                args = self.func_call_args()\n",
    "                if(args.hasSyntaxError == False and self.current_token.type == TokenTypes.RBRACKET):\n",
    "                    pass # return Func_call Node with Args\n",
    "                return ParsedNode(None,True)\n",
    "            else: pass # Return FunktionNode with empty Args\n",
    "        return node\n",
    "        \n",
    "    \n",
    "    def func_call_args(self):\n",
    "        # expr (COMMA expr)*?  \n",
    "        nodes:list[BaseNode] = [] # Args Instead Base Node maybe ArgsNode\n",
    "\n",
    "        arg_1 = self.expr() # 1. Arg\n",
    "\n",
    "        if(arg_1.hasSyntaxError == False):\n",
    "                nodes.append(arg_1)\n",
    "                \n",
    "                # The while method \"concatenates\" the operations\n",
    "\n",
    "                while(self.check_type(self.current_token.type,[TokenTypes.COMMA])):           \n",
    "                   \n",
    "                    self.forward()\n",
    "                    arg = self.expr() #\n",
    "\n",
    "                    if(arg.hasSyntaxError):\n",
    "                        return arg\n",
    "                    \n",
    "                    nodes.append(arg)\n",
    "\n",
    "                pass # Return list of node args, we could maybe have an ArgumentsNode?\n",
    "                    # Binds found operation to its left node\n",
    "                          \n",
    "        return ParsedNode(None, True)\n",
    "\n",
    "    def func_decl(self) -> ParsedNode:\n",
    "        # IDENTIFIER LB func_dec_param RB (COLON type)? BINDING block\n",
    "          # |IDENTIFIER BINDING LB nested_scope LAMBDA expr RB     UPDATE\n",
    "          # \n",
    "        identifier = self.Identifier()\n",
    "\n",
    "        if(self.current_token.type == TokenTypes.LBRACKET):\n",
    "            params = self.func_dec_param()\n",
    "            if(params.hasSyntaxError == False and self.current_token.type == TokenTypes.RBRACKET):\n",
    "                self.forward()\n",
    "                if(self.current_token.type == TokenTypes.COLON):\n",
    "                    token = self.current_token\n",
    "                    type = self.type()\n",
    "                    if(type.hasSyntaxError):\n",
    "                        return ParsedNode(None, True)\n",
    "                        \n",
    "                    if(self.current_token.type == TokenTypes.BINDING):\n",
    "                        self.forward() \n",
    "                        block = self.block()\n",
    "                        if(block.hasSyntaxError):\n",
    "                            return ParsedNode(None, True)\n",
    "            pass      \n",
    "        pass \n",
    "\n",
    "    def func_dec_param(self) -> ParsedNode:\n",
    "\n",
    "        pass\n",
    "\n",
    "    def if_statement(self) -> ParsedNode:\n",
    "        # RULE --> IF LB expr RB ((THEN block ELSE block) | (THEN CBL expr CBR ELSE CBL expr CBR))\n",
    "             \n",
    "        if(self.current_token.type == TokenTypes.IF):\n",
    "            token = self.current_token\n",
    "            self.forward()\n",
    "\n",
    "            if(self.current_token.type == TokenTypes.LBRACKET):\n",
    "                condition = self.expr() # Gets condition part of if statement\n",
    "\n",
    "                if(condition.hasSyntaxError == False and self.current_token.type == TokenTypes.RBRACKET):\n",
    "                    self.forward()\n",
    "\n",
    "                    # Check then block\n",
    "                    if(self.current_token.type == TokenTypes.THEN):\n",
    "                        self.forward()\n",
    "\n",
    "                        then_slb = False\n",
    "\n",
    "                        # If, then block uses curvy brackets\n",
    "                        if(self.current_token.type == TokenTypes.CLB):\n",
    "                            then_clb = True\n",
    "\n",
    "                        then_block = self.block()\n",
    "\n",
    "                        if(then_clb and self.current_token.type != TokenTypes.CRB):\n",
    "                            return ParsedNode(None,True)\n",
    "                        else: self.forward()\n",
    "\n",
    "                        else_clb = False\n",
    "\n",
    "                        # If, else block uses curvy brackets, then block needs to use curvy brackets as well\n",
    "                        if(then_clb and self.current_token.type == TokenTypes.CLB):\n",
    "                            else_clb = True\n",
    "                        else: return ParsedNode(None,True)\n",
    "                        \n",
    "                        else_block = self.block()\n",
    "\n",
    "                        if(else_clb and self.current_token.type != TokenTypes.CRB):\n",
    "                            return ParsedNode(None,True)\n",
    "                        else: self.forward()\n",
    "\n",
    "                    pass # Return IfNod (condition, then_block, else_block)\n",
    "\n",
    "        return ParsedNode(None, True)\n",
    "\n",
    "    def for_loop(self) -> ParsedNode:\n",
    "        pass\n",
    "\n",
    "    def nested_scope(self) -> ParsedNode:\n",
    "        # RULE --> IDENTIFIER (,IDENTIFIER)*? COLON TYPE\n",
    "        node = self.Identifier()\n",
    "        \n",
    "        if(node.hasSyntaxError == False):\n",
    "            identifiers:list[BaseNode] = []\n",
    "            identifiers.append(node)\n",
    "\n",
    "            # Checks if next (current) token is comma and saves it in comman_next (Used for later in method)\n",
    "            comma_next = self.check_type(self.current_token.type,[TokenTypes.COMMA])\n",
    "\n",
    "            # Iterates while-loop and tries to get all identifiers seperated by a comma\n",
    "            while(self.check_type(self.current_token.type,[TokenTypes.COMMA])):\n",
    "                self.forward()\n",
    "                node = self.Identifier()\n",
    "                if(node.hasSyntaxError):\n",
    "                    return ParsedNode(None, True)\n",
    "                \n",
    "                identifiers.append(node) # Stores identifier in a Node list\n",
    "\n",
    "            # Checks if the next token is a colon and then tries to get the type of the scope\n",
    "            if(self.check_type(self.current_token.type,[TokenTypes.COLON])): \n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "\n",
    "                # Tries to get the type of the scope\n",
    "                type = self.type()\n",
    "\n",
    "                # If type couldn't be retrieved --> error\n",
    "                if(type.hasSyntaxError):\n",
    "                    return ParsedNode(None,True)\n",
    "                pass # Return NestedScopeNode or ScopeNode\n",
    "            \n",
    "            # Here we check if it went into the comma while-loop to indicate if it tried to get a nested scope\n",
    "            # if it didnt go into the while-loop or didnt do the if-statement for colon (scope), then it surely \n",
    "            # couldn't have been a scope, so return the node recevied by the first node = self.Identifier()\n",
    "            if(comma_next == False):\n",
    "                return node \n",
    "        \n",
    "        return ParsedNode(None, True)\n",
    "\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "    def expr(self) -> ParsedNode:         \n",
    "        return self.operation()\n",
    "    \n",
    "    \"\"\"\n",
    "    This method checks if a token any of the following operations: =, <, >, <=, >=, |, +, -\n",
    "    Since all of this operations have the same priority and same values output, it is not needed to write them in different methods\n",
    "    \"\"\"\n",
    "    def operation(self):\n",
    "        # RULE --> op: term ((GT|LT|GE|LE|EQUAL|CHOICE|PLUS|MINUS) term)*\n",
    "\n",
    "        left_node = self.term()\n",
    "\n",
    "        # Checks if left node has been received and if the following token is one of the following tokens: : =, <, >, <=, >=, |, +, -\n",
    "\n",
    "        if(left_node.hasSyntaxError == False and (self.check_type(self.current_token.type,\n",
    "                [TokenTypes.GREATER,TokenTypes.GREATEREQ,TokenTypes.LOWER,TokenTypes.LOWEREQ, TokenTypes.CHOICE, TokenTypes.PLUS,\n",
    "                TokenTypes.MINUS, TokenTypes.EQUAL]))):\n",
    "\n",
    "                node = ParsedNode(None,True)\n",
    "                \n",
    "                # The while method \"concatenates\" the operations\n",
    "\n",
    "                while(self.check_type(self.current_token.type,\n",
    "                [TokenTypes.GREATER,TokenTypes.GREATEREQ,TokenTypes.LOWER,TokenTypes.LOWEREQ, TokenTypes.CHOICE, TokenTypes.PLUS,\n",
    "                TokenTypes.MINUS, TokenTypes.EQUAL])):\n",
    "                \n",
    "                    token = self.current_token\n",
    "                    self.forward()\n",
    "                    right_node = self.term()\n",
    "                    if(right_node.hasSyntaxError):\n",
    "                        return right_node\n",
    "                    \n",
    "                    # Binds found operation to its left node\n",
    "                    if(node.node == None):\n",
    "                       node = ParsedNode(OperatorNode(token,left_node.node,right_node.node),False)\n",
    "                    else: node = ParsedNode(OperatorNode(token,node.node,right_node.node),False)\n",
    "                return node\n",
    "        return left_node\n",
    "\n",
    "    \"\"\"\n",
    "    Checks the same way in operation method but here it checks for *, /\n",
    "    \"\"\"\n",
    "    def term(self) -> ParsedNode:\n",
    "        # RULE --> factor ((MUL|DIV) factor)*\n",
    "        \n",
    "        left_node = self.factor() \n",
    "\n",
    "        if(left_node.hasSyntaxError == False and (self.check_type(self.current_token.type,[TokenTypes.MULTIPLY, TokenTypes.DIVIDE]))):\n",
    "            node = ParsedNode(None,True)\n",
    "\n",
    "             # The while method \"concatenates\" the operations\n",
    "            while(self.check_type(self.current_token.type,[TokenTypes.MULTIPLY, TokenTypes.DIVIDE])):\n",
    "               \n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "                right_node = self.factor()\n",
    "                if(right_node.hasSyntaxError):\n",
    "                    return right_node\n",
    "                \n",
    "                # Binds found operation to its left node\n",
    "                if(node.node == None):\n",
    "                  node = ParsedNode(OperatorNode(token,left_node.node,right_node.node),False)\n",
    "                else: node = ParsedNode(OperatorNode(token,node.node,right_node.node),False)\n",
    "            return node\n",
    "        return left_node\n",
    "    \n",
    "    \"\"\"\n",
    "    Checks for unary operations, Integers, brackets (highest priority)\n",
    "    \"\"\"\n",
    "    def factor(self) -> ParsedNode:\n",
    "      \n",
    "      # RULE -->  INTEGER  \n",
    "       # : brackets\n",
    "       # : (MINUS|PLUS) arith\n",
    "       # : func_call x() x\n",
    "       # : indexing     NOT IMPLEMENTING\n",
    "       # : --> means the same as (brackets|unary|func_call) just like in operation()\n",
    "       # only that for each if a different Node may be created not such as only OperationNode like in operation()\n",
    "       \n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "\n",
    "      \n",
    "        #Integer check\n",
    "        if(token.type == TokenTypes.INTEGER):\n",
    "            self.forward()\n",
    "            return ParsedNode(NumberNode(token),False)\n",
    "        \n",
    "        #Unary operation check\n",
    "        if(self.check_type(self.current_token.type,[TokenTypes.PLUS, TokenTypes.MINUS])):\n",
    "            self.forward()\n",
    "            node = self.operation()\n",
    "            if(node.hasSyntaxError):        # (--) --> Error needs (-- expr) or (--3)\n",
    "                return ParsedNode(None, True)\n",
    "            return ParsedNode(UnaryNode(token,node.node),False)\n",
    "        \n",
    "        #Brackets check\n",
    "        return self.brackets() #Returns invalid Node on invalid Syntax\n",
    "    \n",
    "    \"\"\"\n",
    "    Checks for brackets (highest priority)\n",
    "    \"\"\"\n",
    "    def brackets(self) -> ParsedNode:\n",
    "        # RULE --> brackets: LB expr RB \n",
    "        if(self.current_token.type == TokenTypes.LBRACKET):\n",
    "            self.forward()\n",
    "            node = self.expr()\n",
    "        \n",
    "            if(self.current_token.type == TokenTypes.RBRACKET):\n",
    "                self.forward()\n",
    "                return node\n",
    "        return ParsedNode(None,True)\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    METHODS FROM HERE NEEDS TO BE FULLY IMPLEMENTED AND CHECKED (except forward, check_type, set_to_token)!\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    y := 8 y:=(x:int)  y:= method(...)...\n",
    "    \"\"\"\n",
    "    def binding(self) -> ParsedNode:\n",
    "          # RULE --> scope BINDING expr     NEED UPDATE\n",
    "        left_node = self.scope()\n",
    "\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.check_type(self.current_token.type,[TokenTypes.BINDING])):\n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "                right_node = self.expr()\n",
    "                if(right_node.hasSyntaxError == False):\n",
    "                    pass # Return Node\n",
    "                else: ParsedNode(None,True)\n",
    "        return left_node\n",
    "\n",
    "    \"\"\"\n",
    "    x:int\n",
    "    \"\"\"\n",
    "    def scope(self) -> ParsedNode:\n",
    "      # RULE --> Identifier COLON type    NEED UPDATE\n",
    "\n",
    "        left_node = self.Identifier()\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.check_type(self.current_token.type,[TokenTypes.COLON])):\n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "                type = self.type()\n",
    "                if(type.hasSyntaxError == False):\n",
    "                    pass # Return Scope Node\n",
    "                else: ParsedNode(None,True)\n",
    "        return left_node\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    variable/method name\n",
    "    \"\"\"\n",
    "    def Identifier(self) -> ParsedNode:\n",
    "        #RULE --> identifier            NEED UPDATE\n",
    "\n",
    "        token = self.current_token\n",
    "\n",
    "        if(token.type == TokenTypes.IDENTIFIER):\n",
    "            self.forward()\n",
    "            pass # Return Identifier Node\n",
    "        return ParsedNode(None, True) \n",
    "        \n",
    "    \"\"\"\n",
    "    int or tuple(int,int) or array{int}\n",
    "    \"\"\"\n",
    "    def type(self) -> ParsedNode:\n",
    "        # RULE -->  INT                         NEED UPDATE\n",
    "        #        : TUPLE LB type (,type)* RB    \n",
    "\n",
    "        token = self.current_token\n",
    "        if(token == TokenTypes.INT_TYPE):\n",
    "            self.forward()\n",
    "            pass # Return Node\n",
    "        \n",
    "        if(token == TokenTypes.TUPLE_TYPE):\n",
    "             self.forward()\n",
    "             if(token == TokenTypes.LBRACKET):\n",
    "                 \n",
    "                 types:list[TypeNode] = []\n",
    "\n",
    "                 types = self.type()\n",
    "                 if(types.hasSyntaxError == False):\n",
    "                     if(self.check_type(self.current_token.type, [TokenTypes.COMMA])):\n",
    "                        while(self.current_token.type == TokenTypes.COMMA):\n",
    "\n",
    "                            self.forward()\n",
    "                            t = self.type()\n",
    "\n",
    "                            if(t.hasSyntaxError):  #If on error\n",
    "                                return ParsedNode(None,True)\n",
    "                            types.append(t) #else append to list of types\n",
    "                      \n",
    "                     pass # Return TypNode with list of nodes\n",
    "\n",
    "             ParsedNode(None, True) \n",
    "        \n",
    "        return ParsedNode(None, True) \n",
    "        \n",
    "    \"\"\"\n",
    "    a[i:int]\n",
    "    \"\"\"\n",
    "    def indexing(self) -> ParsedNode:\n",
    "        # RULE --> Identifier SLB expr SRB\n",
    "\n",
    "        left_node = self.Identifier()\n",
    "\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.current_token.type == TokenTypes.SLB):\n",
    "                self.forward()\n",
    "                expr_node = self.expr()\n",
    "          \n",
    "                if(expr_node.hasSyntaxError == False and self.current_token == TokenTypes.SRB):\n",
    "                     pass # RETURN INDEXING NODE\n",
    "                return ParsedNode(None,True)\n",
    "        return left_node\n",
    "                \n",
    "\n",
    "    \"\"\"\n",
    "    Moves forward in the tokens list\n",
    "    \"\"\"\n",
    "    def forward(self) -> None:\n",
    "        self.lexer.forward()\n",
    "        self.current_token = lexer.get_token(self.lexer.current_char)\n",
    "        if (self.current_token.type == TokenTypes.EOF):\n",
    "            self.end = True\n",
    "        print(self.current_token.__info__())\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    Checks if a type exists in the following types list\n",
    "    \"\"\"\n",
    "    def check_type(self,type:TokenTypes,types:list[TokenTypes]) -> bool:\n",
    "        return type in types\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Sets current token back if a certain path lead to failure (Wrong syntax)\n",
    "    May need it for later\n",
    "    \"\"\"\n",
    "    def set_to_token(self,index): \n",
    "        self.lexer.index = index\n",
    "        self.forward()\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Interpreter:\n",
    "    def __init__(self, parser: Parser):\n",
    "        self.parser = parser\n",
    "\n",
    "    def interpret(self):\n",
    "        tree = self.parser.parse()\n",
    "        return tree.visit(tree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenTypes.INTEGER:2\n",
      "TokenTypes.MULTIPLY:*\n",
      "TokenTypes.MINUS:-\n",
      "TokenTypes.MINUS:-\n",
      "TokenTypes.MINUS:-\n",
      "TokenTypes.INTEGER:2\n",
      "TokenTypes.EOF:None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "text = \"-2 * 2\"\n",
    "lexer = lexicon(text)\n",
    "parser = Parser(lexer)\n",
    "interpreter = Interpreter(parser)\n",
    "result = interpreter.interpret()\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
