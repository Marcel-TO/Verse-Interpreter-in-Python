{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verse Interpreter development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from enum import Enum\n",
    "from collections import namedtuple\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ErrorType(Enum):\n",
    "    SyntaxError = 'Wrong Syntax at'\n",
    "    SemanticError = 'Wrong Semantics at'\n",
    "    UnkownError = 'Operation Failure'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeStatus(Enum):\n",
    "    # Data\n",
    "    VALUE_RECEIVABLE = None\n",
    "    NOT_ASSIGNED_YET = None\n",
    "    ERROR = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self):{}\n",
    "        \n",
    "    def __log__(self, string:str):{}\n",
    "\n",
    "    def __log_error__(self,string:str, type:ErrorType):{}\n",
    "\n",
    "class Console_Logger(Logger):\n",
    "\n",
    "    def __log__(self, string:str):\n",
    "        print(string)\n",
    "\n",
    "    def __log_error__(self,string:str, type:ErrorType):       \n",
    "        print(\"ERROR| \" + type.value + \": \" + string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenTypes(Enum):\n",
    "    # Data\n",
    "    INTEGER = int\n",
    "    IDENTIFIER = string #Names/Variables\n",
    "    INT_TYPE = \"int\"\n",
    "    TUPLE_TYPE = \"tuple\"\n",
    "    ARRAY_TYPE = \"array\"\n",
    "    FAIL = \"false?\"\n",
    "    # Aritmetics\n",
    "    PLUS = \"+\"\n",
    "    MINUS = \"-\"\n",
    "    MULTIPLY = \"*\"\n",
    "    DIVIDE = \"/\"\n",
    "    GREATER = \">\"\n",
    "    GREATEREQ = \">=\"\n",
    "    LOWER = \"<\"\n",
    "    LOWEREQ = \"<=\"\n",
    "    CHOICE = \"|\"\n",
    "    LAMBDA = \"=>\"\n",
    "    # Mehtods\n",
    "    FOR = \"for\"\n",
    "    DO = \"do\"\n",
    "    IF = \"if\"\n",
    "    THEN = \"then\"\n",
    "    ELSE = \"else\"\n",
    "    # Else\n",
    "    EOF = \"\"\n",
    "    COLON = \":\"\n",
    "    COMMA=\",\"\n",
    "    SEMICOLON =\";\"\n",
    "    BINDING =\":=\"\n",
    "    LBRACKET = \"(\"\n",
    "    RBRACKET = \")\"\n",
    "    SBL = \"[\"\n",
    "    SBR = \"]\"\n",
    "    CBL = \"{\"\n",
    "    CBR = \"}\"\n",
    "    EQUAL = \"=\"\n",
    "    SCOPE = \":\"\n",
    "    DOT = \".\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<TokenTypes.INTEGER: <class 'int'>>,\n",
       " <TokenTypes.IDENTIFIER: <module 'string' from 'c:\\\\Users\\\\chris\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\string.py'>>,\n",
       " <TokenTypes.INT_TYPE: 'int'>,\n",
       " <TokenTypes.TUPLE_TYPE: 'tuple'>,\n",
       " <TokenTypes.ARRAY_TYPE: 'array'>,\n",
       " <TokenTypes.FAIL: 'false?'>,\n",
       " <TokenTypes.PLUS: '+'>,\n",
       " <TokenTypes.MINUS: '-'>,\n",
       " <TokenTypes.MULTIPLY: '*'>,\n",
       " <TokenTypes.DIVIDE: '/'>,\n",
       " <TokenTypes.GREATER: '>'>,\n",
       " <TokenTypes.GREATEREQ: '>='>,\n",
       " <TokenTypes.LOWER: '<'>,\n",
       " <TokenTypes.LOWEREQ: '<='>,\n",
       " <TokenTypes.CHOICE: '|'>,\n",
       " <TokenTypes.LAMBDA: '=>'>,\n",
       " <TokenTypes.FOR: 'for'>,\n",
       " <TokenTypes.DO: 'do'>,\n",
       " <TokenTypes.IF: 'if'>,\n",
       " <TokenTypes.THEN: 'then'>,\n",
       " <TokenTypes.ELSE: 'else'>,\n",
       " <TokenTypes.EOF: ''>,\n",
       " <TokenTypes.COLON: ':'>,\n",
       " <TokenTypes.COMMA: ','>,\n",
       " <TokenTypes.SEMICOLON: ';'>,\n",
       " <TokenTypes.BINDING: ':='>,\n",
       " <TokenTypes.LBRACKET: '('>,\n",
       " <TokenTypes.RBRACKET: ')'>,\n",
       " <TokenTypes.SBL: '['>,\n",
       " <TokenTypes.SBR: ']'>,\n",
       " <TokenTypes.CBL: '{'>,\n",
       " <TokenTypes.CBR: '}'>,\n",
       " <TokenTypes.EQUAL: '='>,\n",
       " <TokenTypes.DOT: '.'>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(TokenTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Token class for reserverd keywords and chars within a Verse program.\n",
    "'''\n",
    "class Token:\n",
    "    def __init__(self, type: TokenTypes, value) -> None:\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "    \n",
    "    def __info__(self):\n",
    "         return \"{}: {}\".format(self.type, self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3327886422.py, line 93)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 93\u001b[1;36m\u001b[0m\n\u001b[1;33m    match result:\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Lexicon class for collecting tokens.\n",
    "'''\n",
    "class lexicon:\n",
    "    def __init__(self, input: string):\n",
    "        self.input = input\n",
    "        self.index = 0\n",
    "        self.current_char = self.input[self.index]\n",
    "    \n",
    "    '''\n",
    "    Moves the pointer a character forward.\n",
    "    '''\n",
    "    def forward(self) -> None:\n",
    "        self.index += 1\n",
    "\n",
    "        # checks if index is out of range\n",
    "        if (self.index >= len(self.input)):\n",
    "            self.current_char = None\n",
    "            return\n",
    "        \n",
    "        self.current_char = self.input[self.index]\n",
    "    \n",
    "    '''\n",
    "    Moves the pointer a character backwards.\n",
    "    '''\n",
    "    def backward(self) -> None:\n",
    "        self.index -= 1\n",
    "\n",
    "        # checks if index is out of range\n",
    "        if self.index < 0:\n",
    "            self.current_char = None\n",
    "            return\n",
    "        \n",
    "        self.current_char = self.input[self.index]\n",
    "    \n",
    "    '''\n",
    "    Checks if something is an integer within a text.\n",
    "    '''\n",
    "    def get_int(self) -> int:\n",
    "        if self.index >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.input[self.index]\n",
    "\n",
    "        # checks if there are multiple digits\n",
    "        while True:\n",
    "            self.forward()\n",
    "\n",
    "            if self.index < len(self.input) and self.input[self.index] != None and self.input[self.index].isnumeric():\n",
    "                result += self.input[self.index]\n",
    "            else:\n",
    "                self.backward()\n",
    "                break\n",
    "\n",
    "        return int(result)\n",
    "    \n",
    "    '''\n",
    "    Checks if something is an identifier within a text.\n",
    "    '''\n",
    "    def get_var(self) -> string:\n",
    "        if self.index >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.input[self.index]\n",
    "\n",
    "        # checks if there is a longer variable name\n",
    "        while True:\n",
    "            self.forward()\n",
    "\n",
    "            if self.index < len(self.input) and self.input[self.index] != None and self.input[self.index].isalpha():\n",
    "                result += self.input[self.index]\n",
    "            elif self.index < len(self.input) and self.input[self.index] != None and self.input[self.index] == '?':\n",
    "                result += self.input[self.index]\n",
    "            else:\n",
    "                self.backward()\n",
    "                break\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    '''\n",
    "    Checks if something is a binding or colon token within a text.\n",
    "    '''\n",
    "    def get_binding(self):\n",
    "        if self.index >= len(self.input) and self.index + 1 >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.input[self.index]\n",
    "        self.forward()\n",
    "        \n",
    "        if self.index < len(self.input) and self.input[self.index] != None:\n",
    "                result += self.input[self.index]\n",
    "\n",
    "        match result:\n",
    "            case TokenTypes.BINDING.value:\n",
    "                return Token(TokenTypes.BINDING, TokenTypes.BINDING.value)\n",
    "        \n",
    "        self.backward()\n",
    "        return Token(TokenTypes.COLON, TokenTypes.COLON.value)\n",
    "    \n",
    "    '''\n",
    "    Checks if something is greater equals or greater token within a text.\n",
    "    '''\n",
    "    def get_greater_eq(self):\n",
    "        if self.index >= len(self.input) and self.index + 1 >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.input[self.index]\n",
    "        self.forward()\n",
    "        \n",
    "        if self.index < len(self.input) and self.input[self.index] != None:\n",
    "                result += self.input[self.index]\n",
    "\n",
    "        match result:\n",
    "            case TokenTypes.GREATEREQ.value:\n",
    "                return Token(TokenTypes.GREATEREQ, TokenTypes.GREATEREQ.value)\n",
    "        \n",
    "        self.backward()\n",
    "        return Token(TokenTypes.GREATER, TokenTypes.GREATER.value)\n",
    "    \n",
    "    '''\n",
    "    Checks if something is lower equals or lower token within a text.\n",
    "    '''\n",
    "    def get_lower_eq(self):\n",
    "        if self.index >= len(self.input) and self.index + 1 >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.input[self.index]\n",
    "        self.forward()\n",
    "        \n",
    "        if self.index < len(self.input) and self.input[self.index] != None:\n",
    "                result += self.input[self.index]\n",
    "\n",
    "        match result:\n",
    "            case TokenTypes.LOWEREQ.value:\n",
    "                return Token(TokenTypes.LOWEREQ, TokenTypes.LOWEREQ.value)\n",
    "        \n",
    "        self.backward()\n",
    "        return Token(TokenTypes.LOWER, TokenTypes.LOWER.value)\n",
    "    \n",
    "    '''\n",
    "    Gets the token within a text.\n",
    "    '''\n",
    "    def get_token(self, char: string) -> Token:\n",
    "        token = self.check_for_tokentypes(char)\n",
    "\n",
    "        if token.type != TokenTypes.EOF:\n",
    "            return token\n",
    "        \n",
    "        if char == None:\n",
    "            return token\n",
    "            \n",
    "        # skip spaces.\n",
    "        if char == ' ':\n",
    "            self.forward()\n",
    "            return self.get_token(self.current_char)\n",
    "        \n",
    "        if char == TokenTypes.COLON:\n",
    "            return self.get_next(TokenTypes.BINDING.value)\n",
    "\n",
    "        # checks if the current character is a number.\n",
    "        if char.isnumeric():\n",
    "            result = self.get_int()\n",
    "            return Token(TokenTypes.INTEGER, result)\n",
    "        \n",
    "        if char.isalpha():\n",
    "            result = self.get_var()\n",
    "            token = self.check_for_tokentypes(result)\n",
    "            if(token.type == TokenTypes.EOF):\n",
    "                token = Token(TokenTypes.IDENTIFIER, result)  \n",
    "                  \n",
    "        return token\n",
    "\n",
    "    '''\n",
    "    Checks for token type for a currently selected character from a text.\n",
    "    '''\n",
    "    def check_for_tokentypes(self, char: string) -> Token:\n",
    "        # checks if the current character is a supported token type.\n",
    "        match char:\n",
    "            case TokenTypes.INTEGER.value:\n",
    "                return Token(TokenTypes.INTEGER, TokenTypes.INTEGER.value)\n",
    "            case TokenTypes.IDENTIFIER.value:\n",
    "                return Token(TokenTypes.IDENTIFIER, TokenTypes.IDENTIFIER.value)\n",
    "            case TokenTypes.INT_TYPE.value:\n",
    "                return Token(TokenTypes.INT_TYPE, TokenTypes.INT_TYPE.value)\n",
    "            case TokenTypes.TUPLE_TYPE.value:\n",
    "                return Token(TokenTypes.TUPLE_TYPE, TokenTypes.TUPLE_TYPE.value)\n",
    "            case TokenTypes.ARRAY_TYPE.value:\n",
    "                return Token(TokenTypes.ARRAY_TYPE, TokenTypes.ARRAY_TYPE.value)\n",
    "            case TokenTypes.FAIL.value:\n",
    "                return Token(TokenTypes.FAIL, TokenTypes.FAIL.value)\n",
    "            case TokenTypes.PLUS.value:\n",
    "                return Token(TokenTypes.PLUS, TokenTypes.PLUS.value)\n",
    "            case TokenTypes.MINUS.value:\n",
    "                return Token(TokenTypes.MINUS, TokenTypes.MINUS.value)\n",
    "            case TokenTypes.MULTIPLY.value:\n",
    "                return Token(TokenTypes.MULTIPLY, TokenTypes.MULTIPLY.value)\n",
    "            case TokenTypes.DIVIDE.value:\n",
    "                return Token(TokenTypes.DIVIDE, TokenTypes.DIVIDE.value)\n",
    "            case TokenTypes.GREATER.value:\n",
    "                return self.get_greater_eq()\n",
    "            case TokenTypes.GREATEREQ.value:\n",
    "                return Token(TokenTypes.GREATEREQ, TokenTypes.GREATEREQ.value)\n",
    "            case TokenTypes.LOWER.value:\n",
    "                return self.get_lower_eq()\n",
    "            case TokenTypes.LOWEREQ.value:\n",
    "                return Token(TokenTypes.LOWEREQ, TokenTypes.LOWEREQ.value)\n",
    "            case TokenTypes.CHOICE.value:\n",
    "                return Token(TokenTypes.CHOICE, TokenTypes.CHOICE.value)\n",
    "            case TokenTypes.FOR.value:\n",
    "                return Token(TokenTypes.FOR, TokenTypes.FOR.value)\n",
    "            case TokenTypes.DO.value:\n",
    "                return Token(TokenTypes.DO, TokenTypes.DO.value)\n",
    "            case TokenTypes.IF.value:\n",
    "                return Token(TokenTypes.IF, TokenTypes.IF.value)\n",
    "            case TokenTypes.THEN.value:\n",
    "                return Token(TokenTypes.THEN, TokenTypes.THEN.value)\n",
    "            case TokenTypes.ELSE.value:\n",
    "                return Token(TokenTypes.ELSE, TokenTypes.ELSE.value)\n",
    "            case TokenTypes.EOF.value:\n",
    "                return Token(TokenTypes.EOF, TokenTypes.EOF.value)\n",
    "            case TokenTypes.COLON.value:\n",
    "                return self.get_binding()\n",
    "            case TokenTypes.COMMA.value:\n",
    "                return Token(TokenTypes.COMMA, TokenTypes.COMMA.value)\n",
    "            case TokenTypes.SEMICOLON.value:\n",
    "                return Token(TokenTypes.SEMICOLON, TokenTypes.SEMICOLON.value)\n",
    "            case TokenTypes.BINDING.value:\n",
    "                return Token(TokenTypes.BINDING, TokenTypes.BINDING.value)\n",
    "            case TokenTypes.LBRACKET.value:\n",
    "                return Token(TokenTypes.LBRACKET, TokenTypes.LBRACKET.value)\n",
    "            case TokenTypes.RBRACKET.value:\n",
    "                return Token(TokenTypes.RBRACKET, TokenTypes.RBRACKET.value)\n",
    "            case TokenTypes.SBL.value:\n",
    "                return Token(TokenTypes.SBL, TokenTypes.SBL.value)\n",
    "            case TokenTypes.SBR.value:\n",
    "                return Token(TokenTypes.SBR, TokenTypes.SBR.value)\n",
    "            case TokenTypes.CBL.value:\n",
    "                return Token(TokenTypes.CBL, TokenTypes.CBL.value)\n",
    "            case TokenTypes.CBR.value:\n",
    "                return Token(TokenTypes.CBR, TokenTypes.CBR.value)\n",
    "            case TokenTypes.EQUAL.value:\n",
    "                return Token(TokenTypes.EQUAL, TokenTypes.EQUAL.value)\n",
    "            case TokenTypes.SCOPE.value:\n",
    "                return Token(TokenTypes.SCOPE, TokenTypes.SCOPE.value)\n",
    "            case TokenTypes.DOT.value:\n",
    "                return Token(TokenTypes.DOT, TokenTypes.DOT.value)\n",
    "            case _:\n",
    "                return Token(TokenTypes.EOF, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is of the tokentype: TokenTypes.IDENTIFIER\n",
      ": is of the tokentype: TokenTypes.COLON\n",
      "4 is of the tokentype: TokenTypes.INTEGER\n",
      "; is of the tokentype: TokenTypes.SEMICOLON\n",
      ">= is of the tokentype: TokenTypes.GREATEREQ\n",
      "; is of the tokentype: TokenTypes.SEMICOLON\n",
      "1 is of the tokentype: TokenTypes.INTEGER\n",
      ". is of the tokentype: TokenTypes.DOT\n",
      ". is of the tokentype: TokenTypes.DOT\n",
      "10 is of the tokentype: TokenTypes.INTEGER\n"
     ]
    }
   ],
   "source": [
    "lexer = lexicon(\"x:4; >=; 1..10\")\n",
    "\n",
    "while lexer.current_char is not None:\n",
    "    token = lexer.get_token(lexer.current_char)\n",
    "    print(str(token.value) + \" is of the tokentype: \" + str(token.type))\n",
    "    lexer.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Class that takes a parsed node, containes information if node could have been parsed.\n",
    "'''\n",
    "class ParsedNode:\n",
    "    def __init__(self, node, hasSyntaxError:bool ):\n",
    "        self.node = node\n",
    "        self.hasSyntaxError = hasSyntaxError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Top class of all nodes.\n",
    "'''\n",
    "class BaseNode:\n",
    "    def __init__(self, token) -> None:\n",
    "        self.token = token  \n",
    "\n",
    "     \n",
    "'''\n",
    "Node for block statements.\n",
    "'''  \n",
    "class BlockNode(BaseNode):\n",
    "    def __init__(self, nodes:list[BaseNode]) -> None:\n",
    "        self.nodes:list[BaseNode] = nodes\n",
    "\n",
    "'''\n",
    "Top Node in tree.\n",
    "''' \n",
    "class ProgramNode(BaseNode):\n",
    "    def __init__(self, node:BlockNode) -> None:\n",
    "        self.node = node\n",
    "\n",
    "'''\n",
    "Node for binded identifiers.\n",
    "''' \n",
    "class BindingNode(BaseNode):\n",
    "    def __init__(self,token:Token, leftNode:BaseNode, rightNode:BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.leftNode = leftNode\n",
    "        self.rightNode = rightNode\n",
    "\n",
    "'''\n",
    "Node representing a number.\n",
    "''' \n",
    "class NumberNode(BaseNode):\n",
    "    def __init__(self, token:Token) -> None:\n",
    "        super().__init__(token)\n",
    "        self.value = token.value\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self.value)\n",
    "\n",
    "'''\n",
    "Node for +, -, /, *, <, >, <=, >= operations.\n",
    "''' \n",
    "class OperatorNode(BaseNode):\n",
    "    def __init__(self, token:Token, leftNode: BaseNode, rightNode: BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.leftNode = leftNode\n",
    "        self.rightNode = rightNode\n",
    "\n",
    "\n",
    "'''\n",
    "Node for unary operations.\n",
    "''' \n",
    "class UnaryNode(BaseNode):\n",
    "     def __init__(self, token:Token, node) -> None:\n",
    "        super().__init__(token)\n",
    "        self.node = node\n",
    "\n",
    "'''\n",
    "Node for identifiers.\n",
    "''' \n",
    "class IdentifierNode(BaseNode):\n",
    "    def __init__(self, token:Token) -> None: #Change into Variable/IdentifierNode\n",
    "        super().__init__(token)\n",
    "\n",
    "\n",
    "'''\n",
    "Node for scoped identifiers.\n",
    "''' \n",
    "class ScopeNode(BaseNode):\n",
    "    def __init__(self, token:Token, nodes:list[BaseNode], type) -> None: #Change into Variable/IdentifierNode\n",
    "        super().__init__(token)\n",
    "        self.nodes = nodes\n",
    "        self.type = type\n",
    "\n",
    "'''\n",
    "Top class node for types (int, tuple, etc.).\n",
    "''' \n",
    "class TypeNode(BaseNode):\n",
    "    def __init__(self, token:Token) -> None: \n",
    "        super().__init__(token)\n",
    "        self.type = type\n",
    "\n",
    "'''\n",
    "Node for sequence types (tuple).\n",
    "''' \n",
    "class SequenceTypeNode(TypeNode):\n",
    "    def __init__(self, token:Token, types:list[TypeNode]) -> None: \n",
    "        super().__init__(token)\n",
    "        self.types = types\n",
    "\n",
    "\n",
    "'''\n",
    "Node for scoped func calls.\n",
    "''' \n",
    "class FuncCallNode:\n",
    "    def __init__(self,identifier:IdentifierNode, args:list) -> None:\n",
    "        self.identifier = identifier\n",
    "        self.args = args\n",
    "\n",
    "'''\n",
    "Node for params of a func declarations.\n",
    "''' \n",
    "class ParamsNode:\n",
    "    def __init__(self, nodes:list[ScopeNode]) -> None:\n",
    "        self.nodes = nodes\n",
    "\n",
    "'''\n",
    "Node for func declarations.\n",
    "''' \n",
    "class FuncDeclNode:\n",
    "    def __init__(self,identifier:IdentifierNode, nodes:list[ParamsNode],usesLambda:bool, type:TypeNode, block:BlockNode) -> None:\n",
    "        self.identifier = identifier\n",
    "        self.nodes = nodes\n",
    "        self.usesLambda = usesLambda\n",
    "        self.type = type\n",
    "        self.block = block\n",
    "\n",
    "'''\n",
    "Node for loops.\n",
    "''' \n",
    "class ForNode(BaseNode):\n",
    "     def __init__(self, token:Token, node: BaseNode, condition: BaseNode, expr: BaseNode, do: BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.node = node\n",
    "        self.condition = condition\n",
    "        self.expr = expr\n",
    "        self.do = do\n",
    "\n",
    "'''\n",
    "Node for if statements.\n",
    "''' \n",
    "class IfNode(BaseNode):\n",
    "     def __init__(self, token:Token, if_node: BaseNode, then_node: BaseNode, else_node: BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.if_node = if_node\n",
    "        self.then_node = then_node\n",
    "        self.else_node = else_node\n",
    "\n",
    "'''\n",
    "Node for rigid equals.\n",
    "''' \n",
    "class RigidEqNode(BaseNode):\n",
    "     def __init__(self, token:Token, left_node:BaseNode, right_node:BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.left_node = left_node\n",
    "        self.right_node = right_node\n",
    "\n",
    "'''\n",
    "Node for flexible equals.\n",
    "''' \n",
    "class FlexibleEqNode(BaseNode):\n",
    "     def __init__(self, token:Token, left_node:BaseNode, right_node:BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.left_node = left_node\n",
    "        self.right_node = right_node\n",
    "\n",
    "'''\n",
    "Node for sequences (tuple, array).\n",
    "''' \n",
    "class SequenceNode(BaseNode):\n",
    "     def __init__(self, token:Token, nodes:list[BaseNode]) -> None:\n",
    "        super().__init__(token)\n",
    "        self.nodes = nodes\n",
    "        self.seperator = \",\"\n",
    "        \n",
    "     def __repr__(self) -> str:    \n",
    "        return \"(\" + self.seperator.join([repr(n) for n in self.nodes]) + \")\"\n",
    "\n",
    "'''\n",
    "Node for indexing.\n",
    "''' \n",
    "class IndexingNode(BaseNode):\n",
    "      def __init__(self, token:Token,identifier:IdentifierNode, index:BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.identifier = identifier\n",
    "        self.index = index\n",
    "\n",
    "'''\n",
    "Node for choices sequences(branches of a listing of choices).\n",
    "''' \n",
    "class ChoiceSequenceNode(BaseNode):\n",
    "    def __init__(self, token:Token, nodes:list[BaseNode]) -> None:\n",
    "        super().__init__(token)\n",
    "        self.nodes = nodes\n",
    "        self.seperator = \"|\"\n",
    "        \n",
    "        # Current choice branch/nodes index.\n",
    "        self.currentChoice:int = 0 \n",
    "\n",
    "        # Current val index for current choice branch/nodes.\n",
    "        self.currentVal:int = - 1 \n",
    "\n",
    "        # Gets the vals of current choice branch.\n",
    "        self.getVals = self.getValsOfChoice()\n",
    "        \n",
    "    def __repr__(self) -> str:    \n",
    "        return \"(\" + self.seperator.join([repr(n) for n in self.nodes]) + \")\"\n",
    "    \n",
    "    '''\n",
    "    Gets the vals of the current choice branch.\n",
    "    ''' \n",
    "    def getValsOfChoice(self):\n",
    "        val = []\n",
    "        current_node = self.nodes[self.currentChoice]\n",
    "        if self.currentChoice > len(self.nodes) - 1:\n",
    "            return None\n",
    "        if current_node.token.type == TokenTypes.CHOICE:\n",
    "            for v in current_node.yieldVal():\n",
    "                val.append(v)\n",
    "            return val\n",
    "        else: return [current_node]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    '''\n",
    "        Steps to the next choice if possible.\n",
    "        \n",
    "        If:\n",
    "\n",
    "        no choice branches available (Index of choice is at the last choice branch),\n",
    "        set choice branch index back to the beginning choice branch, choice branch at index 0\n",
    "        and set back the index counter for the values of the choice branch at current index.\n",
    "        Return False indicating, no choice branches left.\n",
    "\n",
    "        Else:\n",
    "        \n",
    "        Step to the next choice branch.\n",
    "        Set counter back, so it can start at the beginning of the current choice branch, as\n",
    "        soon get next val method is called.\n",
    "        Return True indicating next choice branch has been selected.\n",
    "    ''' \n",
    "    def nextChoice(self) -> bool:\n",
    "           \n",
    "        if self.currentChoice + 1 > len(self.nodes) - 1:\n",
    "            self.setChoiceBack()\n",
    "            self.setValCountBack()\n",
    "            return False\n",
    "        \n",
    "       \n",
    "        else: \n",
    "            self.currentChoice += 1\n",
    "            self.setValCountBack()\n",
    "            self.getVals = self.getValsOfChoice()         \n",
    "            return True     \n",
    "\n",
    "\n",
    "    '''\n",
    "    Set back the current choice branch index to 0 and its value index also to its starting integer value.\n",
    "    '''\n",
    "    def setChoiceBack(self):\n",
    "        self.currentChoice = 0\n",
    "        self.setValCountBack()\n",
    "        self.getVals = self.getValsOfChoice()\n",
    "\n",
    "    '''\n",
    "    Sets the val to -1, so when get next val is called, its steps forward to index 0. \n",
    "    '''\n",
    "    def setValCountBack(self):\n",
    "        self.currentVal = -1\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Gets the next val of current choice branch. Repeats the selection of a choice branch, if requested.\n",
    "    Needs to repeat the values for a choice branch, except for the last choices node during operation.\n",
    "    '''\n",
    "    def getNextVal(self, repeat:bool):\n",
    "        if self.currentVal + 1 > len(self.getVals) - 1 and repeat: # If first val none, maybe error\n",
    "            self.setValCountBack()\n",
    "            self.currentVal += 1\n",
    "            return self.getVals[self.currentVal]\n",
    "        \n",
    "        elif self.currentVal + 1 > len(self.getVals) - 1: # Need to delete or change this line of code (Not needed)\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            self.currentVal += 1\n",
    "            return self.getVals[self.currentVal]\n",
    "        \n",
    "    '''\n",
    "    Checks if current choice branch has a next value.\n",
    "    Return wheter if its True or not.\n",
    "    '''\n",
    "    def hasNextVal(self):\n",
    "        nextValExists = self.currentVal < len(self.getVals) - 1\n",
    "        return nextValExists\n",
    "\n",
    "    '''\n",
    "    Yields all values of a choice branch.\n",
    "    '''\n",
    "    def yieldVal(self):\n",
    "        for c in self.nodes:   \n",
    "            if c.token.type == TokenTypes.CHOICE:\n",
    "                yield c.yieldVal()\n",
    "            else: yield c\n",
    "\n",
    "'''\n",
    "Fail node indicating false? in Verse.\n",
    "'''\n",
    "class FailNode(BaseNode): # Technically not need, since Fail node is 1 to 1 a BaseNode\n",
    "      def __init__(self, token:Token) -> None:\n",
    "        super().__init__(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symboltable:\n",
    "    def __init__(self) -> None:\n",
    "        self.symboltable = []\n",
    "    \n",
    "    def __info__(self) -> None:\n",
    "        for t in self.symboltable:\n",
    "            print(\"Symboltable: Name= {}, Value= {}, ParentNode= {}\".format(t[0], t[1], t[2]))\n",
    "    \n",
    "    def check_if_exists(self, name: string, parentNode: BaseNode) -> bool:\n",
    "        for symbol in self.symboltable:\n",
    "            if symbol[0] == name:\n",
    "                if symbol[2] == parentNode:\n",
    "                    return True \n",
    "        return False\n",
    "    \n",
    "    def add(self, name: string, value: BaseNode, parentNode: BaseNode) -> None:\n",
    "        # checks if the name already exists in the current scope. Otherwise add to table.\n",
    "        if self.check_if_exists(name, parentNode) == False:\n",
    "            self.symboltable.append([name, value, parentNode])\n",
    "    \n",
    "    def remove(self, name:string, value: BaseNode, parentNode: BaseNode) -> None:\n",
    "        # checks if the table is empty.\n",
    "        if len(self.symboltable) < 1:\n",
    "            return\n",
    "        \n",
    "        # iterates through and removes the corresponding \n",
    "        for symbol in self.symboltable:\n",
    "            if symbol[0] == name:\n",
    "                if symbol[2] == parentNode:\n",
    "                    self.symboltable.remove([name, value, parentNode]) \n",
    "    \n",
    "    def get_value(self, name: string, parentNode: BaseNode) -> tuple[bool, BaseNode]:\n",
    "        for symbol in self.symboltable:\n",
    "            if symbol[0] == name:\n",
    "                if symbol[2] == parentNode:\n",
    "                    return True, symbol[1]\n",
    "        return False, parentNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scope:\n",
    "    def __init__(self, symbol: string, symbolType: TokenTypes, insideTable) -> None:\n",
    "        self.symbol: string = symbol\n",
    "        self.symbolType: TokenTypes | None = symbolType\n",
    "        self.insideTable = insideTable\n",
    "\n",
    "\n",
    "class Scope:\n",
    "    def __init__(self, symbol: string, values:list[BaseNode], symbolType: TokenTypes, insideTable) -> None:\n",
    "        self.symbol: string = symbol\n",
    "        self.values: list[BaseNode] | None = values\n",
    "        self.symbolType: TokenTypes | None = symbolType\n",
    "        self.insideTable = insideTable\n",
    "\n",
    "    def getValue(self):\n",
    "        if self.values == None | len(self.values) == 0:\n",
    "            return False, None\n",
    "        return self.values[0] # Only first value for now.\n",
    "\n",
    "class ScopeTable:\n",
    "    def __init__(self) -> None:\n",
    "        self.scopetable: list[Scope] = []\n",
    "    \n",
    "    def __info__(self) -> None:\n",
    "        for scope in self.scopetable:\n",
    "            print(\"Symboltable: Name= {}, Value= {}, type= {} and inside table={}\".format(scope.symbol, scope.values, scope.symbolType, scope.insideTable))\n",
    "    \n",
    "    def check_if_exists(self, symbol: string, table) -> bool:\n",
    "        for scope in self.scopetable:\n",
    "            if scope.symbol == symbol and table == scope.insideTable:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def addScope(self, symbol: string, value: BaseNode, symbolType: TokenTypes) -> None:\n",
    "        # checks if the name already exists in the current scope. Otherwise add to table.\n",
    "        if self.check_if_exists(symbol, self) == False:\n",
    "            self.scopetable.append(Scope(symbol, [value], symbolType, self))\n",
    "        \n",
    "        # checks if the scope is already defined with type or value.\n",
    "        for scope in self.scopetable:\n",
    "            if scope.symbol == symbol and scope.symbolType != None and scope.values == None and value != None:\n",
    "                # Need to implement type check value before adding\n",
    "                scope.values.append(value)\n",
    "            elif scope.symbol == symbol and scope.symbolType == None and scope.values != None and symbolType != None:\n",
    "                scope.symbolType = symbolType\n",
    "\n",
    "    def addScopeTable(self, scopetable) -> None:\n",
    "\n",
    "            # checks if the name already exists in the current scope. Otherwise add to table.\n",
    "            for scope in scopetable.scopetable:\n",
    "                if self.check_if_exists(scope.symbol, scopetable) == False:\n",
    "                    self.scopetable.append(Scope(scope.symbol, scope.values, scope.symbolType, scopetable))\n",
    "\n",
    "    \n",
    "    def remove(self, symbol:string, value: BaseNode, symbolType: type) -> None:\n",
    "        # checks if the table is empty.\n",
    "        if len(self.scopetable) < 1:\n",
    "            return\n",
    "        \n",
    "        # iterates through and removes the corresponding \n",
    "        for scope in self.scopetable:\n",
    "            if scope.symbol == symbol:\n",
    "                if scope.insideTable == self:\n",
    "                    self.scopetable.remove(Scope(scope.symbol, scope.values, scope.symbolType, self)) \n",
    "    \n",
    "    def get_value(self, symbol: string, scopetable) -> tuple[bool, BaseNode]:\n",
    "        for scope in self.scopetable:\n",
    "            if scope.symbol == symbol:\n",
    "                if scope.insideTable == scopetable:\n",
    "                    return scope.getValue()\n",
    "        return False, None\n",
    "    \n",
    "    def get_scope(self, symbol:string):\n",
    "        for scope in self.scopetable:\n",
    "            if scope.symbol == symbol:\n",
    "                return True, scope\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scope:\n",
    "    def __init__(self, symbol: string, values:list[BaseNode], symbolType: TokenTypes, insideTable) -> None:\n",
    "        self.symbol: string = symbol\n",
    "        self.values: list[BaseNode] | None = values\n",
    "        self.symbolType: TokenTypes | None = symbolType\n",
    "        self.insideTable = insideTable\n",
    "\n",
    "    def getValue(self):\n",
    "        if self.values == None | len(self.values) == 0:\n",
    "            return False, None\n",
    "        return self.values[0] # Only first value for now.\n",
    "\n",
    "class ScopeTable:\n",
    "    def __init__(self) -> None:\n",
    "        self.scopetable: list[Scope] = []\n",
    "    \n",
    "    def __info__(self) -> None:\n",
    "        for scope in self.scopetable:\n",
    "            print(\"Symboltable: Name= {}, Value= {}, type= {} and inside table={}\".format(scope.symbol, scope.values, scope.symbolType, scope.insideTable))\n",
    "    \n",
    "    def check_if_exists(self, symbol: string, table) -> bool:\n",
    "        for scope in self.scopetable:\n",
    "            if scope.symbol == symbol and table == scope.insideTable:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def addScope(self, symbol: string, value: BaseNode, symbolType: TokenTypes) -> None:\n",
    "        # checks if the name already exists in the current scope. Otherwise add to table.\n",
    "        if self.check_if_exists(symbol, self) == False:\n",
    "            self.scopetable.append(Scope(symbol, [value], symbolType, self))\n",
    "        \n",
    "        # checks if the scope is already defined with type or value.\n",
    "        for scope in self.scopetable:\n",
    "            if scope.symbol == symbol and scope.symbolType != None and scope.values == None and value != None:\n",
    "                # Need to implement type check value before adding\n",
    "                scope.values.append(value)\n",
    "            elif scope.symbol == symbol and scope.symbolType == None and scope.values != None and symbolType != None:\n",
    "                scope.symbolType = symbolType\n",
    "\n",
    "    def addScopeTable(self, scopetable) -> None:\n",
    "\n",
    "            # checks if the name already exists in the current scope. Otherwise add to table.\n",
    "            for scope in scopetable.scopetable:\n",
    "                if self.check_if_exists(scope.symbol, scopetable) == False:\n",
    "                    self.scopetable.append(Scope(scope.symbol, scope.values, scope.symbolType, scopetable))\n",
    "\n",
    "    \n",
    "    def remove(self, symbol:string, value: BaseNode, symbolType: type) -> None:\n",
    "        # checks if the table is empty.\n",
    "        if len(self.scopetable) < 1:\n",
    "            return\n",
    "        \n",
    "        # iterates through and removes the corresponding \n",
    "        for scope in self.scopetable:\n",
    "            if scope.symbol == symbol:\n",
    "                if scope.insideTable == self:\n",
    "                    self.scopetable.remove(Scope(scope.symbol, scope.values, scope.symbolType, self)) \n",
    "    \n",
    "    def get_value(self, symbol: string, scopetable) -> tuple[bool, BaseNode]:\n",
    "        for scope in self.scopetable:\n",
    "            if scope.symbol == symbol:\n",
    "                if scope.insideTable == scopetable:\n",
    "                    return scope.getValue()\n",
    "        return False, None\n",
    "    \n",
    "    def get_scope(self, symbol:string):\n",
    "        for scope in self.scopetable:\n",
    "            if scope.symbol == symbol:\n",
    "                return True, scope\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symboltable: Name= y, Value= [[7]], type= TokenTypes.INT_TYPE and inside table=<__main__.ScopeTable object at 0x00000234FA769F50>\n",
      "Symboltable: Name= x, Value= [[4]], type= TokenTypes.INT_TYPE and inside table=<__main__.ScopeTable object at 0x00000234FA769E90>\n"
     ]
    }
   ],
   "source": [
    "table = ScopeTable()\n",
    "table.addScope(\"y\", [NumberNode(Token(TokenTypes.INTEGER, 7))], TokenTypes.INT_TYPE)\n",
    "\n",
    "table2 = ScopeTable()\n",
    "table2.addScope(\"x\", [NumberNode(Token(TokenTypes.INTEGER, 4))], TokenTypes.INT_TYPE)\n",
    "\n",
    "table.addScopeTable(table2)\n",
    "\n",
    "table.__info__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, lexer: lexicon):\n",
    "       self.logger: Logger = Console_Logger()\n",
    "       self.end = False\n",
    "       self.lexer = lexer\n",
    "       self.current_token = lexer.get_token(self.lexer.current_char)\n",
    "       self.scopetable = ScopeTable()\n",
    "       \n",
    "\n",
    "    def parse(self) -> BaseNode:     \n",
    "        node = self.program()\n",
    "        if node.hasSyntaxError or self.current_token.type != TokenTypes.EOF:\n",
    "            self.logger.__log_error__(\"it appears there was a problem\", ErrorType.SyntaxError)\n",
    "        return node.node\n",
    "       \n",
    "    #####################################\n",
    "    # statements\n",
    "    #####################################\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the program has either statements or function calls.\n",
    "    Rule => statement_list | func_decl (SEMI statement_list | func_decl)*?\n",
    "    \"\"\"\n",
    "    def program(self) -> ParsedNode:\n",
    "      \n",
    "\n",
    "         #node = self.func_decl()\n",
    "\n",
    "        # checks if start of the program is not a block but a function.\n",
    "        #if(node.hasSyntaxError == True):\n",
    "        #    self.set_to_token(index, token)\n",
    "        node = self.block()\n",
    "        \n",
    "        # checks if the program is not a function either.\n",
    "        if(node.hasSyntaxError == True):\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        nodes = node\n",
    "        \n",
    "        return ParsedNode(ProgramNode(nodes.node), False)\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the program has a list of statements.\n",
    "    Rule => statement_list\n",
    "    \"\"\"\n",
    "    def block(self) -> ParsedNode:\n",
    "        node = self.statement()\n",
    "        nodes = []\n",
    "        nodes.append(node)\n",
    "\n",
    "        if(node.hasSyntaxError==False):\n",
    "            if(self.current_token.type == TokenTypes.SEMICOLON):\n",
    "                while(self.current_token.type == TokenTypes.SEMICOLON):\n",
    "                    self.forward()\n",
    "                    node = self.statement()\n",
    "                    if node.hasSyntaxError:\n",
    "                        return ParsedNode(None,True)\n",
    "                    else: nodes.append(node)\n",
    "                return ParsedNode(BlockNode(nodes), False)\n",
    "        return node\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the current node is either an expression statemnts, if statement, for statement, a function call or an assignment statemnt.\n",
    "    Rule => expr | if | for | func_call | assign_statement\n",
    "    \"\"\"\n",
    "    def statement(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "\n",
    "        node: ParsedNode = self.nested_scope()\n",
    "\n",
    "        # checks if current node is not an expression.\n",
    "\n",
    "        if(node.hasSyntaxError == True):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.func_decl()\n",
    "\n",
    "        if(node.hasSyntaxError == True):\n",
    "             self.set_to_token(index,token)\n",
    "             node = self.flexible_eq()\n",
    "             \n",
    "        if(node.hasSyntaxError == True):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.expr()\n",
    "        \n",
    "     \n",
    "        \n",
    "        return node\n",
    "    \n",
    "    \"\"\"\n",
    "    Flexible Eq Statement (Used only to give something a value)\n",
    "    Rule -> (Identifier EQUAL expr)\n",
    "    \"\"\"\n",
    "    def flexible_eq(self)-> ParsedNode:\n",
    "        left_node = self.identifier()\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.current_token.type == TokenTypes.EQUAL):\n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "                right_node = self.expr()\n",
    "                if(right_node.hasSyntaxError == False):\n",
    "                    return ParsedNode(FlexibleEqNode(token,left_node,right_node), False)\n",
    "        return ParsedNode(None,True)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Rigid Eq Statement (Used only to check if two expr are equals)\n",
    "    Rule -> (expr (EQUAL expr)*?)\n",
    "    \"\"\"\n",
    "    def rigid_eq(self) -> ParsedNode:\n",
    "        left_node = self.block()\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.current_token.type == TokenTypes.EQUAL):\n",
    "                node = ParsedNode(None,True)\n",
    "                while self.current_token.type == TokenTypes.EQUAL:\n",
    "                    token = self.current_token\n",
    "                    self.forward()\n",
    "                    right_node = self.expr()\n",
    "                    if(right_node.hasSyntaxError == False):\n",
    "                        if(node.node == None):\n",
    "                                node = RigidEqNode(token,left_node.node,right_node.node)\n",
    "                        if(self.current_token.type == TokenTypes.EQUAL):\n",
    "                            node = RigidEqNode(token, node, right_node)\n",
    "                    else: return ParsedNode(None,True)\n",
    "                return ParsedNode(node,False)\n",
    "            return left_node\n",
    "        return ParsedNode(None,True)\n",
    "   \n",
    "  \n",
    "    \"\"\"\n",
    "    Checks for a function call.\n",
    "    Rule => IDENTIFIER LB (func_call_args)? RB \n",
    "    \"\"\"\n",
    "    def func_call(self) -> ParsedNode:\n",
    "         # RULE --> IDENTIFIER LB (func_call_param)? RB  NOT IMPLEMENTED\n",
    "        node = self.identifier()\n",
    "        if(node.hasSyntaxError):\n",
    "            return ParsedNode(None, True)  \n",
    "        if(self.current_token.type == TokenTypes.LBRACKET):\n",
    "            self.forward()\n",
    "            \n",
    "            # checks if it is an empty function call.\n",
    "            if self.current_token.type == TokenTypes.RBRACKET:\n",
    "                self.forward()\n",
    "                return ParsedNode(FuncCallNode(node, None), False)\n",
    "\n",
    "            params = self.func_call_args()\n",
    "            for param in params:\n",
    "                if param.hasSyntaxError:\n",
    "                    return ParsedNode(None, True)\n",
    "                \n",
    "            if(self.current_token.type == TokenTypes.RBRACKET):\n",
    "                self.forward()\n",
    "                return ParsedNode(FuncCallNode(node, params), False)\n",
    "                \n",
    "        return ParsedNode(None, True)\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    Checks for the arguments of the function call.\n",
    "    Rule => expr (COMMA expr)*?  \n",
    "    \"\"\"    \n",
    "    def func_call_args(self) -> list[ParsedNode]:\n",
    "        nodes = []\n",
    "        nodes.append(self.expr())\n",
    "\n",
    "        while True:\n",
    "            if(self.current_token.type == TokenTypes.COMMA):\n",
    "                self.forward()\n",
    "                nodes.append(self.expr())\n",
    "            else:\n",
    "                for node in nodes:\n",
    "                    if node.hasSyntaxError:\n",
    "                        return [ParsedNode(None, True)]\n",
    "                break\n",
    "        \n",
    "        return nodes\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Checks for the declaration of a function.\n",
    "    Rule => IDENTIFIER LB func_dec_param RB (COLON type)? BINDING block\n",
    "           |IDENTIFIER BINDING LB nested_scope LAMBDA expr RB    \n",
    "    \"\"\"\n",
    "    def func_decl(self) -> ParsedNode:\n",
    "        identifier = self.identifier()\n",
    "        if identifier.hasSyntaxError == False:\n",
    "\n",
    "            if self.current_token.type == TokenTypes.LBRACKET:\n",
    "                self.forward()\n",
    "\n",
    "                params = self.func_decl_param()\n",
    "\n",
    "                if self.current_token.type == TokenTypes.RBRACKET:\n",
    "                    self.forward()\n",
    "                    type = None\n",
    "                    if(self.current_token.type == TokenTypes.COLON):\n",
    "                        self.forward()\n",
    "                        type = self.type()\n",
    "                        if(type.hasSyntaxError):\n",
    "                            return ParsedNode(None,True)\n",
    "                        \n",
    "                    if self.current_token.type == TokenTypes.BINDING:\n",
    "                        self.forward()\n",
    "                        block = self.expr()\n",
    "                        if(block.hasSyntaxError == False):\n",
    "                            return ParsedNode(FuncDeclNode(identifier,params,False,type,block),False)\n",
    "                return ParsedNode(None,True)\n",
    "            \n",
    "            if self.current_token.type == TokenTypes.BINDING:\n",
    "                self.forward()\n",
    "                if self.current_token.type == TokenTypes.LBRACKET:\n",
    "                    self.forward()\n",
    "                    type = None\n",
    "                    params = self.func_decl_param()\n",
    "                    if(params.hasSyntaxError):\n",
    "                        return ParsedNode(None,True)\n",
    "                    \n",
    "                    if self.current_token.type == TokenTypes.LAMBDA:\n",
    "                        self.forward()                   \n",
    "                        block = self.expr()\n",
    "                        if(block.hasSyntaxError == False and self.current_token.type == TokenTypes.RBRACKET):\n",
    "                            self.forward()\n",
    "                            return ParsedNode(FuncDeclNode(identifier,params,True,type,block),False)\n",
    "                    return ParsedNode(None,True)\n",
    "\n",
    "        return ParsedNode(None,True)\n",
    "\n",
    "    \"\"\"\n",
    "    Checks for the arguments of the function declaration.\n",
    "    Rule => nested_scope\n",
    "    \"\"\"\n",
    "    def func_decl_param(self) -> ParsedNode:\n",
    "        nodes:list[ScopeNode] = []\n",
    "        if(self.current_token.type == TokenTypes.RBRACKET):\n",
    "            return ParsedNode(ParamsNode(nodes),False)\n",
    "        \n",
    "        node = self.scope()\n",
    "        if(node.hasSyntaxError == False):\n",
    "            nodes.append(node.node)\n",
    "            while(self.current_token.type == TokenTypes.COMMA):\n",
    "                self.forward()\n",
    "                node = self.scope()\n",
    "                if(node.hasSyntaxError):\n",
    "                    return ParsedNode(None,True)\n",
    "                nodes.append(node.node)\n",
    "            return ParsedNode(ParamsNode(nodes),False)\n",
    "        return ParsedNode(None,True)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the statement is an if statement.\n",
    "    Rule => IF LB expr RB THEN CBL block CBR ELSE CBL block CBR\n",
    "          | IF LB expr RB THEN expr ELSE expr  \n",
    "    \"\"\"\n",
    "    def if_statement(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "\n",
    "        if token.type != TokenTypes.IF:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        if self.current_token.type != TokenTypes.LBRACKET:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        if_node = self.rigid_eq()\n",
    "        if if_node.hasSyntaxError == True or self.current_token.type != TokenTypes.RBRACKET:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        if self.current_token.type != TokenTypes.THEN:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "\n",
    "        hasCB:bool = self.current_token.type == TokenTypes.CBL\n",
    "        then_node = ParsedNode(None,True)\n",
    "        else_node = ParsedNode(None,True)\n",
    "\n",
    "        if(hasCB):\n",
    "            self.forward()\n",
    "            then_node = self.block()\n",
    "            if(then_node.hasSyntaxError):\n",
    "                return ParsedNode(None,True)\n",
    "            if(self.current_token.type == TokenTypes.CBR):\n",
    "                self.forward()\n",
    "            else: return ParsedNode(None,True)\n",
    "        else:\n",
    "            then_node = self.expr()\n",
    "            if(then_node.hasSyntaxError):\n",
    "                return ParsedNode(None,True)\n",
    "            \n",
    "        if self.current_token.type != TokenTypes.ELSE:\n",
    "            return ParsedNode(None, True)     \n",
    "        self.forward()\n",
    "\n",
    "        if(hasCB and self.current_token.type == TokenTypes.CBL):\n",
    "            self.forward()\n",
    "            else_node = self.block()\n",
    "            if(else_node.hasSyntaxError):\n",
    "                return ParsedNode(None,True)\n",
    "            if(self.current_token.type == TokenTypes.CBR):\n",
    "                self.forward()\n",
    "            else: return ParsedNode(None,True)\n",
    "        else:\n",
    "            else_node = self.expr()\n",
    "            if(else_node.hasSyntaxError):\n",
    "                return ParsedNode(None,True)\n",
    "            \n",
    "        return ParsedNode(IfNode(token, if_node.node, then_node.node, else_node.node),False)\n",
    "       \n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the statement is a loop expression.\n",
    "    Rule => FOR CBL (scope|expr) (;expr)*? CBR\n",
    "          | FOR LB (scope|expr) (,expr)*? RB DO expr\n",
    "    \"\"\"\n",
    "    def for_loop(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "\n",
    "        if token.type != TokenTypes.FOR:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        # checks if the for loop is defined with a curly bracket.\n",
    "        if self.current_token.type == TokenTypes.CBL:\n",
    "            self.forward()\n",
    "            return self.for_loop_curly()\n",
    "        elif self.current_token.type == TokenTypes.LBRACKET:\n",
    "            self.forward()\n",
    "            return self.for_loop_bracket()\n",
    "\n",
    "        return ParsedNode(None, True)\n",
    "            \n",
    "    \n",
    "    def for_loop_curly(self) -> ParsedNode:\n",
    "        condition: ParsedNode\n",
    "        expression: ParsedNode\n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "\n",
    "        node = self.scope()\n",
    "\n",
    "        # checks if the loop content is not a scope but an expression.\n",
    "        if node.hasSyntaxError == True:\n",
    "            self.set_to_token(index, token)\n",
    "            node = self.expr()\n",
    "        \n",
    "        # checks if the loop input is invalid.\n",
    "        if node.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        if self.current_token.type == TokenTypes.CBR:\n",
    "            self.forward()\n",
    "            return ParsedNode(ForNode(TokenTypes.FOR, node=node.node, condition=None, expr=None, do=None), False)\n",
    "        \n",
    "        self.forward()\n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "        condition = self.flexible_eq()\n",
    "\n",
    "        if(condition.hasSyntaxError == True):\n",
    "            self.set_to_token(index,token)\n",
    "            condition = self.expr()\n",
    "\n",
    "        if condition.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "\n",
    "        if self.current_token.type == TokenTypes.SEMICOLON:\n",
    "            self.forward()\n",
    "            token = self.current_token\n",
    "            index = self.lexer.index\n",
    "            expression = self.flexible_eq()\n",
    "\n",
    "            if(expression.hasSyntaxError == True):\n",
    "                self.set_to_token(index,token)\n",
    "                expression = self.expr()\n",
    "        \n",
    "            if self.current_token.type != TokenTypes.CBR or expression.hasSyntaxError:\n",
    "                return ParsedNode(None, True)\n",
    "\n",
    "            self.forward()\n",
    "            return ParsedNode(ForNode(TokenTypes.FOR, node=node.node, condition=condition.node, expr=expression.node, do=None),False)\n",
    "        \n",
    "        if self.current_token.type == TokenTypes.CBR:\n",
    "            self.forward()\n",
    "            return ParsedNode(ForNode(TokenTypes.FOR, node=node.node, condition=None, expr=condition.node, do=None), False)\n",
    "        \n",
    "        return ParsedNode(None, True)\n",
    "    \n",
    "    def for_loop_bracket(self) -> ParsedNode:\n",
    "        condition: ParsedNode\n",
    "        expression: ParsedNode\n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "\n",
    "        node = self.scope()\n",
    "\n",
    "        # checks if the loop content is not a scope but an expression.\n",
    "        if node.hasSyntaxError == True:\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.expr()\n",
    "        \n",
    "        # checks if the loop input is invalid.\n",
    "        if node.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        if self.current_token == TokenTypes.RBRACKET:\n",
    "            self.forward()\n",
    "            return ParsedNode(ForNode(TokenTypes.FOR, node=node.node, condition=None, expr=None, do=None), False)\n",
    "        \n",
    "        self.forward()\n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "        condition = self.flexible_eq()\n",
    "\n",
    "        if(condition.hasSyntaxError == True):\n",
    "            self.set_to_token(index,token)\n",
    "            condition = self.expr()\n",
    "\n",
    "        if condition.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "\n",
    "        if self.current_token.type == TokenTypes.SEMICOLON:\n",
    "            self.forward()\n",
    "            token = self.current_token\n",
    "            index = self.lexer.index\n",
    "            expression = self.flexible_eq()\n",
    "\n",
    "            if(expression.hasSyntaxError == True):\n",
    "                self.set_to_token(index,token)\n",
    "                expression = self.expr()\n",
    "        \n",
    "            if self.current_token.type != TokenTypes.RBRACKET or expression.hasSyntaxError:\n",
    "                return ParsedNode(None, True)\n",
    "        \n",
    "            self.forward()\n",
    "            if self.current_token.type != TokenTypes.DO:\n",
    "                return ParsedNode(None, True)\n",
    "        \n",
    "            self.forward()\n",
    "            do = self.expr()\n",
    "        \n",
    "            if do.hasSyntaxError:\n",
    "                return ParsedNode(None, True)\n",
    "            \n",
    "            return ParsedNode(ForNode(token, node=node.node, condition=condition.node, expr=expression.node, do=do.node), False)\n",
    "        \n",
    "        if self.current_token.type != TokenTypes.RBRACKET:\n",
    "                return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        if self.current_token.type != TokenTypes.DO:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        do = self.expr()\n",
    "        \n",
    "        if do.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "            \n",
    "        return ParsedNode(ForNode(token, node=node.node, condition=None, expr=condition.node, do=do.node), False)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the statement is a nested scope.\n",
    "    Rule =>  (Identifier COMMA Identifier)* COLON TYPE\n",
    "    \"\"\"\n",
    "    def nested_scope(self) -> ParsedNode:\n",
    "        nodes: list[ParsedNode] = []\n",
    "        nodes.append(self.identifier())\n",
    "\n",
    "        if nodes[0].hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "            \n",
    "        hasComma:bool = False\n",
    "        while True:        \n",
    "            if self.current_token.type == TokenTypes.COMMA:\n",
    "                hasComma = True\n",
    "                self.forward()\n",
    "                nodes.append(self.identifier())\n",
    "            else:\n",
    "                for node in nodes:\n",
    "                    if node.hasSyntaxError:\n",
    "                        return ParsedNode(None, True)\n",
    "                break\n",
    "        \n",
    "        if hasComma == False or self.current_token.type != TokenTypes.COLON:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        type = self.type()\n",
    "\n",
    "        if type.hasSyntaxError == True:\n",
    "            return ParsedNode(None, True)\n",
    "\n",
    "        return ParsedNode(ScopeNode(TokenTypes.COLON, nodes, type), False)\n",
    "        \n",
    "        \n",
    "\n",
    "    #####################################\n",
    "    # expressions\n",
    "    #####################################\n",
    "\n",
    "    def expr(self) -> ParsedNode:         \n",
    "        leftNode = self.choice()\n",
    "\n",
    "        if leftNode.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "\n",
    "        if self.current_token.type != TokenTypes.DOT:\n",
    "            return leftNode\n",
    "        \n",
    "        self.forward()\n",
    "        if self.current_token.type != TokenTypes.DOT:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        token = self.current_token\n",
    "        self.forward()\n",
    "        rightNode = self.choice()\n",
    "\n",
    "        if rightNode.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "\n",
    "        return ParsedNode(OperatorNode(token, leftNode.node, rightNode.node), False)\n",
    "    \n",
    "    def choice(self):\n",
    "        node = self.operation()\n",
    "        token = self.current_token\n",
    "\n",
    "        nodes:list[BaseNode] = []\n",
    "     \n",
    "        if(node.hasSyntaxError==False and self.current_token.type == TokenTypes.CHOICE):\n",
    "                nodes.append(node.node)\n",
    "                while(self.current_token.type == TokenTypes.CHOICE):\n",
    "                    token = self.current_token\n",
    "                    self.forward()\n",
    "                    node = self.operation()\n",
    "                    if(node.hasSyntaxError==False):\n",
    "                        nodes.append(node.node)\n",
    "                    else: return ParsedNode(None,True)\n",
    "                return ParsedNode(ChoiceSequenceNode(token,nodes), False)\n",
    "        return node\n",
    "    \n",
    "    \"\"\"\n",
    "    This method checks if a token any of the following operations: =, <, >, <=, >=, |, +, -\n",
    "    Since all of this operations have the same priority and same values output, it is not needed to write them in different methods\n",
    "    \"\"\"\n",
    "    def operation(self):\n",
    "          # RULE --> op: term ((GT|LT|GE|LE|EQUAL|CHOICE|PLUS|MINUS) term)*\n",
    "\n",
    "        left_node = self.term()\n",
    "\n",
    "        # Checks if left node has been received and if the following token is one of the following tokens: : =, <, >, <=, >=, |, +, -\n",
    "\n",
    "        if(left_node.hasSyntaxError == False and (self.check_type(self.current_token.type,\n",
    "                [TokenTypes.GREATER,TokenTypes.GREATEREQ,TokenTypes.LOWER,TokenTypes.LOWEREQ, TokenTypes.PLUS,\n",
    "                TokenTypes.MINUS]))):\n",
    "\n",
    "                node = ParsedNode(None,True)\n",
    "                \n",
    "                # The while method \"concatenates\" the operations\n",
    "\n",
    "                while(self.check_type(self.current_token.type,\n",
    "                [TokenTypes.GREATER,TokenTypes.GREATEREQ,TokenTypes.LOWER,TokenTypes.LOWEREQ, TokenTypes.PLUS,\n",
    "                TokenTypes.MINUS])):\n",
    "                \n",
    "                    token = self.current_token\n",
    "                    self.forward()\n",
    "                    right_node = self.term()\n",
    "                    if(right_node.hasSyntaxError):\n",
    "                        return right_node\n",
    "                    \n",
    "                    # Binds found operation to its left node\n",
    "                    if(node.node == None):\n",
    "                       node = ParsedNode(OperatorNode(token,left_node.node,right_node.node),False)\n",
    "                    else: node = ParsedNode(OperatorNode(token,node.node,right_node.node),False)\n",
    "                return node\n",
    "        return left_node\n",
    "\n",
    "    \"\"\"\n",
    "    Checks the same way in operation method but here it checks for *, /\n",
    "    \"\"\"\n",
    "    def term(self) -> ParsedNode:\n",
    "        # RULE --> factor ((MUL|DIV) factor)*\n",
    "        \n",
    "        left_node = self.factor() \n",
    "\n",
    "        if(left_node.hasSyntaxError == False and (self.check_type(self.current_token.type,[TokenTypes.MULTIPLY, TokenTypes.DIVIDE]))):\n",
    "            node = ParsedNode(None,True)\n",
    "\n",
    "             # The while method \"concatenates\" the operations\n",
    "            while(self.check_type(self.current_token.type,[TokenTypes.MULTIPLY, TokenTypes.DIVIDE])):\n",
    "               \n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "                right_node = self.factor()\n",
    "                if(right_node.hasSyntaxError):\n",
    "                    return right_node\n",
    "                \n",
    "                # Binds found operation to its left node\n",
    "                if(node.node == None):\n",
    "                  node = ParsedNode(OperatorNode(token,left_node.node,right_node.node),False)\n",
    "                else: node = ParsedNode(OperatorNode(token,node.node,right_node.node),False)\n",
    "            return node\n",
    "        return left_node\n",
    "    \n",
    "    \"\"\"\n",
    "    Checks for unary operations, Integers, brackets (highest priority)\n",
    "    RULE -->  INTEGER  \n",
    "        : brackets\n",
    "        : (MINUS|PLUS) arith\n",
    "        : func_call x() x\n",
    "        : indexing     NOT IMPLEMENTING\n",
    "        : --> means the same as (brackets|unary|func_call) just like in operation()\n",
    "        only that for each if a different Node may be created not such as only OperationNode like in operation()\n",
    "    \"\"\"\n",
    "    def factor(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "\n",
    "        #Integer check\n",
    "        if(token.type == TokenTypes.INTEGER):\n",
    "            self.forward()\n",
    "            return ParsedNode(NumberNode(token),False)\n",
    "        \n",
    "        if(token.type == TokenTypes.FAIL):\n",
    "            self.forward()\n",
    "            return ParsedNode(FailNode(token),False)\n",
    "        \n",
    "        #Unary operation check\n",
    "        if(self.check_type(self.current_token.type,[TokenTypes.PLUS, TokenTypes.MINUS])):\n",
    "            self.forward()\n",
    "            node = self.operation()\n",
    "            if(node.hasSyntaxError):        # (--) --> Error needs (-- expr) or (--3)\n",
    "                return ParsedNode(None, True)\n",
    "            return ParsedNode(UnaryNode(token,node.node),False)\n",
    "        \n",
    "        #brackets check\n",
    "        node = self.brackets()\n",
    "\n",
    "        #if node has failed check for loop\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.indexing()\n",
    "\n",
    "        #if node has failed check for loop\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.scope()\n",
    "\n",
    "         #if node has failed check for loop\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.binding()\n",
    "\n",
    "        #if node has failed check indexing\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.func_call()\n",
    "        \n",
    "        #if node has failed check for loop\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.for_loop()\n",
    "\n",
    "        #if node has failed check if statement\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.if_statement()\n",
    "        \n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.sequence()\n",
    "            \n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.identifier()\n",
    "        return node\n",
    "    \n",
    "    \"\"\"\n",
    "    Checks for brackets (highest priority)\n",
    "    RULE --> brackets: LB expr RB\n",
    "    \"\"\"\n",
    "    def brackets(self) -> ParsedNode: \n",
    "        if(self.current_token.type == TokenTypes.LBRACKET):\n",
    "            self.forward()\n",
    "            node = self.block()\n",
    "        \n",
    "            if(self.current_token.type == TokenTypes.RBRACKET):\n",
    "                self.forward()\n",
    "                return node\n",
    "        return ParsedNode(None,True)\n",
    "        \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    y := 8 y:=(x:int)  y:= method(...)...\n",
    "    RULE --> scope BINDING expr\n",
    "    \"\"\"\n",
    "    def binding(self) -> ParsedNode:\n",
    "        left_node = self.identifier()\n",
    "\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.check_type(self.current_token.type,[TokenTypes.BINDING])):\n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "                right_node = self.expr()\n",
    "                if(right_node.hasSyntaxError == False):\n",
    "                    return ParsedNode(BindingNode(token,left_node.node,right_node.node), False)\n",
    "                else: return ParsedNode(None,True)\n",
    "        return ParsedNode(None,True)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    x:int\n",
    "    RULE --> identifier COLON type \n",
    "    \"\"\"\n",
    "    def scope(self) -> ParsedNode:\n",
    "        left_node = self.identifier()\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.check_type(self.current_token.type,[TokenTypes.COLON])):\n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "                type = self.type()\n",
    "                if(type.hasSyntaxError == False):\n",
    "                    return ParsedNode(ScopeNode(token,[left_node.node],type.node),False) # Return Scope Node\n",
    "                else: return ParsedNode(None,True)\n",
    "        return ParsedNode(None,True)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    variable/method name\n",
    "    RULE --> identifier            NEED UPDATE\n",
    "    \"\"\"\n",
    "    def identifier(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "        if(token.type == TokenTypes.IDENTIFIER):\n",
    "            self.forward()\n",
    "            return ParsedNode(IdentifierNode(token), False)\n",
    "        return ParsedNode(None, True) \n",
    "        \n",
    "    \"\"\"\n",
    "    int or tuple(int,int) or array{int}\n",
    "    RULE -->  INT                        \n",
    "            : TUPLE LB type (,type)* RB \n",
    "    \"\"\"\n",
    "    def type(self) -> ParsedNode:\n",
    "        # RULE -->  INT                        \n",
    "        #        : TUPLE LB type (,type)* RB    \n",
    "\n",
    "        token = self.current_token\n",
    "        if(token.type == TokenTypes.INT_TYPE):\n",
    "            self.forward()\n",
    "            return ParsedNode(TypeNode(token),False)\n",
    "        \n",
    "        if(token.type == TokenTypes.TUPLE_TYPE):\n",
    "            self.forward()\n",
    "            if(self.current_token.type == TokenTypes.LBRACKET):\n",
    "                self.forward()\n",
    "                types:list[TypeNode] = []\n",
    "\n",
    "                type = self.type()\n",
    "                if(type.hasSyntaxError == False):\n",
    "                    types.append(type.node)\n",
    "                    if(self.check_type(self.current_token.type, [TokenTypes.COMMA])):\n",
    "                        while(self.current_token.type == TokenTypes.COMMA):\n",
    "\n",
    "                            self.forward()\n",
    "                            t = self.type()\n",
    "\n",
    "                            if(t.hasSyntaxError):  #If on error\n",
    "                                return ParsedNode(None,True)\n",
    "                            types.append(t.node) #else append to list of types\n",
    "                     \n",
    "            if(self.current_token.type == TokenTypes.RBRACKET):  \n",
    "                self.forward()\n",
    "                return ParsedNode(SequenceTypeNode(TokenTypes.TUPLE_TYPE,types), False)\n",
    "            \n",
    "        return ParsedNode(None, True) \n",
    "        \n",
    "    \"\"\"\n",
    "    a[i:int]\n",
    "    # RULE --> identifier SBL expr SBR\n",
    "    \"\"\"\n",
    "    def indexing(self) -> ParsedNode:\n",
    "        left_node = self.identifier()\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.current_token.type == TokenTypes.SBL):\n",
    "                self.forward()\n",
    "                expr_node = self.expr()\n",
    "          \n",
    "                if(expr_node.hasSyntaxError == False and self.current_token.type == TokenTypes.SBR):\n",
    "                     self.forward()\n",
    "                     return ParsedNode(IndexingNode(left_node.node.token,left_node.node,expr_node.node),False)\n",
    "                return ParsedNode(None,True)\n",
    "        return ParsedNode(None,True)\n",
    "    \n",
    "    \"\"\"\n",
    "    RUKE --> LB (expr COMMA expr)* RB                  --> tuple (n1,...)\n",
    "             array CBL expr (COMMA expr)*? CBR         --> long-form syntax and singleton tuple/array array{n1} oder array{n1,...}\n",
    "    \"\"\"\n",
    "    def sequence(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "\n",
    "        nodes:list[BaseNode] = []\n",
    "\n",
    "        # Tuple\n",
    "        if(token.type == TokenTypes.LBRACKET):\n",
    "            self.forward()\n",
    "            node = self.expr()\n",
    "            if(node.hasSyntaxError==False):\n",
    "                nodes.append(node.node)\n",
    "                while(self.current_token.type == TokenTypes.COMMA):\n",
    "                    self.forward()\n",
    "                    node = self.expr()\n",
    "                    if(node.hasSyntaxError==False):\n",
    "                        nodes.append(node.node)\n",
    "                    else: return ParsedNode(None,True)\n",
    "                if(len(nodes) > 1 and self.current_token.type == TokenTypes.RBRACKET):\n",
    "                    self.forward()\n",
    "                    return ParsedNode(SequenceNode(Token(TokenTypes.TUPLE_TYPE,TokenTypes.TUPLE_TYPE.value),nodes), False)\n",
    "\n",
    "\n",
    "        # Array\n",
    "        if(token.type == TokenTypes.ARRAY_TYPE):\n",
    "                self.forward()\n",
    "                if(self.current_token.type == TokenTypes.CBL):\n",
    "                    self.forward()\n",
    "                    node = self.expr()\n",
    "                    if(node.hasSyntaxError == False):\n",
    "                        nodes.append(node.node)\n",
    "                        while(self.current_token.type == TokenTypes.COMMA):\n",
    "                              self.forward()\n",
    "                              node = self.expr()\n",
    "                              if(node.hasSyntaxError==False):\n",
    "                                nodes.append(node.node)\n",
    "                              else: return ParsedNode(None,True)\n",
    "                        if(self.current_token.type == TokenTypes.CBR):\n",
    "                            self.forward()\n",
    "                            return ParsedNode(SequenceNode(Token(TokenTypes.TUPLE_TYPE,TokenTypes.TUPLE_TYPE.value),nodes), False)\n",
    "                        \n",
    "        return ParsedNode(None, True)\n",
    "                \n",
    "\n",
    "    \"\"\"\n",
    "    Moves forward in the tokens list\n",
    "    \"\"\"\n",
    "    def forward(self) -> None:\n",
    "        print(self.current_token.__info__())\n",
    "        self.lexer.forward()\n",
    "        self.current_token = lexer.get_token(self.lexer.current_char)\n",
    "        if self.current_token.type == TokenTypes.EOF:\n",
    "            self.end = True\n",
    "        \n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    Checks if a type exists in the following types list\n",
    "    \"\"\"\n",
    "    def check_type(self,type:TokenTypes,types:list[TokenTypes]) -> bool:\n",
    "        return type in types\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Sets current token back if a certain path lead to failure (Wrong syntax)\n",
    "    May need it for later\n",
    "    \"\"\"\n",
    "    def set_to_token(self,index, token): \n",
    "        self.current_token = token\n",
    "        self.lexer.index = index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 418 (2870167013.py, line 422)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[157], line 422\u001b[1;36m\u001b[0m\n\u001b[1;33m    '''\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 418\n"
     ]
    }
   ],
   "source": [
    "class Interpreter:\n",
    "    def __init__(self, parser: Parser):\n",
    "        self.parser = parser\n",
    "        self.scopetable = ScopeTable()\n",
    "        self.current_scopetable = self.scopetable\n",
    "\n",
    "    def interpret(self):\n",
    "        tree = self.parser.parse()\n",
    "        if tree != None:\n",
    "            return self.visit(tree)\n",
    "    \n",
    "    def visit(self, node):\n",
    "        if isinstance(node, ProgramNode):\n",
    "                return self.visit_programNode(node)\n",
    "        elif isinstance(node, BlockNode):\n",
    "                return self.visit_blockNode(node)\n",
    "        elif isinstance(node, ScopeNode):\n",
    "                return self.visit_scopeNode(node)\n",
    "        elif isinstance(node, BindingNode):\n",
    "                return self.visit_bindingNode(node)\n",
    "        elif isinstance(node, OperatorNode):\n",
    "                return self.visit_operatorNode(node)\n",
    "        elif isinstance(node, NumberNode):\n",
    "                return self.visit_numberNode(node)\n",
    "        elif isinstance(node, UnaryNode):\n",
    "                return self.visit_unaryNode(node)\n",
    "        elif isinstance(node, IdentifierNode):\n",
    "                return self.visit_identifierNode(node)\n",
    "        elif isinstance(node, TypeNode):\n",
    "                return self.visit_typeNode(node)\n",
    "        elif isinstance(node, SequenceTypeNode):\n",
    "                return self.visit_typeNodeSequence(node)\n",
    "        elif isinstance(node, FuncCallNode):\n",
    "                return self.visit_funcCallNode(node)\n",
    "        elif isinstance(node, ParamsNode):\n",
    "                return self.visit_paramsNode(node)\n",
    "        elif isinstance(node, FuncDeclNode):\n",
    "                return self.visit_funcDeclNode(node)\n",
    "        elif isinstance(node, ForNode):\n",
    "            return self.visit_forNode(node)\n",
    "        elif isinstance(node, IfNode):\n",
    "            return self.visit_ifNode(node)\n",
    "        elif isinstance(node, RigidEqNode):\n",
    "                return self.visit_rigidEqNode(node)\n",
    "        elif isinstance(node, FlexibleEqNode):\n",
    "                return self.visit_flexibleEqNode(node)\n",
    "        elif isinstance(node, SequenceNode):\n",
    "                return self.visit_sequenceNode(node)\n",
    "        elif isinstance(node, ChoiceSequenceNode):\n",
    "            return self.visit_choiceSequenceNode(node)\n",
    "        elif isinstance(node, IndexingNode):\n",
    "                return self.visit_indexingNode(node)\n",
    "        elif isinstance(node, ParsedNode):\n",
    "                return self.visit(node.node)\n",
    "        elif isinstance(node, FailNode):\n",
    "                return self.visit_failNode(node)\n",
    "    \n",
    "    def visit_programNode(self, node: ProgramNode):\n",
    "        return self.visit(node.node)\n",
    "\n",
    "    def visit_blockNode(self, node: BlockNode):\n",
    "        results = []\n",
    "        for n in node.nodes:\n",
    "            result = self.visit(n)\n",
    "            if result != None:\n",
    "                 results.append(result)\n",
    "\n",
    "        '''\n",
    "        HIER GEÄNDERT Block Node, darf nur ein Value liefern.\n",
    "        Bsp. y:= (31|(z:=9; z)); x:=(7|22); (x,y)\n",
    "        wenn er in diesem Block (z:=9; z) die liste übergibt kommt es später zu einem error.\n",
    "        Er muss das z zurückgeben, sprich Ein resultat vom Block. \n",
    "        '''\n",
    "        \n",
    "        return results[len(results)-1]\n",
    "\n",
    "    def visit_scopeNode(self, node: ScopeNode):\n",
    "        for n in node.nodes:\n",
    "            self.current_scopetable.addScope(n.token.value, None, self.visit(node.type))\n",
    "\n",
    "    def visit_bindingNode(self, node: BindingNode):\n",
    "        self.current_scopetable.addScope(node.leftNode.token.value, node.rightNode, None)\n",
    "        \n",
    "\n",
    "    def visit_numberNode(self, node):\n",
    "        return NumberNode(node.token)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Operators: +, *, -, /, <, >, <=, >=.\n",
    "\n",
    "    Fail condition on using following nodes for any \n",
    "    of the above listed operations: FaileNode, SequenceNodes (Except choices).\n",
    "\n",
    "    Operator node, checks its left and right node by visiting it.\n",
    "    Then in the sequentor it get combination if there is or are many choices\n",
    "    in the left and right node. Iterates the sequences received by the sequentor and\n",
    "    return a new node number node or choice node.\n",
    "    '''\n",
    "    def visit_operatorNode(self, node):\n",
    "\n",
    "        fail_conditions = [TokenTypes.FAIL, TokenTypes.TUPLE_TYPE, TokenTypes.ARRAY_TYPE]\n",
    "\n",
    "\n",
    "        node_left = self.visit(node.leftNode)\n",
    "        if node_left.token.type in fail_conditions:\n",
    "                return FailNode(Token(TokenTypes.FAIL, TokenTypes.FAIL.value))\n",
    "       \n",
    "        node_right = self.visit(node.rightNode)\n",
    "        if node_right.token.type in fail_conditions:\n",
    "                 return FailNode(Token(TokenTypes.FAIL, TokenTypes.FAIL.value))\n",
    "\n",
    "        sequentor = Sequentor([node_left,node_right])\n",
    "        seqences = sequentor.getSequences()\n",
    "\n",
    "        # If lenght is one, it can only be two integers.\n",
    "        if len(seqences) == 1:\n",
    "            return self.doOperation(seqences[0][0].value,seqences[0][1].value, node.token)\n",
    "        \n",
    "        # Else left or/and right node of operation had to be a choice.\n",
    "        nodes = []\n",
    "        for s in seqences:\n",
    "            left_val = s[0]\n",
    "            right_val = s[1]\n",
    "\n",
    "            '''\n",
    "            Checks if left_val or right_val (nodes) are valid for the operation.\n",
    "            If node save fail node in nodes\n",
    "            '''\n",
    "            if (left_val.token.type in fail_conditions) or (right_val.token.type in fail_conditions):\n",
    "                nodes.append( FailNode(Token(TokenTypes.FAIL, TokenTypes.FAIL.value)))\n",
    "           \n",
    "            # Else save vale of done operation of left_val and right_val (nodes) into the nodes list.\n",
    "            else: nodes.append(self.doOperation(left_val.value,right_val.value, node.token))\n",
    "\n",
    "        # creates the choice\n",
    "        choice = ChoiceSequenceNode(Token(TokenTypes.CHOICE,TokenTypes.CHOICE.value), nodes)\n",
    "\n",
    "        '''\n",
    "        Last visit if choice contains for example (false?|false?).\n",
    "        in the choice visit method it returns only the values without the false?.\n",
    "        If there are no valid nodes/values in the choice sequence, it return FailNode.\n",
    "        ''' \n",
    "        return self.visit(choice)\n",
    "\n",
    "\n",
    "    '''\n",
    "    Does any of the following operations in the match case\n",
    "    for two values and returns a new node.\n",
    "    '''\n",
    "    def doOperation(self,val1:int,val2:int, token:Token):\n",
    "        result = 0\n",
    "        match token.type:\n",
    "            case TokenTypes.DIVIDE:\n",
    "                result = val1 // val2\n",
    "            case TokenTypes.MULTIPLY:\n",
    "                result = val1 * val2\n",
    "            case TokenTypes.PLUS:              \n",
    "                result = val1 + val2\n",
    "            case TokenTypes.MINUS:\n",
    "                result = val1 - val2      \n",
    "            case TokenTypes.GREATER:\n",
    "                if val1 > val2:\n",
    "                    result = val1\n",
    "                else: return FailNode(Token(TokenTypes.FAIL, TokenTypes.FAIL.value)) \n",
    "            case TokenTypes.LOWER:\n",
    "                if val1:\n",
    "                    result = val1\n",
    "                else: return FailNode(Token(TokenTypes.FAIL, TokenTypes.FAIL.value)) \n",
    "        return  NumberNode(Token(TokenTypes.INTEGER, result))  \n",
    "    \n",
    "    '''\n",
    "    If unary node is called, it calls visitor operator in following way:\n",
    "    creates multiplication operator node containg -1 and its val it has to multiply.\n",
    "    '''\n",
    "    def visit_unaryNode(self, node):\n",
    "\n",
    "        mul:int = 1\n",
    "        if node.token.type == TokenTypes.MINUS:\n",
    "            mul = -1\n",
    "        return self.visit_operatorNode(OperatorNode(Token(TokenTypes.MULTIPLY, TokenTypes.MULTIPLY.value),\n",
    "                                                 NumberNode(Token(TokenTypes.INTEGER,mul)),node.node))\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def visit_identifierNode(self, node: IdentifierNode):\n",
    "        # checks if the identifier already exists in the scopetable.\n",
    "        for scope in self.current_scopetable.scopetable:\n",
    "             if scope.symbol == node.token.value and scope.values != None:\n",
    "                val = scope.getValue()\n",
    "                return val[1] # Returns value\n",
    "        return node # Else return not assigned\n",
    "\n",
    "    def visit_typeNode(self, node: TypeNode):\n",
    "        return node.token.type\n",
    "\n",
    "    def visit_typeNodeSequence(self, node: SequenceTypeNode):\n",
    "        result = []\n",
    "        for n in node.types:\n",
    "            result.append(self.visit(n))\n",
    "        return result\n",
    "\n",
    "    def visit_funcCallNode(self, node: FuncCallNode):\n",
    "        identifier = self.visit(node.identifier).token.value # Wegen ParsedNode\n",
    "\n",
    "        # exists = self.check_if_exists(identifier)\n",
    "        table = ScopeTable()\n",
    "        for scope in self.current_scopetable.scopetable:\n",
    "            if scope.symbol == identifier:\n",
    "\n",
    "                func_dec = copy.deepcopy(scope.values[0])  # Need to change\n",
    "                func_dec_nodes = self.visit(func_dec.nodes).nodes # params\n",
    "\n",
    "                if len(func_dec_nodes) == len(node.args):\n",
    "                    index = 0\n",
    "\n",
    "                    for arg in node.args: # Sets args values to scopes in params\n",
    "                      param = func_dec_nodes[index]\n",
    "                      table.addScope(param.nodes[0].token.value,arg,param.type)\n",
    "                      index += 1\n",
    "\n",
    "                self.current_scopetable = table\n",
    "                val = self.visit(func_dec.block)     \n",
    "                self.current_scopetable = self.scopetable  \n",
    "                return val\n",
    "                    \n",
    "\n",
    "       \n",
    "        \n",
    "\n",
    "    def visit_paramsNode(self, node: ParamsNode):\n",
    "        return node\n",
    "         \n",
    "\n",
    "    def visit_funcDeclNode(self, node: FuncDeclNode):\n",
    "        # f(p:int,q:int):int := p + q; f(1,2)\n",
    "        identifier = self.visit(node.identifier).token.value\n",
    "        symbol = identifier.token.value\n",
    "\n",
    "        self.current_scopetable.addScope(symbol, node, node.type)\n",
    "        \n",
    "    \n",
    "    def visit_forNode(self, node: ForNode):\n",
    "        if node.condition == None and node.expr == None and node.do == None:\n",
    "            return self.visit(node.node)\n",
    "        visitted_node = self.visit(node.node)\n",
    "        \n",
    "        if node.condition != None:\n",
    "            visitted_condition = self.visit(node.condition)\n",
    "\n",
    "        if node.expr != None:\n",
    "            visitted_expr = self.visit(node.expr)\n",
    "        \n",
    "        if visitted_expr != None:\n",
    "                return visitted_expr\n",
    "        \n",
    "\n",
    "\n",
    "    def visit_ifNode(self, node: IfNode):\n",
    "        result_if = self.visit(node.if_node)\n",
    "        if result_if != None:\n",
    "            return self.visit(node.then_node)\n",
    "        return self.visit(node.else_node)\n",
    "    \n",
    "\n",
    "\n",
    "    def visit_rigidEqNode(self, node: RigidEqNode):\n",
    "        \n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def visit_flexibleEqNode(self, node: FlexibleEqNode):\n",
    "        leftResult = self.visit(node.left_node)\n",
    "        self.current_scopetable.addScope(leftResult, node.right_node, None)\n",
    "             \n",
    "\n",
    "    def visit_indexingNode(self, node: IndexingNode):\n",
    "        for scope in self.current_scopetable.scopetable:\n",
    "            if node.identifier.token.value == scope.symbol:\n",
    "                value = self.visit(scope.value)\n",
    "                if node.index.value >= len(value):\n",
    "                    print(\"Exception -> Index out of range\")\n",
    "                    return\n",
    "\n",
    "                return value[node.index.value]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Visitor for choice node.\n",
    "    choices only return nodes/vals which are not false?\n",
    "    if there is no valid value/node, it returns fail node.\n",
    "    '''\n",
    "    def visit_choiceSequenceNode(self,node):\n",
    "        nodes = []\n",
    "\n",
    "        # Choice appends all of its sequence, not containing false?\n",
    "        if node.token.type == TokenTypes.CHOICE:\n",
    "            for n in node.nodes:\n",
    "                    current_n = self.visit(n)\n",
    "\n",
    "                    # Skip fail node\n",
    "                    if current_n.token.type != TokenTypes.FAIL:\n",
    "                         nodes.append(current_n)  \n",
    "\n",
    "            # If choise sequence is empty, return false?\n",
    "            if(len(nodes) == 0):\n",
    "                return FailNode(Token(TokenTypes.FAIL,TokenTypes.FAIL.value))\n",
    "            \n",
    "            # If choise has atleast one return the node it only contains instead od a choice sequence node.\n",
    "            if(len(nodes) == 1):\n",
    "                  # HIER GEÄNDERT  anstatt nodes[0].node nur nodes[0], weil es nur ein node ist und kein visitornode\n",
    "                 return nodes[0]\n",
    "            \n",
    "            # At last, return choice sequence node wit all visited values.\n",
    "\n",
    "            \n",
    "            return ChoiceSequenceNode(node.token, nodes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Sequence node, firstly visitis all its nodes and if one node contains false?\n",
    "    sequence returns fail node, since its invalid.\n",
    "    If sequence is valid, it gets seqeunces by the sequentor and returns the resulting sequence(ses).\n",
    "    if sequentor returns many sequences, such as by doing operator node, it means the sequence given to the\n",
    "    sequentor contained a choice, thus the visitor of sequence node returns a choice sequence node.\n",
    "    '''\n",
    "    def visit_sequenceNode(self, node):\n",
    "\n",
    "         # HIER GEÄNDERT \n",
    "        visited_nodes = []\n",
    "        for n in node.nodes:\n",
    "            visited_node = self.visit(n)\n",
    "            if visited_node.token.type == TokenTypes.FAIL:\n",
    "                return FailNode(TokenTypes.FAIL,TokenTypes.FAIL.value)\n",
    "            visited_nodes.append(visited_node)\n",
    "        \n",
    "        sequentor:Sequentor = Sequentor(visited_nodes)\n",
    "      \n",
    "        sequences = sequentor.getSequences()\n",
    "\n",
    "        if len(sequences) == 0:\n",
    "            return FailNode(TokenTypes.FAIL,TokenTypes.FAIL.value)\n",
    "        \n",
    "        if len(sequences) == 1:\n",
    "            return SequenceNode(Token(TokenTypes.TUPLE_TYPE,TokenTypes.TUPLE_TYPE.value),sequences[0])\n",
    "\n",
    "        seq_nodes = []\n",
    "\n",
    "        for s in sequences:\n",
    "            seq_nodes.append(SequenceNode(Token(TokenTypes.TUPLE_TYPE,TokenTypes.TUPLE_TYPE.value),s))\n",
    "\n",
    "        return ChoiceSequenceNode(Token(TokenTypes.CHOICE,TokenTypes.CHOICE.value),seq_nodes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def visit_failNode(self, node: FailNode):\n",
    "        return FailNode(Token(TokenTypes.FAIL,TokenTypes.FAIL.value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Creates a/or many possible sequences.\n",
    "''' \n",
    "class Sequentor:\n",
    " # HIER GEÄNDERT \n",
    "    '''\n",
    "    Gets the nodes to find possible seqences.\n",
    "    '''\n",
    "    def __init__(self, nodes:list[BaseNode], main_scopetable, current_scope) -> None:\n",
    "        self.nodes:list[BaseNode] = nodes\n",
    "        self.others = []\n",
    "        self.choices = []\n",
    "        self.identifiers = []\n",
    "        self.references = []\n",
    "        self.pointer_pos = 0\n",
    "        \n",
    "\n",
    "\n",
    "    '''\n",
    "    Gets the resulting seqeunces.\n",
    "    '''\n",
    "    def getSequences(self):\n",
    "        self.setUpNodes()\n",
    "        sequences = self.createSequences() \n",
    "        return sequences \n",
    "\n",
    "    '''\n",
    "    Sets up the nodes of the sequences by differenciating choices and other values (Integers, Tuple).\n",
    "    As well coping each to their own list, which will be combined later on.\n",
    "    Row need to be saved and the node wihin the seqeunce to know where the reuslting value\n",
    "    of a node needs to be stored in a new/resulting list.\n",
    "    '''\n",
    "    def setUpNodes(self):\n",
    "        row = 0\n",
    "        \n",
    "        for n in self.nodes:\n",
    "            if n.token.type == TokenTypes.CHOICE:\n",
    "\n",
    "            # Deep copy since duplicates can change value during operation of functions.\n",
    "            # y:=(31|5); x:=(7|22); ((2|3),x,y)\n",
    "                self.choices.append([row, copy.deepcopy(n)]) \n",
    "            elif n.token.type == TokenTypes.IDENTIFIER:\n",
    "                 self.identifiers.append([row, n])\n",
    "            else: self.others.append([row, n])\n",
    "            row += 1\n",
    "\n",
    "        # x y y     y x\n",
    "        for id in self.identifiers:\n",
    "            for self.scope\n",
    "   \n",
    "\n",
    "    '''\n",
    "    Sets up the list with values that are fix (Not choices):\n",
    "\n",
    "    Example: (( 31 | 4 ), 9, (23,77))\n",
    "    cv_fix -> [0, 1, 2]\n",
    "\n",
    "    *Raplace values with the right ones (Fixed values only for now)*\n",
    "     cv_fix -> [0, 9, (23,77)]\n",
    "    '''\n",
    "    def setUp(self):\n",
    "        cv_fix = list(range(0, len(self.choices) + len(self.others)))\n",
    "        for o in self.others:\n",
    "            cv_fix[o[0]] = o[1]\n",
    "        return cv_fix\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Creates a list of possible sequenc(es).\n",
    "    '''\n",
    "    def createSequences(self):\n",
    "            # If there are no choices, than return back the nodes given to the sequentor.\n",
    "            if len(self.choices) == 0:\n",
    "              return [self.nodes]\n",
    "    \n",
    "            \n",
    "            current_pointer_pos = len(self.choices) - 2\n",
    "            last_index = len(self.choices) - 1\n",
    "            choice_values = []\n",
    "            current_index = 0\n",
    "            hasCompleted:bool = False\n",
    "            point_move_next_choice = False\n",
    "            hasManyChoices = True\n",
    "\n",
    "            if(current_pointer_pos < 0):\n",
    "                current_pointer_pos = 0\n",
    "                hasManyChoices = False\n",
    "\n",
    "            while hasCompleted == False:\n",
    "                choiceVals = self.setUp()\n",
    "                for c in self.choices:\n",
    "                \n",
    "                    current_choice = c[1]\n",
    "\n",
    "                    if current_index == current_pointer_pos: \n",
    "                        if point_move_next_choice :\n",
    "                            has_next_choice = current_choice.nextChoice()\n",
    "                            if has_next_choice == False:\n",
    "                                if current_pointer_pos == 0:\n",
    "                                    hasCompleted = True\n",
    "                                    break\n",
    "                                else: current_pointer_pos -= 1\n",
    "                            point_move_next_choice = False \n",
    "                        val = current_choice.getNextVal(hasManyChoices)\n",
    "                        \n",
    "                        # This if statement is only for single choices as such: x:= (2,3); (1,x)\n",
    "                        if hasManyChoices == False and current_choice.hasNextVal() == False:\n",
    "                            point_move_next_choice = True\n",
    "\n",
    "                        choiceVals[c[0]] = val \n",
    "\n",
    "                    elif  current_index == last_index:\n",
    "                        val = None\n",
    "                        val = current_choice.getNextVal(False)\n",
    "                        has_next_choice = True\n",
    "                        if val != None:\n",
    "                            choiceVals[c[0]] = val\n",
    "                            \n",
    "                        if current_choice.hasNextVal() == False:\n",
    "                            has_next_choice = current_choice.nextChoice()\n",
    "                        if(has_next_choice == False):\n",
    "                                point_move_next_choice = True  \n",
    "                                current_choice.setChoiceBack() \n",
    "                    else:\n",
    "                        val = current_choice.getNextVal(True)    \n",
    "                        choiceVals[c[0]] = val \n",
    "\n",
    "                    current_index += 1\n",
    "                if(hasCompleted == False):\n",
    "                    choice_values.append(choiceVals)\n",
    "                current_index = 0\n",
    "\n",
    "            return choice_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenTypes.IDENTIFIER: f\n",
      "TokenTypes.IDENTIFIER: f\n",
      "TokenTypes.LBRACKET: (\n",
      "TokenTypes.IDENTIFIER: p\n",
      "TokenTypes.COLON: :\n",
      "TokenTypes.INT_TYPE: int\n",
      "TokenTypes.COMMA: ,\n",
      "TokenTypes.IDENTIFIER: q\n",
      "TokenTypes.COLON: :\n",
      "TokenTypes.INT_TYPE: int\n",
      "TokenTypes.RBRACKET: )\n",
      "TokenTypes.COLON: :\n",
      "TokenTypes.INT_TYPE: int\n",
      "TokenTypes.BINDING: :=\n",
      "TokenTypes.IDENTIFIER: p\n",
      "TokenTypes.IDENTIFIER: p\n",
      "TokenTypes.IDENTIFIER: p\n",
      "TokenTypes.IDENTIFIER: p\n",
      "TokenTypes.IDENTIFIER: p\n",
      "TokenTypes.PLUS: +\n",
      "TokenTypes.IDENTIFIER: q\n",
      "TokenTypes.IDENTIFIER: q\n",
      "TokenTypes.IDENTIFIER: q\n",
      "TokenTypes.IDENTIFIER: q\n",
      "TokenTypes.IDENTIFIER: q\n",
      "TokenTypes.SEMICOLON: ;\n",
      "TokenTypes.IDENTIFIER: f\n",
      "TokenTypes.IDENTIFIER: f\n",
      "TokenTypes.LBRACKET: (\n",
      "TokenTypes.IDENTIFIER: f\n",
      "TokenTypes.IDENTIFIER: f\n",
      "TokenTypes.IDENTIFIER: f\n",
      "TokenTypes.IDENTIFIER: f\n",
      "TokenTypes.IDENTIFIER: f\n",
      "TokenTypes.LBRACKET: (\n",
      "TokenTypes.INTEGER: 1\n",
      "TokenTypes.COMMA: ,\n",
      "TokenTypes.INTEGER: 2\n",
      "TokenTypes.RBRACKET: )\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m parser \u001b[39m=\u001b[39m Parser(lexer)\n\u001b[0;32m      5\u001b[0m interpreter \u001b[39m=\u001b[39m Interpreter(parser)\n\u001b[1;32m----> 6\u001b[0m result \u001b[39m=\u001b[39m interpreter\u001b[39m.\u001b[39;49minterpret()\n\u001b[0;32m      7\u001b[0m \u001b[39mrepr\u001b[39m(result)\n",
      "Cell \u001b[1;32mIn[122], line 10\u001b[0m, in \u001b[0;36mInterpreter.interpret\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      8\u001b[0m tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparser\u001b[39m.\u001b[39mparse()\n\u001b[0;32m      9\u001b[0m \u001b[39mif\u001b[39;00m tree \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(tree)\n",
      "Cell \u001b[1;32mIn[122], line 14\u001b[0m, in \u001b[0;36mInterpreter.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[0;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, ProgramNode):\n\u001b[1;32m---> 14\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_programNode(node)\n\u001b[0;32m     15\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, BlockNode):\n\u001b[0;32m     16\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_blockNode(node)\n",
      "Cell \u001b[1;32mIn[122], line 59\u001b[0m, in \u001b[0;36mInterpreter.visit_programNode\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_programNode\u001b[39m(\u001b[39mself\u001b[39m, node: ProgramNode):\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node\u001b[39m.\u001b[39;49mnode)\n",
      "Cell \u001b[1;32mIn[122], line 16\u001b[0m, in \u001b[0;36mInterpreter.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_programNode(node)\n\u001b[0;32m     15\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, BlockNode):\n\u001b[1;32m---> 16\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_blockNode(node)\n\u001b[0;32m     17\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, ScopeNode):\n\u001b[0;32m     18\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_scopeNode(node)\n",
      "Cell \u001b[1;32mIn[122], line 64\u001b[0m, in \u001b[0;36mInterpreter.visit_blockNode\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     62\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[0;32m     63\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mnodes:\n\u001b[1;32m---> 64\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(n)\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m          results\u001b[39m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[122], line 54\u001b[0m, in \u001b[0;36mInterpreter.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_indexingNode(node)\n\u001b[0;32m     53\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, ParsedNode):\n\u001b[1;32m---> 54\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node\u001b[39m.\u001b[39;49mnode)\n\u001b[0;32m     55\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, FailNode):\n\u001b[0;32m     56\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_failNode(node)\n",
      "Cell \u001b[1;32mIn[122], line 34\u001b[0m, in \u001b[0;36mInterpreter.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_typeNodeSequence(node)\n\u001b[0;32m     33\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, FuncCallNode):\n\u001b[1;32m---> 34\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_funcCallNode(node)\n\u001b[0;32m     35\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, ParamsNode):\n\u001b[0;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_paramsNode(node)\n",
      "Cell \u001b[1;32mIn[122], line 220\u001b[0m, in \u001b[0;36mInterpreter.visit_funcCallNode\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    218\u001b[0m               index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_scopetable \u001b[39m=\u001b[39m table\n\u001b[1;32m--> 220\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(func_dec\u001b[39m.\u001b[39;49mblock)\n\u001b[0;32m    221\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_scopetable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscopetable\n",
      "Cell \u001b[1;32mIn[122], line 54\u001b[0m, in \u001b[0;36mInterpreter.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_indexingNode(node)\n\u001b[0;32m     53\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, ParsedNode):\n\u001b[1;32m---> 54\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node\u001b[39m.\u001b[39;49mnode)\n\u001b[0;32m     55\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, FailNode):\n\u001b[0;32m     56\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_failNode(node)\n",
      "Cell \u001b[1;32mIn[122], line 22\u001b[0m, in \u001b[0;36mInterpreter.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_bindingNode(node)\n\u001b[0;32m     21\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, OperatorNode):\n\u001b[1;32m---> 22\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_operatorNode(node)\n\u001b[0;32m     23\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, NumberNode):\n\u001b[0;32m     24\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_numberNode(node)\n",
      "Cell \u001b[1;32mIn[122], line 114\u001b[0m, in \u001b[0;36mInterpreter.visit_operatorNode\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    111\u001b[0m          \u001b[39mreturn\u001b[39;00m FailNode(Token(TokenTypes\u001b[39m.\u001b[39mFAIL, TokenTypes\u001b[39m.\u001b[39mFAIL\u001b[39m.\u001b[39mvalue))\n\u001b[0;32m    113\u001b[0m sequentor \u001b[39m=\u001b[39m Sequentor([node_left,node_right])\n\u001b[1;32m--> 114\u001b[0m seqences \u001b[39m=\u001b[39m sequentor\u001b[39m.\u001b[39;49mgetSequences()\n\u001b[0;32m    116\u001b[0m \u001b[39m# If lenght is one, it can only be two integers.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(seqences) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "Cell \u001b[1;32mIn[122], line 392\u001b[0m, in \u001b[0;36mSequentor.getSequences\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetSequences\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 392\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetUpNodes()\n\u001b[0;32m    393\u001b[0m     sequences \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreateSequences() \n\u001b[0;32m    394\u001b[0m     \u001b[39mreturn\u001b[39;00m sequences\n",
      "Cell \u001b[1;32mIn[122], line 412\u001b[0m, in \u001b[0;36mSequentor.setUpNodes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m n\u001b[39m.\u001b[39mtoken\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m TokenTypes\u001b[39m.\u001b[39mCHOICE:\n\u001b[0;32m    407\u001b[0m \n\u001b[0;32m    408\u001b[0m \u001b[39m# Deep copy since duplicates can change value during operation of functions.\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[39m# y:=(31|5); x:=(7|22); ((2|3),x,y)\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchoices\u001b[39m.\u001b[39mappend([row, copy\u001b[39m.\u001b[39mdeepcopy(n)]) \n\u001b[1;32m--> 412\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39mothers\u001b[39m.\u001b[39mappend([row, n])\n\u001b[0;32m    413\u001b[0m row \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[122], line 412\u001b[0m, in \u001b[0;36mSequentor.setUpNodes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m n\u001b[39m.\u001b[39mtoken\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m TokenTypes\u001b[39m.\u001b[39mCHOICE:\n\u001b[0;32m    407\u001b[0m \n\u001b[0;32m    408\u001b[0m \u001b[39m# Deep copy since duplicates can change value during operation of functions.\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[39m# y:=(31|5); x:=(7|22); ((2|3),x,y)\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchoices\u001b[39m.\u001b[39mappend([row, copy\u001b[39m.\u001b[39mdeepcopy(n)]) \n\u001b[1;32m--> 412\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39mothers\u001b[39m.\u001b[39mappend([row, n])\n\u001b[0;32m    413\u001b[0m row \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\chris\\Desktop\\Fh\\4.Semester\\Logikprogrammierung\\Projekt\\Repo\\Verse_Interpreter\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:1197\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m   1195\u001b[0m \u001b[39mif\u001b[39;00m is_line:\n\u001b[0;32m   1196\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_suspend(thread, step_cmd, original_step_cmd\u001b[39m=\u001b[39minfo\u001b[39m.\u001b[39mpydev_original_step_cmd)\n\u001b[1;32m-> 1197\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_wait_suspend(thread, frame, event, arg)\n\u001b[0;32m   1198\u001b[0m \u001b[39melif\u001b[39;00m is_return:  \u001b[39m# return event\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m     back \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mf_back\n",
      "File \u001b[1;32mc:\\Users\\chris\\Desktop\\Fh\\4.Semester\\Logikprogrammierung\\Projekt\\Repo\\Verse_Interpreter\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_wait_suspend\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mdo_wait_suspend(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chris\\Desktop\\Fh\\4.Semester\\Logikprogrammierung\\Projekt\\Repo\\Verse_Interpreter\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\Desktop\\Fh\\4.Semester\\Logikprogrammierung\\Projekt\\Repo\\Verse_Interpreter\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = \"f(p:int,q:int):int := p + q; f(1,2)\"\n",
    "# text = \"x:int; x=7; if(x<20) then x else 333\"\n",
    "lexer = lexicon(text)\n",
    "parser = Parser(lexer)\n",
    "interpreter = Interpreter(parser)\n",
    "result = interpreter.interpret()\n",
    "repr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.COLON: :\n",
      "TokenTypes.INT_TYPE: int\n",
      "TokenTypes.SEMICOLON: ;\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.EQUAL: =\n",
      "TokenTypes.INTEGER: 7\n",
      "TokenTypes.SEMICOLON: ;\n",
      "TokenTypes.IF: if\n",
      "TokenTypes.LBRACKET: (\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.GREATER: >\n",
      "TokenTypes.INTEGER: 20\n",
      "TokenTypes.RBRACKET: )\n",
      "TokenTypes.THEN: then\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.IDENTIFIER: x\n",
      "TokenTypes.ELSE: else\n",
      "TokenTypes.INTEGER: 333\n",
      "\n",
      " Result = 7\n"
     ]
    }
   ],
   "source": [
    "text = \"x:int; x=7; if(x>20) then x else 333\"\n",
    "# text = \"x,y:int; x=7; y=3; x+y\"\n",
    "lexer = lexicon(text)\n",
    "parser = Parser(lexer)\n",
    "interpreter = Interpreter(parser)\n",
    "result = interpreter.interpret()\n",
    "print(\"\\n Result = \" + str(result))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testcases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom ddt import ddt, data, file_data, idata, unpack\\nimport unittest \\n    \\n@ddt\\nclass LexerTest(unittest.TestCase):\\n    \\n   \\n    # INTEGER = int\\n    # IDENTIFIER = string #Names/Variables\\n       \\n    @data({\\'input\\': \"if\", \\'expected\\': Token(TokenTypes.IF,TokenTypes.IF.value)},\\n          {\\'input\\': \".\", \\'expected\\': Token(TokenTypes.DOT,TokenTypes.DOT.value)},\\n          {\\'input\\': \":\", \\'expected\\': Token(TokenTypes.COLON,TokenTypes.COLON.value)},\\n          {\\'input\\': \"=\", \\'expected\\': Token(TokenTypes.EQUAL,TokenTypes.EQUAL.value)},\\n          {\\'input\\': \"}\", \\'expected\\': Token(TokenTypes.CBR,TokenTypes.CBR.value)},\\n          {\\'input\\': \":=\", \\'expected\\': Token(TokenTypes.BINDING,TokenTypes.BINDING.value)},\\n          {\\'input\\': \"{\", \\'expected\\': Token(TokenTypes.CBL,TokenTypes.CBL.value)},\\n          {\\'input\\': \";\", \\'expected\\': Token(TokenTypes.SEMICOLON,TokenTypes.SEMICOLON.value)},\\n          {\\'input\\': \"]\", \\'expected\\': Token(TokenTypes.SBR,TokenTypes.SBR.value)},\\n          {\\'input\\': \",\", \\'expected\\': Token(TokenTypes.COMMA,TokenTypes.COMMA.value)},\\n          {\\'input\\': \"[\", \\'expected\\': Token(TokenTypes.SBL,TokenTypes.SBL.value)},\\n          {\\'input\\': \")\", \\'expected\\': Token(TokenTypes.RBRACKET,TokenTypes.RBRACKET.value)},\\n          {\\'input\\': \"else\", \\'expected\\': Token(TokenTypes.ELSE,TokenTypes.ELSE.value)},\\n          {\\'input\\': \"(\", \\'expected\\': Token(TokenTypes.LBRACKET,TokenTypes.LBRACKET.value)},\\n          {\\'input\\': \"then\", \\'expected\\': Token(TokenTypes.THEN,TokenTypes.THEN.value)},\\n          {\\'input\\': \"do\", \\'expected\\': Token(TokenTypes.DO,TokenTypes.DO.value)},\\n          {\\'input\\': \"for\", \\'expected\\': Token(TokenTypes.FOR,TokenTypes.FOR.value)},\\n          {\\'input\\': \"=>\", \\'expected\\': Token(TokenTypes.LAMBDA,TokenTypes.LAMBDA.value)},\\n          {\\'input\\': \"|\", \\'expected\\': Token(TokenTypes.CHOICE,TokenTypes.CHOICE.value)},\\n          {\\'input\\': \">\", \\'expected\\': Token(TokenTypes.GREATER,TokenTypes.GREATER.value)},\\n          {\\'input\\': \"<\", \\'expected\\': Token(TokenTypes.LOWER,TokenTypes.LOWER.value)},\\n          {\\'input\\': \"/\", \\'expected\\': Token(TokenTypes.DIVIDE,TokenTypes.DIVIDE.value)},\\n          {\\'input\\': \"*\", \\'expected\\': Token(TokenTypes.MULTIPLY,TokenTypes.MULTIPLY.value)},\\n          {\\'input\\': \"-\", \\'expected\\': Token(TokenTypes.MINUS,TokenTypes.MINUS.value)},\\n          {\\'input\\': \"+\", \\'expected\\': Token(TokenTypes.PLUS,TokenTypes.PLUS.value)},\\n          {\\'input\\': \"false?\", \\'expected\\': Token(TokenTypes.FAIL,TokenTypes.FAIL.value)},\\n          {\\'input\\': \"array\", \\'expected\\': Token(TokenTypes.ARRAY_TYPE,TokenTypes.ARRAY_TYPE.value)},\\n          {\\'input\\': \"tuple\", \\'expected\\': Token(TokenTypes.TUPLE_TYPE,TokenTypes.TUPLE_TYPE.value)},\\n          {\\'input\\': \"int\", \\'expected\\': Token(TokenTypes.INT_TYPE,TokenTypes.INT_TYPE.value)},\\n          {\\'input\\': \"123\", \\'expected\\': Token(TokenTypes.INTEGER,123)},\\n          {\\'input\\': \"arrays\", \\'expected\\': Token(TokenTypes.IDENTIFIER,\"arrays\")},\\n          {\\'input\\': \"tuplde2\", \\'expected\\': Token(TokenTypes.IDENTIFIER,\"tuplde\")},\\n          {\\'input\\': \"\", \\'expected\\': Token(TokenTypes.EOF,\"\")},\\n          {\\'input\\': None, \\'expected\\': Token(TokenTypes.EOF,\"\")},\\n       )\\n\\n    @unpack\\n    def test_received_tokens(self, input, expected:Token):\\n        self.lexer = lexicon(input)\\n        token = self.lexer.get_token(self.lexer.current_char)\\n        self.assertTrue(expected.type == token.type and expected.value == token.value)\\n    \\n\\nif __name__ == \\'__main__\\':\\n    unittest.main(argv=[\\'first-arg-is-ignored\\'], exit=False)       \\n'"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "from ddt import ddt, data, file_data, idata, unpack\n",
    "import unittest \n",
    "    \n",
    "@ddt\n",
    "class LexerTest(unittest.TestCase):\n",
    "    \n",
    "   \n",
    "    # INTEGER = int\n",
    "    # IDENTIFIER = string #Names/Variables\n",
    "       \n",
    "    @data({'input': \"if\", 'expected': Token(TokenTypes.IF,TokenTypes.IF.value)},\n",
    "          {'input': \".\", 'expected': Token(TokenTypes.DOT,TokenTypes.DOT.value)},\n",
    "          {'input': \":\", 'expected': Token(TokenTypes.COLON,TokenTypes.COLON.value)},\n",
    "          {'input': \"=\", 'expected': Token(TokenTypes.EQUAL,TokenTypes.EQUAL.value)},\n",
    "          {'input': \"}\", 'expected': Token(TokenTypes.CBR,TokenTypes.CBR.value)},\n",
    "          {'input': \":=\", 'expected': Token(TokenTypes.BINDING,TokenTypes.BINDING.value)},\n",
    "          {'input': \"{\", 'expected': Token(TokenTypes.CBL,TokenTypes.CBL.value)},\n",
    "          {'input': \";\", 'expected': Token(TokenTypes.SEMICOLON,TokenTypes.SEMICOLON.value)},\n",
    "          {'input': \"]\", 'expected': Token(TokenTypes.SBR,TokenTypes.SBR.value)},\n",
    "          {'input': \",\", 'expected': Token(TokenTypes.COMMA,TokenTypes.COMMA.value)},\n",
    "          {'input': \"[\", 'expected': Token(TokenTypes.SBL,TokenTypes.SBL.value)},\n",
    "          {'input': \")\", 'expected': Token(TokenTypes.RBRACKET,TokenTypes.RBRACKET.value)},\n",
    "          {'input': \"else\", 'expected': Token(TokenTypes.ELSE,TokenTypes.ELSE.value)},\n",
    "          {'input': \"(\", 'expected': Token(TokenTypes.LBRACKET,TokenTypes.LBRACKET.value)},\n",
    "          {'input': \"then\", 'expected': Token(TokenTypes.THEN,TokenTypes.THEN.value)},\n",
    "          {'input': \"do\", 'expected': Token(TokenTypes.DO,TokenTypes.DO.value)},\n",
    "          {'input': \"for\", 'expected': Token(TokenTypes.FOR,TokenTypes.FOR.value)},\n",
    "          {'input': \"=>\", 'expected': Token(TokenTypes.LAMBDA,TokenTypes.LAMBDA.value)},\n",
    "          {'input': \"|\", 'expected': Token(TokenTypes.CHOICE,TokenTypes.CHOICE.value)},\n",
    "          {'input': \">\", 'expected': Token(TokenTypes.GREATER,TokenTypes.GREATER.value)},\n",
    "          {'input': \"<\", 'expected': Token(TokenTypes.LOWER,TokenTypes.LOWER.value)},\n",
    "          {'input': \"/\", 'expected': Token(TokenTypes.DIVIDE,TokenTypes.DIVIDE.value)},\n",
    "          {'input': \"*\", 'expected': Token(TokenTypes.MULTIPLY,TokenTypes.MULTIPLY.value)},\n",
    "          {'input': \"-\", 'expected': Token(TokenTypes.MINUS,TokenTypes.MINUS.value)},\n",
    "          {'input': \"+\", 'expected': Token(TokenTypes.PLUS,TokenTypes.PLUS.value)},\n",
    "          {'input': \"false?\", 'expected': Token(TokenTypes.FAIL,TokenTypes.FAIL.value)},\n",
    "          {'input': \"array\", 'expected': Token(TokenTypes.ARRAY_TYPE,TokenTypes.ARRAY_TYPE.value)},\n",
    "          {'input': \"tuple\", 'expected': Token(TokenTypes.TUPLE_TYPE,TokenTypes.TUPLE_TYPE.value)},\n",
    "          {'input': \"int\", 'expected': Token(TokenTypes.INT_TYPE,TokenTypes.INT_TYPE.value)},\n",
    "          {'input': \"123\", 'expected': Token(TokenTypes.INTEGER,123)},\n",
    "          {'input': \"arrays\", 'expected': Token(TokenTypes.IDENTIFIER,\"arrays\")},\n",
    "          {'input': \"tuplde2\", 'expected': Token(TokenTypes.IDENTIFIER,\"tuplde\")},\n",
    "          {'input': \"\", 'expected': Token(TokenTypes.EOF,\"\")},\n",
    "          {'input': None, 'expected': Token(TokenTypes.EOF,\"\")},\n",
    "       )\n",
    "\n",
    "    @unpack\n",
    "    def test_received_tokens(self, input, expected:Token):\n",
    "        self.lexer = lexicon(input)\n",
    "        token = self.lexer.get_token(self.lexer.current_char)\n",
    "        self.assertTrue(expected.type == token.type and expected.value == token.value)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)       \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a01c28328f65be720e9d0443b68bfc03fdde5263d5f6e7c10f8af6f0ef832734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
