{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verse Interpreter development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essential installs:\n",
    "- `pip3 install .....`\n",
    "\n",
    "\n",
    "This version is used to test the first steps for the verse interpreter. The final version will be used as a full python file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR-TYPE ENUMERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ErrorType(Enum):\n",
    "    SyntaxError = 'Wrong Syntax at'\n",
    "    SemanticError = 'Wrong Semantics at'\n",
    "    UnkownError = 'Operation Failure'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGGER CLASSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self):{}\n",
    "        \n",
    "    def __log__(self, string:str):{}\n",
    "\n",
    "    def __log_error__(self,string:str, type:ErrorType):{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Console_Logger(Logger):\n",
    "\n",
    "    def __log__(self, string:str):\n",
    "        print(string)\n",
    "\n",
    "    def __log_error__(self,string:str, type:ErrorType):       \n",
    "        print(\"ERROR| \" + type.value + \": \" + string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import string\n",
    "\n",
    "# class syntax\n",
    "\n",
    "class TokenTypes(Enum):\n",
    "    # Data\n",
    "    Integer = int\n",
    "    Identifier = string #Names/Variables\n",
    "    Type = None\n",
    "    # Aritmetics\n",
    "    Plus = \"+\"\n",
    "    Minus = \"-\"\n",
    "    Multiply = \"*\"\n",
    "    Divide = \"/\"\n",
    "    Greater = \">\"\n",
    "    GreaterEq = \">=\"\n",
    "    Lower = \"<\"\n",
    "    LowerEq = \"<=\"\n",
    "    Choice = \"|\"\n",
    "    # Mehtods\n",
    "    For = \"for\"\n",
    "    LBracket = \"(\"\n",
    "    RBracket = \")\"\n",
    "    # Else\n",
    "    EOF = None\n",
    "    Colon = \":\"\n",
    "    Comma=\",\"\n",
    "    SemiColon =\";\"\n",
    "    Binding =\":=\"\n",
    "    SLB = \"[\"\n",
    "    SRB = \"]\"\n",
    "    Equal = \"]\"\n",
    "    Scope = \":\"\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['halloo wie geht', 'ws', 'efaf', ' aefe ', ' eeerwre']\n"
     ]
    }
   ],
   "source": [
    "class FileReader:\n",
    "    def __init__(self):{}\n",
    "\n",
    "    \n",
    "    def get_Lines(self, name:str):\n",
    "       \n",
    "        try:\n",
    "            f = open('..\\modules\\{}'.format(name),'r')\n",
    "            lines = f.read().split(\"\\n\")\n",
    "            return (lines,True)\n",
    "        except:\n",
    "            return ([],False)\n",
    "        \n",
    "       \n",
    "\n",
    "   \n",
    "reader = FileReader()\n",
    "segments,read_success = reader.get_Lines('example.txt')\n",
    "print(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "     def __init__(self, type: TokenTypes,value, start_pos:int, end_pos:int):\n",
    "        self.value = value\n",
    "        self.type = type\n",
    "        self.start_pos = start_pos\n",
    "        self.end_pos = end_pos\n",
    "\n",
    "     def __info__(self):\n",
    "         return \"{}:{}\".format(self.type, self.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "class lexicon:\n",
    "    def __init__(self, input: string):\n",
    "        self.input = input\n",
    "        self.index = 0\n",
    "        self.current_char = self.input[self.index]\n",
    "\n",
    "    def error():\n",
    "        raise Exception('Invalid character.')\n",
    "    \n",
    "    # moves the pointer a character forward\n",
    "    def forward(self, index) -> tuple[str,int]:\n",
    "        index += 1\n",
    "\n",
    "        # check if index out of range\n",
    "        if (index >= len(self.input)):\n",
    "            return None, index\n",
    "        \n",
    "        return self.input[index],index\n",
    "    \n",
    "    def future_token(self, index) -> tuple[Token,int]:\n",
    "        index += 1\n",
    "\n",
    "        # check if index out of range\n",
    "        if (index >= len(self.input)):\n",
    "            return None,index\n",
    "        \n",
    "        return self.get_token(self.input[index], index)\n",
    "    \n",
    "    def get_int(self, index: int) -> tuple[int,int]:\n",
    "        result = ''\n",
    "\n",
    "        # checks if there are multiple digits\n",
    "        while True:\n",
    "            if index < len(self.input) and self.input[index] != None and self.input[index].isdigit():\n",
    "                result += self.input[index]\n",
    "\n",
    "                if index + 1 < len(self.input) and self.input[index + 1].isdigit():\n",
    "                    _,index = self.forward(index)\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return int(result),index\n",
    "    \n",
    "    def get_token(self, char: string, index: int) -> tuple[Token,int]:\n",
    "        if char is None:\n",
    "            return Token(TokenTypes.EOF, None,0,0),index\n",
    "\n",
    "        if char.isdigit():\n",
    "            result,index = self.get_int(index)\n",
    "            return Token(TokenTypes.Integer, result,0,0),index\n",
    "\n",
    "        if char == TokenTypes.Divide.value:\n",
    "            return Token(TokenTypes.Divide, TokenTypes.Divide.value,0,0),index\n",
    "        \n",
    "        if char == TokenTypes.Multiply.value:\n",
    "            return Token(TokenTypes.Multiply, TokenTypes.Multiply.value,0,0),index\n",
    "        \n",
    "        if char == TokenTypes.Plus.value:\n",
    "            return Token(TokenTypes.Plus, TokenTypes.Plus.value,0,0),index\n",
    "        \n",
    "        if char == TokenTypes.Minus.value:\n",
    "            return Token(TokenTypes.Minus, TokenTypes.Minus.value,0,0),index\n",
    "        \n",
    "        if char == TokenTypes.SemiColon.value:\n",
    "            return Token(TokenTypes.SemiColon, TokenTypes.SemiColon.value,0,0),index\n",
    "        \n",
    "        if char == TokenTypes.Comma.value:\n",
    "            return Token(TokenTypes.Comma, TokenTypes.Comma.value,0,0),index\n",
    "        \n",
    "        if char == TokenTypes.Colon.value:\n",
    "            return Token(TokenTypes.Colon, TokenTypes.Colon.value,0,0),index\n",
    "        \n",
    "        if char == TokenTypes.LBracket.value:\n",
    "            return Token(TokenTypes.LBracket, TokenTypes.LBracket.value,0,0),index\n",
    "        \n",
    "        if char == TokenTypes.RBracket.value:\n",
    "            return Token(TokenTypes.RBracket, TokenTypes.RBracket.value,0,0),index\n",
    "        \n",
    "        if char == ' ':\n",
    "            char,index = self.forward(index)\n",
    "            return self.get_token(char, index)\n",
    "        \n",
    "        return Token(TokenTypes.EOF, None,0,0),index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723 is of the tokentype: TokenTypes.Integer\n",
      "Future:TokenTypes.Plus\n",
      "\n",
      "+ is of the tokentype: TokenTypes.Plus\n",
      "Future:TokenTypes.Integer\n",
      "\n",
      "2 is of the tokentype: TokenTypes.Integer\n",
      "Future:TokenTypes.Minus\n",
      "\n",
      "- is of the tokentype: TokenTypes.Minus\n",
      "Future:TokenTypes.Integer\n",
      "\n",
      "5 is of the tokentype: TokenTypes.Integer\n",
      "Future:TokenTypes.Multiply\n",
      "\n",
      "* is of the tokentype: TokenTypes.Multiply\n",
      "Future:TokenTypes.Integer\n",
      "\n",
      "1235 is of the tokentype: TokenTypes.Integer\n",
      "Future:TokenTypes.Divide\n",
      "\n",
      "/ is of the tokentype: TokenTypes.Divide\n",
      "Future:TokenTypes.Integer\n",
      "\n",
      "100 is of the tokentype: TokenTypes.Integer\n"
     ]
    }
   ],
   "source": [
    "lexer = lexicon(\"723 + 2 - 5 * 1235 / 100\")\n",
    "\n",
    "while lexer.current_char is not None:\n",
    "    token,lexer.index = lexer.get_token(lexer.current_char, lexer.index)\n",
    "    print(str(token.value) + \" is of the tokentype: \" + str(token.type))\n",
    "    future_token,index = lexer.future_token(lexer.index)\n",
    "    if future_token is not None:\n",
    "        print(\"Future:\" + str(future_token.type) + \"\\n\")\n",
    "    lexer.current_char, lexer.index = lexer.forward(lexer.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNode:\n",
    "    def __init__(self, token:Token) -> None:\n",
    "        self.token = token\n",
    "\n",
    "class BlockNode(BaseNode):\n",
    "    def __init__(self, node:list[BaseNode]) -> None:\n",
    "        self.node = node\n",
    "\n",
    "class Program(BaseNode):\n",
    "    def __init__(self, node:list[BlockNode]) -> None:\n",
    "        self.node = node\n",
    "\n",
    "\n",
    "class ScopeNode(BaseNode):\n",
    "    def __init__(self,token:Token, nodes:list[BaseNode]) -> None:\n",
    "        super().__init__(token)\n",
    "        self.nodes = nodes\n",
    "\n",
    "class NumberNode(BaseNode):\n",
    "    def __init__(self, token:Token) -> None:\n",
    "        super().__init__(token)\n",
    "        self.value = token.value\n",
    "\n",
    "class OperatorNode(BaseNode):\n",
    "    def __init__(self, token:Token, leftNode: BaseNode, rightNode: BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.leftNode = leftNode\n",
    "        self.rightNode = rightNode\n",
    "\n",
    "class UnaryNode(BaseNode):\n",
    "     def __init__(self, token:Token, node) -> None:\n",
    "        super().__init__(token)\n",
    "        self.node = node\n",
    "\n",
    "class ScopeNode(BaseNode):\n",
    "    def __init__(self, token:Token, nodes:list[BaseNode], type) -> None: #Change into Variable/IdentifierNode\n",
    "        super().__init__(token)\n",
    "        self.nodes = nodes\n",
    "        self.type = type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class that takes a parsed node, containes information if node could have been parsed\n",
    "class ParsedNode:\n",
    "    def __init__(self, node:BaseNode, hasSyntaxError:bool ):\n",
    "        self.node = node\n",
    "        self.hasSyntaxError = hasSyntaxError\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpreter:\n",
    "    def __init__(self, parser):\n",
    "        self.parser = parser\n",
    "\n",
    "    def Ovisitor(self, node: OperatorNode):\n",
    "        if node.token.type == TokenTypes.Plus:\n",
    "            return self.visit(node.leftNode) + self.visit(node.rightNode)\n",
    "        elif node.token.type == TokenTypes.Minus:\n",
    "            return self.visit(node.leftNode) - self.visit(node.rightNode)\n",
    "        elif node.token.type == TokenTypes.Multiply:\n",
    "            return self.visit(node.leftNode) * self.visit(node.rightNode)\n",
    "        elif node.token.type == TokenTypes.Divide:\n",
    "            return self.visit(node.leftNode) // self.visit(node.rightNode)\n",
    "        \n",
    "\n",
    "    def Nvisitor(self, node: NumberNode):\n",
    "        return node.value\n",
    "\n",
    "    def interpret(self):\n",
    "        tree = self.parser.parse()\n",
    "        return self.visit(tree)\n",
    "    \n",
    "    def visit(self, node: BaseNode):\n",
    "        if type(node) == OperatorNode:\n",
    "            return self.Ovisitor(node)\n",
    "        \n",
    "        return self.Nvisitor(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, lexer: lexicon):\n",
    "       self.logger: Logger = Console_Logger()\n",
    "       self.end = False\n",
    "       self.lexer = lexer\n",
    "       self.current_token, self.index = lexer.get_token(\n",
    "           self.lexer.current_char, self.lexer.index)\n",
    "       \n",
    "\n",
    "    def parse(self) -> ParsedNode:     \n",
    "        node = self.program().node\n",
    "        return node\n",
    "       \n",
    "  \n",
    "\n",
    "    def program(self) -> ParsedNode:\n",
    "        return self.expr()\n",
    "\n",
    "    def block(self):\n",
    "        pass\n",
    "\n",
    "    def statement_list(self):\n",
    "        pass\n",
    "\n",
    "    def statement(self):\n",
    "        pass\n",
    "\n",
    "    def func_call(self):\n",
    "        pass\n",
    "    \n",
    "    def func_call_param(self):\n",
    "        pass\n",
    "\n",
    "    def func_decl(self):\n",
    "        pass \n",
    "\n",
    "    def func_dec_param(self):\n",
    "        pass\n",
    "\n",
    "    def if_statement(self):\n",
    "        pass\n",
    "\n",
    "    def for_loop(self):\n",
    "        pass\n",
    "\n",
    "    def nested_scope(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "    def expr(self) -> ParsedNode:    \n",
    "        \n",
    "        return self.choice()\n",
    "\n",
    "    def choice(self) -> ParsedNode:\n",
    "        #equal (| equal)*\n",
    "        left_node = self.equal()\n",
    "\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            while(self.current_token.type == TokenTypes.Choice):\n",
    "                token = self.current_token\n",
    "                self.advance_to_next_token()\n",
    "                right_node = self.equal()\n",
    "                if(right_node.hasSyntaxError):\n",
    "                    return right_node\n",
    "                else:\n",
    "                    return ParsedNode(OperatorNode(token,left_node.node,right_node.node),False)\n",
    "        return left_node\n",
    "         \n",
    "\n",
    "    def equal(self) -> ParsedNode:\n",
    "        #eqaul: gl = gl\n",
    "\n",
    "        left_node = self.gl()\n",
    "\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            while(self.current_token.type == TokenTypes.Equal):\n",
    "                token = self.current_token\n",
    "                self.advance_to_next_token()\n",
    "                right_node = self.gl()\n",
    "                if(right_node.hasSyntaxError):\n",
    "                    return right_node\n",
    "                else:\n",
    "                    return ParsedNode(OperatorNode(token,left_node.node,right_node.node),False)\n",
    "        return left_node\n",
    "       \n",
    "\n",
    "    def gl(self) -> ParsedNode:\n",
    "        #gl: arith ((GT|LT|GE|LE) arith)*\n",
    "\n",
    "        left_node = self.arith()\n",
    "\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            while(self.current_token.type == TokenTypes.Greater or self.current_token.type == TokenTypes.GreaterEq or \n",
    "                  self.current_token.type == TokenTypes.Lower or self.current_token.type == TokenTypes.LowerEq):\n",
    "                token = self.current_token\n",
    "                self.advance_to_next_token()\n",
    "                right_node = self.arith()\n",
    "                if(right_node.hasSyntaxError):\n",
    "                    return right_node\n",
    "                else:\n",
    "                    return ParsedNode(OperatorNode(token,left_node.node,right_node.node),False)\n",
    "        return left_node\n",
    "\n",
    "    def arith(self) -> ParsedNode:\n",
    "        #term ((PLUS|MINUS) term)*\n",
    "\n",
    "        left_node = self.term()\n",
    "\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            while(self.current_token.type == TokenTypes.Plus or self.current_token.type == TokenTypes.Minus):\n",
    "                token = self.current_token\n",
    "                self.advance_to_next_token()\n",
    "                right_node = self.term()\n",
    "                if(right_node.hasSyntaxError):\n",
    "                    return right_node\n",
    "                else:\n",
    "                    return ParsedNode(OperatorNode(token,left_node.node,right_node.node),False)\n",
    "        return left_node\n",
    "\n",
    "    def term(self) -> ParsedNode:\n",
    "        #factor ((MUL|DIV) factor)*\n",
    "\n",
    "        left_node = self.factor()\n",
    "\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            while(self.current_token.type == TokenTypes.Multiply or self.current_token.type == TokenTypes.Divide):\n",
    "                token = self.current_token\n",
    "                self.advance_to_next_token()\n",
    "                right_node = self.factor()\n",
    "                if(right_node.hasSyntaxError):\n",
    "                    return right_node\n",
    "                else:\n",
    "                    return ParsedNode(OperatorNode(token,left_node.node,right_node.node),False)\n",
    "        return left_node\n",
    "    \n",
    "\n",
    "    def factor(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "        index = self.index\n",
    "      # INTEGER  \n",
    "      # : tuple\n",
    "      # : (MINUS|PLUS) arith\n",
    "      # : func_call\n",
    "      # : indexing \n",
    "\n",
    "        if(token.type == TokenTypes.Integer):\n",
    "            self.advance_to_next_token()\n",
    "            return ParsedNode(NumberNode(token),False)\n",
    "        \n",
    "        if(self.current_token.type == TokenTypes.Plus or self.current_token.type == TokenTypes.Minus):\n",
    "            self.advance_to_next_token()\n",
    "            node = self.arith()\n",
    "            return ParsedNode(UnaryNode(token,node),False)\n",
    "        \n",
    "        node = self.tuple()\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index)\n",
    "        else: return node\n",
    "        \n",
    "        return ParsedNode(None,True) #Returns invalid Node on invalid Syntax\n",
    "        \n",
    "\n",
    "    def binding(self) -> ParsedNode:\n",
    "          #scope BINDING expr\n",
    "        left_node = self.scope()\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.current_token.type == TokenTypes.Binding):\n",
    "                token = self.current_token\n",
    "                self.advance_to_next_token()\n",
    "                right_node = self.expr()\n",
    "                if(right_node.hasSyntaxError == False):\n",
    "                    return ParsedNode(OperatorNode(token,left_node,right_node))\n",
    "        return left_node\n",
    "\n",
    "    def scope(self) -> ParsedNode:\n",
    "      #Identifier (COMMA IDENTIFIER)*? COLON type    UPDATE\n",
    "      left_node = self.Identifier()\n",
    "      identifiers = list[BaseNode]=[]\n",
    "      comma_true = self.current_token.type == TokenTypes.Comma\n",
    "\n",
    "      while(self.current_token.type == TokenTypes.Comma):\n",
    "          token = self.current_token\n",
    "          self.advance_to_next_token()\n",
    "          \n",
    "          id_node = self.Identifier()\n",
    "          if(id_node.hasSyntaxError == False):\n",
    "              identifiers.append(id_node)\n",
    "          else: return ParsedNode(None,True)\n",
    "      \n",
    "      colon_true = self.current_token.type == TokenTypes.Colon\n",
    "\n",
    "      if(comma_true and colon_true == False):\n",
    "          return ParsedNode(None,True)\n",
    "      \n",
    "      if(colon_true):\n",
    "          identifiers.append(left_node)\n",
    "          token = self.current_token\n",
    "          self.advance_to_next_token()\n",
    "          right_node = self.type()\n",
    "          if(right_node.hasSyntaxError == False):\n",
    "              return ParsedNode(ScopeNode(token,identifiers,right_node),False)\n",
    "          else: return ParsedNode(None,True)\n",
    "      return left_node\n",
    "\n",
    "\n",
    "    def Identifier(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "        if(token.type == TokenTypes.Identifier):\n",
    "            self.advance_to_next_token()\n",
    "            return ParsedNode(BaseNode(self.current_token), False)\n",
    "        return ParsedNode(None, True) \n",
    "        \n",
    "\n",
    "    def type(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "        if(self.current_token.type == TokenTypes.Type):\n",
    "            self.advance_to_next_token()\n",
    "            return ParsedNode(BaseNode(self.current_token), False)\n",
    "        return ParsedNode(None, True) \n",
    "\n",
    "\n",
    "    def tuple(self) -> ParsedNode:\n",
    "        #tuple: LB expr (COMMA expr)*? RB           NEED TO COMPLETE\n",
    "        if(self.current_token.type == TokenTypes.LBracket):\n",
    "            self.advance_to_next_token()\n",
    "            node = self.expr()\n",
    "            \n",
    "           \n",
    "            if(self.current_token.type == TokenTypes.RBracket):\n",
    "                self.advance_to_next_token()\n",
    "                return node\n",
    "        return ParsedNode(None,True)\n",
    "        \n",
    "\n",
    "    def indexing(self) -> ParsedNode:\n",
    "        #Identifier SLB expr RLB\n",
    "        left_node = self.Identifier()\n",
    "\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.current_token.type == TokenTypes.SLB):\n",
    "                self.advance_to_next_token()\n",
    "                expr_node = self.expr()\n",
    "                if(expr_node.hasSyntaxError == False):\n",
    "                    if(self.current_token == TokenTypes.SRB):\n",
    "                        pass # RETURN INDEXING NODE\n",
    "        return left_node\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def advance_to_next_token(self):\n",
    "        self.lexer.current_char, self.lexer.index = self.lexer.forward(\n",
    "            self.index)\n",
    "        self.current_token, self.index = lexer.get_token(\n",
    "            self.lexer.current_char, self.lexer.index)\n",
    "\n",
    "        if (self.current_token.type == TokenTypes.EOF):\n",
    "            self.end = True\n",
    "        print(self.current_token.__info__())\n",
    "\n",
    "    def set_to_token(self,index): \n",
    "        self.index = index\n",
    "        self.advance_to_next_token()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIERLBracket\n",
      "TokenTypes.Integer:2\n",
      "HIERInteger\n",
      "TokenTypes.Multiply:*\n",
      "TokenTypes.Integer:3\n",
      "TokenTypes.RBracket:)\n",
      "TokenTypes.Multiply:*\n",
      "TokenTypes.LBracket:(\n",
      "TokenTypes.Integer:2\n",
      "HIERInteger\n",
      "TokenTypes.Plus:+\n",
      "TokenTypes.Integer:2\n",
      "TokenTypes.RBracket:)\n",
      "TokenTypes.Type:None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "text = \"(2 * 3) * (2 + 2)\"\n",
    "lexer = lexicon(text)\n",
    "parser = Parser(lexer)\n",
    "interpreter = Interpreter(parser)\n",
    "result = interpreter.interpret()\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
