{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verse Interpreter development\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essential installs:\n",
    "\n",
    "- `pip3 install .....`\n",
    "\n",
    "This version is used to test the first steps for the verse interpreter. The final version will be used as a full python file.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR-TYPE ENUMERATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ErrorType(Enum):\n",
    "    SyntaxError = 'Wrong Syntax at'\n",
    "    SemanticError = 'Wrong Semantics at'\n",
    "    UnkownError = 'Operation Failure'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGGER CLASSS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self):{}\n",
    "        \n",
    "    def __log__(self, string:str):{}\n",
    "\n",
    "    def __log_error__(self,string:str, type:ErrorType):{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Console_Logger(Logger):\n",
    "\n",
    "    def __log__(self, string:str):\n",
    "        print(string)\n",
    "\n",
    "    def __log_error__(self,string:str, type:ErrorType):       \n",
    "        print(\"ERROR| \" + type.value + \": \" + string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "\n",
    "class TokenTypes(Enum):\n",
    "    # Data\n",
    "    INTEGER = int\n",
    "    IDENTIFIER = string #Names/Variables\n",
    "    INT_TYPE = \"int\"\n",
    "    TUPLE_TYPE = \"tuple\"\n",
    "    ARRAY_TYPE = \"array\"\n",
    "    FAIL = \"false?\"\n",
    "    # Aritmetics\n",
    "    PLUS = \"+\"\n",
    "    MINUS = \"-\"\n",
    "    MULTIPLY = \"*\"\n",
    "    DIVIDE = \"/\"\n",
    "    GREATER = \">\"\n",
    "    GREATEREQ = \">=\"\n",
    "    LOWER = \"<\"\n",
    "    LOWEREQ = \"<=\"\n",
    "    CHOICE = \"|\"\n",
    "    LAMBDA = \"=>\"\n",
    "    # Mehtods\n",
    "    FOR = \"for\"\n",
    "    DO = \"do\"\n",
    "    IF = \"if\"\n",
    "    THEN = \"then\"\n",
    "    ELSE = \"else\"\n",
    "    # Else\n",
    "    EOF = \"\"\n",
    "    COLON = \":\"\n",
    "    COMMA=\",\"\n",
    "    SEMICOLON =\";\"\n",
    "    BINDING =\":=\"\n",
    "    LBRACKET = \"(\"\n",
    "    RBRACKET = \")\"\n",
    "    SBL = \"[\"\n",
    "    SBR = \"]\"\n",
    "    CBL = \"{\"\n",
    "    CBR = \"}\"\n",
    "    EQUAL = \"=\"\n",
    "    SCOPE = \":\"\n",
    "    DOT = \".\"\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['halloo wie geht', 'ws', 'efaf', ' aefe ', ' eeerwre']\n"
     ]
    }
   ],
   "source": [
    "class FileReader:\n",
    "    def __init__(self):{}\n",
    "\n",
    "    \n",
    "    def get_Lines(self, name:str):\n",
    "       \n",
    "        try:\n",
    "            f = open('..\\modules\\{}'.format(name),'r')\n",
    "            lines = f.read().split(\"\\n\")\n",
    "            return (lines,True)\n",
    "        except:\n",
    "            return ([],False)\n",
    "        \n",
    "       \n",
    "\n",
    "   \n",
    "reader = FileReader()\n",
    "segments,read_success = reader.get_Lines('example.txt')\n",
    "print(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class NodeStatus(Enum):\n",
    "    # Data\n",
    "    VALUE_RECEIVABLE = None\n",
    "    NOT_ASSIGNED_YET = None\n",
    "    ERROR = None\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisitorNode:\n",
    "    def __init__(self, type:NodeStatus, node):\n",
    "        self.type = type\n",
    "        self.node = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, type: TokenTypes, value) -> None:\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "    \n",
    "    def __info__(self):\n",
    "         return \"{}: {}\".format(self.type, self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lexicon:\n",
    "    def __init__(self, input: string):\n",
    "        self.input = input\n",
    "        self.index = 0\n",
    "        self.current_char = self.input[self.index]\n",
    "    \n",
    "    # moves the pointer a character forward\n",
    "    def forward(self) -> None:\n",
    "        self.index += 1\n",
    "\n",
    "        # checks if index is out of range\n",
    "        if self.index >= len(self.input):\n",
    "            self.current_char = None\n",
    "            return\n",
    "        \n",
    "        self.current_char = self.input[self.index]\n",
    "    \n",
    "    def backward(self) -> None:\n",
    "        self.index -= 1\n",
    "\n",
    "        # checks if index is out of range\n",
    "        if self.index < 0:\n",
    "            self.current_char = None\n",
    "            return\n",
    "        \n",
    "        self.current_char = self.input[self.index]\n",
    "    \n",
    "    def get_int(self) -> int:\n",
    "        if self.index >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.input[self.index]\n",
    "\n",
    "        # checks if there are multiple digits\n",
    "        while True:\n",
    "            self.forward()\n",
    "\n",
    "            if self.index < len(self.input) and self.input[self.index] != None and self.input[self.index].isnumeric():\n",
    "                result += self.input[self.index]\n",
    "            else:\n",
    "                self.backward()\n",
    "                break\n",
    "\n",
    "        return int(result)\n",
    "    \n",
    "    def get_var(self) -> string:\n",
    "        if self.index >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.input[self.index]\n",
    "\n",
    "        # checks if there is a longer variable name\n",
    "        while True:\n",
    "            self.forward()\n",
    "\n",
    "            if self.index < len(self.input) and self.input[self.index] != None and self.input[self.index].isalpha():\n",
    "                result += self.input[self.index]\n",
    "            elif self.index < len(self.input) and self.input[self.index] != None and self.input[self.index] == '?':\n",
    "                result += self.input[self.index]\n",
    "            else:\n",
    "                self.backward()\n",
    "                break\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_a_string_from_input(self) -> string:\n",
    "        result = self.input[self.index]\n",
    "        self.forward()\n",
    "        \n",
    "        if self.index < len(self.input) and self.input[self.index] != None:\n",
    "                result += self.input[self.index]\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def get_binding(self):\n",
    "        if self.index >= len(self.input) and self.index + 1 >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.get_a_string_from_input()\n",
    "\n",
    "        match result:\n",
    "            case TokenTypes.BINDING.value:\n",
    "                return Token(TokenTypes.BINDING, TokenTypes.BINDING.value)\n",
    "        \n",
    "        self.backward()\n",
    "        return Token(TokenTypes.COLON, TokenTypes.COLON.value)\n",
    "    \n",
    "    def get_greater_eq(self):\n",
    "        if self.index >= len(self.input) and self.index + 1 >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.get_a_string_from_input()\n",
    "\n",
    "        match result:\n",
    "            case TokenTypes.GREATEREQ.value:\n",
    "                return Token(TokenTypes.GREATEREQ, TokenTypes.GREATEREQ.value)\n",
    "        \n",
    "        self.backward()\n",
    "        return Token(TokenTypes.GREATER, TokenTypes.GREATER.value)\n",
    "    \n",
    "\n",
    "    def get_lower_eq(self):\n",
    "        if self.index >= len(self.input) and self.index + 1 >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.input[self.index]\n",
    "        self.forward()\n",
    "        \n",
    "        result = self.get_a_string_from_input()\n",
    "\n",
    "        match result:\n",
    "            case TokenTypes.LOWEREQ.value:\n",
    "                return Token(TokenTypes.LOWEREQ, TokenTypes.LOWEREQ.value)\n",
    "        \n",
    "        self.backward()\n",
    "        return Token(TokenTypes.LOWER, TokenTypes.LOWER.value)\n",
    "    \n",
    "    def get_lambda(self):\n",
    "        if self.index >= len(self.input) and self.index + 1 >= len(self.input):\n",
    "            return None\n",
    "        \n",
    "        result = self.input[self.index]\n",
    "        \n",
    "        result = self.get_a_string_from_input()\n",
    "\n",
    "        match result:\n",
    "            case TokenTypes.LAMBDA.value:\n",
    "                return Token(TokenTypes.LAMBDA, TokenTypes.LAMBDA.value)\n",
    "        \n",
    "        self.backward()\n",
    "        return Token(TokenTypes.EQUAL, TokenTypes.EQUAL.value)\n",
    "    \n",
    "   \n",
    "    def get_token(self, char: string) -> Token:\n",
    "        token = self.check_for_tokentypes(char)\n",
    "\n",
    "        if token.type != TokenTypes.EOF:\n",
    "            return token\n",
    "        \n",
    "        if char == None:\n",
    "            return token\n",
    "            \n",
    "        # skip spaces.\n",
    "        if char == ' ':\n",
    "            self.forward()\n",
    "            return self.get_token(self.current_char)\n",
    "        \n",
    "        if char == TokenTypes.COLON:\n",
    "            return self.get_next(TokenTypes.BINDING.value)\n",
    "\n",
    "        # checks if the current character is a number.\n",
    "        if char.isnumeric():\n",
    "            result = self.get_int()\n",
    "            return Token(TokenTypes.INTEGER, result)\n",
    "        \n",
    "        if char.isalpha():\n",
    "            result = self.get_var()\n",
    "            token = self.check_for_tokentypes(result)\n",
    "            if(token.type == TokenTypes.EOF):\n",
    "                token = Token(TokenTypes.IDENTIFIER, result)  \n",
    "                  \n",
    "        return token\n",
    "\n",
    "    def check_for_tokentypes(self, char: string) -> Token:\n",
    "        # checks if the current character is a supported token type.\n",
    "        match char:\n",
    "            case TokenTypes.INTEGER.value:\n",
    "                return Token(TokenTypes.INTEGER, TokenTypes.INTEGER.value)\n",
    "            case TokenTypes.IDENTIFIER.value:\n",
    "                return Token(TokenTypes.IDENTIFIER, TokenTypes.IDENTIFIER.value)\n",
    "            case TokenTypes.INT_TYPE.value:\n",
    "                return Token(TokenTypes.INT_TYPE, TokenTypes.INT_TYPE.value)\n",
    "            case TokenTypes.TUPLE_TYPE.value:\n",
    "                return Token(TokenTypes.TUPLE_TYPE, TokenTypes.TUPLE_TYPE.value)\n",
    "            case TokenTypes.ARRAY_TYPE.value:\n",
    "                return Token(TokenTypes.ARRAY_TYPE, TokenTypes.ARRAY_TYPE.value)\n",
    "            case TokenTypes.FAIL.value:\n",
    "                return Token(TokenTypes.FAIL, TokenTypes.FAIL.value)\n",
    "            case TokenTypes.PLUS.value:\n",
    "                return Token(TokenTypes.PLUS, TokenTypes.PLUS.value)\n",
    "            case TokenTypes.MINUS.value:\n",
    "                return Token(TokenTypes.MINUS, TokenTypes.MINUS.value)\n",
    "            case TokenTypes.MULTIPLY.value:\n",
    "                return Token(TokenTypes.MULTIPLY, TokenTypes.MULTIPLY.value)\n",
    "            case TokenTypes.DIVIDE.value:\n",
    "                return Token(TokenTypes.DIVIDE, TokenTypes.DIVIDE.value)\n",
    "            case TokenTypes.GREATER.value:\n",
    "                return self.get_greater_eq()\n",
    "            case TokenTypes.GREATEREQ.value:\n",
    "                return Token(TokenTypes.GREATEREQ, TokenTypes.GREATEREQ.value)\n",
    "            case TokenTypes.LOWER.value:\n",
    "                return self.get_lower_eq()\n",
    "            case TokenTypes.LOWEREQ.value:\n",
    "                return Token(TokenTypes.LOWEREQ, TokenTypes.LOWEREQ.value)\n",
    "            case TokenTypes.CHOICE.value:\n",
    "                return Token(TokenTypes.CHOICE, TokenTypes.CHOICE.value)\n",
    "            case TokenTypes.FOR.value:\n",
    "                return Token(TokenTypes.FOR, TokenTypes.FOR.value)\n",
    "            case TokenTypes.DO.value:\n",
    "                return Token(TokenTypes.DO, TokenTypes.DO.value)\n",
    "            case TokenTypes.IF.value:\n",
    "                return Token(TokenTypes.IF, TokenTypes.IF.value)\n",
    "            case TokenTypes.THEN.value:\n",
    "                return Token(TokenTypes.THEN, TokenTypes.THEN.value)\n",
    "            case TokenTypes.ELSE.value:\n",
    "                return Token(TokenTypes.ELSE, TokenTypes.ELSE.value)\n",
    "            case TokenTypes.EOF.value:\n",
    "                return Token(TokenTypes.EOF, TokenTypes.EOF.value)\n",
    "            case TokenTypes.COLON.value:\n",
    "                return self.get_binding()\n",
    "            case TokenTypes.COMMA.value:\n",
    "                return Token(TokenTypes.COMMA, TokenTypes.COMMA.value)\n",
    "            case TokenTypes.SEMICOLON.value:\n",
    "                return Token(TokenTypes.SEMICOLON, TokenTypes.SEMICOLON.value)\n",
    "            case TokenTypes.BINDING.value:\n",
    "                return Token(TokenTypes.BINDING, TokenTypes.BINDING.value)\n",
    "            case TokenTypes.LBRACKET.value:\n",
    "                return Token(TokenTypes.LBRACKET, TokenTypes.LBRACKET.value)\n",
    "            case TokenTypes.RBRACKET.value:\n",
    "                return Token(TokenTypes.RBRACKET, TokenTypes.RBRACKET.value)\n",
    "            case TokenTypes.RBRACKET.value:\n",
    "                return Token(TokenTypes.RBRACKET, TokenTypes.RBRACKET.value)\n",
    "            case TokenTypes.SBR.value:\n",
    "                return Token(TokenTypes.SBR, TokenTypes.SBR.value)\n",
    "            case TokenTypes.CBL.value:\n",
    "                return Token(TokenTypes.CBL, TokenTypes.CBL.value)\n",
    "            case TokenTypes.CBR.value:\n",
    "                return Token(TokenTypes.CBR, TokenTypes.CBR.value)\n",
    "            case TokenTypes.SBL.value:\n",
    "                return Token(TokenTypes.SBL, TokenTypes.SBL.value)\n",
    "            case TokenTypes.EQUAL.value:\n",
    "                return self.get_lambda()\n",
    "            case TokenTypes.SCOPE.value:\n",
    "                return Token(TokenTypes.SCOPE, TokenTypes.SCOPE.value)\n",
    "            case TokenTypes.DOT.value:\n",
    "                return Token(TokenTypes.DOT, TokenTypes.DOT.value)\n",
    "            case _:\n",
    "                return Token(TokenTypes.EOF, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if is of the tokentype: TokenTypes.IF\n",
      "( is of the tokentype: TokenTypes.LBRACKET\n",
      "x is of the tokentype: TokenTypes.IDENTIFIER\n",
      "= is of the tokentype: TokenTypes.EQUAL\n",
      "0 is of the tokentype: TokenTypes.INTEGER\n",
      ") is of the tokentype: TokenTypes.RBRACKET\n",
      "then is of the tokentype: TokenTypes.THEN\n",
      "{ is of the tokentype: TokenTypes.CBL\n",
      "y is of the tokentype: TokenTypes.IDENTIFIER\n",
      "= is of the tokentype: TokenTypes.EQUAL\n",
      "3 is of the tokentype: TokenTypes.INTEGER\n",
      "; is of the tokentype: TokenTypes.SEMICOLON\n",
      "z is of the tokentype: TokenTypes.IDENTIFIER\n",
      "= is of the tokentype: TokenTypes.EQUAL\n",
      "4 is of the tokentype: TokenTypes.INTEGER\n",
      "} is of the tokentype: TokenTypes.CBR\n",
      "else is of the tokentype: TokenTypes.ELSE\n",
      "{ is of the tokentype: TokenTypes.CBL\n",
      "y is of the tokentype: TokenTypes.IDENTIFIER\n",
      "= is of the tokentype: TokenTypes.EQUAL\n",
      "232 is of the tokentype: TokenTypes.INTEGER\n",
      "; is of the tokentype: TokenTypes.SEMICOLON\n",
      "z is of the tokentype: TokenTypes.IDENTIFIER\n",
      "= is of the tokentype: TokenTypes.EQUAL\n",
      "913 is of the tokentype: TokenTypes.INTEGER\n",
      "} is of the tokentype: TokenTypes.CBR\n",
      "; is of the tokentype: TokenTypes.SEMICOLON\n"
     ]
    }
   ],
   "source": [
    "lexer = lexicon(\"if (x=0) then { y=3; z=4 } else { y=232; z=913 };\")\n",
    "\n",
    "while lexer.current_char is not None:\n",
    "    token = lexer.get_token(lexer.current_char)\n",
    "    print(str(token.value) + \" is of the tokentype: \" + str(token.type))\n",
    "    lexer.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Class that takes a parsed node, containes information if node could have been parsed\n",
    "class ParsedNode:\n",
    "    def __init__(self, node, hasSyntaxError:bool ):\n",
    "        self.node = node\n",
    "        self.hasSyntaxError = hasSyntaxError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "class BaseNode:\n",
    "    def __init__(self, token) -> None:\n",
    "        self.token = token\n",
    "        self.current_scope = 0\n",
    "\n",
    "    def visit(self, node):\n",
    "        if isinstance(node, ProgramNode):\n",
    "                return self.visit_programNode(node)\n",
    "        elif isinstance(node, BlockNode):\n",
    "                return self.visit_blockNode(node)\n",
    "        elif isinstance(node, ScopeNode):\n",
    "                return self.visit_scopeNode(node)\n",
    "        elif isinstance(node, BindingNode):\n",
    "                return self.visit_bindingNode(node)\n",
    "        elif isinstance(node, OperatorNode):\n",
    "                return self.visit_operatorNode(node)\n",
    "        elif isinstance(node, NumberNode):\n",
    "                return self.visit_numberNode(node)\n",
    "        elif isinstance(node, FailNode):\n",
    "                return self.visit_failNode(node)\n",
    "        elif isinstance(node, UnaryNode):\n",
    "                return self.visit_unaryNode(node)\n",
    "        elif isinstance(node, ParsedNode):\n",
    "             return self.visit(node.node)\n",
    "        elif isinstance(node, ForNode):\n",
    "            return self.visit_forNode(node)\n",
    "        elif isinstance(node, ScopeNode):\n",
    "            return self.visit_scopeNode(node)\n",
    "        elif isinstance(node, ForNode):\n",
    "            return self.visit_forNode(node)\n",
    "        elif isinstance(node, SequenceNode):\n",
    "            return self.visit_sequenceNode(node)\n",
    "        \n",
    "        \n",
    "\n",
    "    def visit_blockNode(self, node):\n",
    "            for n in node.nodes:\n",
    "                return self.visit(n)\n",
    "            \n",
    "    def visit_programNode(self, node):\n",
    "        return self.visit(node.node)\n",
    "\n",
    "   \n",
    "    def visit_scopeNode(self, node):\n",
    "        # token:Token, nodes:list[BaseNode], type\n",
    "        pass\n",
    "\n",
    "    def visit_bindingNode(self, node):\n",
    "        # token:Token, leftNode:IdentifierNode, rightNode:BaseNode\n",
    "        identifierName:string = node.leftNode.token.type.value\n",
    "        # Check if identifer exists outside its scope level\n",
    "\n",
    "        # If not exists:\n",
    "        val = self.visit(node.rightNode)\n",
    "        if(val.type == NodeStatus.NOT_ASSIGNED_YET):\n",
    "             return val\n",
    "        # safe identifier wit val and its scope level\n",
    "        pass\n",
    "\n",
    "    def visit_numberNode(self, node):\n",
    "        return VisitorNode(NodeStatus.VALUE_RECEIVABLE, NumberNode(node.token))\n",
    "    \n",
    "    def visit_operatorNode(self, node):\n",
    "\n",
    "        val_left = self.visit(node.leftNode)\n",
    "        if val_left.node.token.type == TokenTypes.FAIL:\n",
    "                return val_left\n",
    "        val_right = self.visit(node.rightNode)\n",
    "        if val_right.node.token.type == TokenTypes.FAIL:\n",
    "                return val_right\n",
    "        \n",
    "        return self.GetNodeForOperation(val_left,val_right,node.token)\n",
    "        \"\"\"\n",
    "        match node.token.type:\n",
    "            case TokenTypes.DIVIDE:\n",
    "                return self.visit(node.leftNode) // self.visit(node.rightNode)\n",
    "            case TokenTypes.MULTIPLY:\n",
    "                return val_left.value * val_right.value\n",
    "            case TokenTypes.PLUS:              \n",
    "                return self.GetNodeForOperation(val_left,val_right)\n",
    "            case TokenTypes.MINUS:\n",
    "                return self.visit(node.leftNode) - self.visit(node.rightNode)       \n",
    "            case TokenTypes.GREATER:\n",
    "                if val_left.value > val_right.value:\n",
    "                    return val_left\n",
    "                else: return Value(ValueTypes.FAIL,ValueTypes.FAIL.value)\n",
    "            case TokenTypes.LOWER:\n",
    "                if val_left.value < val_right.value:\n",
    "                    return val_left\n",
    "                else: return Value(ValueTypes.FAIL,ValueTypes.FAIL.value)  \n",
    "            case TokenTypes.DOT:\n",
    "                return [i for i in range(self.visit(node.leftNode), self.visit(node.rightNode)+1)]\n",
    "        \"\"\"\n",
    "    def GetNodeForOperation(self,val_left,val_right, opToken:Token):\n",
    "        nodes = []\n",
    "        nodeStatus = NodeStatus.VALUE_RECEIVABLE\n",
    "        token = None\n",
    "\n",
    "        if val_left.node.token.type == TokenTypes.CHOICE:\n",
    "            token = val_left.node.token\n",
    "            for n in val_left.node.nodes:\n",
    "                if val_right.node.token.type == TokenTypes.CHOICE:\n",
    "                    for n2 in val_right.node.nodes:\n",
    "                       node = self.doOperation(n.value,n2.value,opToken)\n",
    "                       nodes.append(node)\n",
    "                else:nodes.append(self.doOperation(n.value,val_right.node.token.value,opToken)) \n",
    "\n",
    "        elif val_right.node.token.type == TokenTypes.CHOICE:\n",
    "            token = val_right.node.token\n",
    "            for n in val_right.node.nodes:\n",
    "               nodes.append(self.doOperation(n.value,val_left.node.token.value,opToken)) \n",
    "\n",
    "        elif val_left.node.token.type == TokenTypes.INTEGER and val_right.node.token.type == TokenTypes.INTEGER:\n",
    "             return VisitorNode(nodeStatus, NumberNode(Token(TokenTypes.INTEGER,val_left.node.token.value + val_right.node.token.value)))\n",
    "        return VisitorNode(nodeStatus,SequenceNode(token, nodes))\n",
    "                             \n",
    "    def doOperation(self,val1:int,val2:int, token:Token):\n",
    "        result = 0\n",
    "        match token.type:\n",
    "            case TokenTypes.DIVIDE:\n",
    "                result = val1 // val2\n",
    "            case TokenTypes.MULTIPLY:\n",
    "                result = val1 * val2\n",
    "            case TokenTypes.PLUS:              \n",
    "                result = val1 + val2\n",
    "            case TokenTypes.MINUS:\n",
    "                result = val1 - val2      \n",
    "            case TokenTypes.GREATER:\n",
    "                if val1 > val2:\n",
    "                    result = val1\n",
    "                else: return FailNode(Token(TokenTypes.FAIL, TokenTypes.FAIL.value)) \n",
    "            case TokenTypes.LOWER:\n",
    "                if val1:\n",
    "                    result = val1\n",
    "                else: return FailNode(Token(TokenTypes.FAIL, TokenTypes.FAIL.value)) \n",
    "        return  NumberNode(Token(TokenTypes.INTEGER, result))  \n",
    "           \n",
    "    def visit_unaryNode(self, node):\n",
    "        mul:int = 1\n",
    "        if node.token.type == TokenTypes.MINUS:\n",
    "            mul = -1\n",
    "        val = self.visit(node.node)\n",
    "        if(val.type == ValueTypes.FAIL):\n",
    "            return(val)\n",
    "        return Value(ValueTypes.INTEGER, mul * self.visit(node.node).value)\n",
    "    \n",
    "    def visit_identifierNode(self, node):\n",
    "        # Check in scope table if exists\n",
    "        # if not return Value(ValueTypes.NOT_ASSIGNED_YET, node.token.type.value)\n",
    "        # else return its value: Value(...)\n",
    "        pass\n",
    "\n",
    "    def visit_typeNode(self, node):\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def visit_sequenceTypeNode(self, node):\n",
    "       pass\n",
    "         \n",
    "\n",
    "    def visit_argumentsNode(self, node):\n",
    "        pass\n",
    "\n",
    "    def visit_funcCallNode(self, node):\n",
    "        pass\n",
    "\n",
    "    def visit_ParamsNode(self, node):\n",
    "        pass\n",
    "    def visit_funcDeclNode(self, node):\n",
    "        pass\n",
    "    def visit_forNode(self, node):\n",
    "        pass\n",
    "    def visit_ifNode(self, node):\n",
    "        pass\n",
    "    def visit_rigidEqNode(self, node):\n",
    "        # token:Token, left_node:BaseNode, right_node:BaseNode\n",
    "        \"\"\"\n",
    "        val_left = self.visit(node.leftNode)\n",
    "        if val_left.type == ValueTypes.FAIL:\n",
    "                return val_left\n",
    "        val_right = self.visit(node.rightNode)\n",
    "        if val_right.type == ValueTypes.FAIL:\n",
    "                return val_right\n",
    "        if val_left.value == val_right:\n",
    "            return val_left\n",
    "        else: Value(ValueTypes.FAIL, ValueTypes.FAIL.value)\n",
    "        \"\"\"\n",
    "        \n",
    "    def visit_flexibleEqNode(self, node):\n",
    "        # token:Token, left_node:BaseNode, right_node:BaseNode\n",
    "        if(node.token.type == TokenTypes.IDENTIFIER):\n",
    "             # Get type of node tuple(int,int) (21+2,3*2)\n",
    "            \n",
    "            pass\n",
    "        pass\n",
    "    def visit_sequenceNode(self, node):\n",
    "        nodeStatus:NodeStatus = NodeStatus.VALUE_RECEIVABLE\n",
    "        finalNodes = []\n",
    "        nodes = []\n",
    "        if node.token.type == TokenTypes.CHOICE:\n",
    "            for n in node.nodes:\n",
    "                    current_n = self.visit(n)\n",
    "                    if current_n.type == NodeStatus.NOT_ASSIGNED_YET:\n",
    "                         nodeStatus = NodeStatus.NOT_ASSIGNED_YET\n",
    "\n",
    "                    elif current_n.type == NodeStatus.ERROR:\n",
    "                         nodeStatus = NodeStatus.ERROR\n",
    "                         print(\"Error in sequence visitor for CHOICE\")\n",
    "                         break \n",
    "                    \n",
    "                    if current_n.node.token.type != TokenTypes.FAIL:\n",
    "                         nodes.append(current_n.node)  \n",
    "\n",
    "            if(len(nodes) == 0):\n",
    "                return VisitorNode(nodeStatus,FailNode(Token(TokenTypes.FAIL,TokenTypes.FAIL.value)))\n",
    "            if(len(nodes) == 1):\n",
    "                 return VisitorNode(nodeStatus,nodes[0].node) \n",
    "            return VisitorNode(nodeStatus,SequenceNode(node.token, nodes))\n",
    "        \n",
    "       \n",
    "        else:\n",
    "            '''\n",
    "            Visit something for tuple/array sequences.\n",
    "            What it does it visits the nodes of the tuple/array and\n",
    "            stores them in a nodes list.\n",
    "            Choices (1|2) will be appended as such: [NN(1),NN(2)]\n",
    "\n",
    "            Integers, Tuple/Array etc (1,2) , 3 as such:\n",
    "            Tuple/Array:  [SN( NN(1), NN(2) )]        Integers:  [NN(1)]\n",
    "            This Type of Converting only occures if the first element is a choice in\n",
    "\n",
    "            a tuple/array sequence.\n",
    "            ill-formed tuple/array : ( 1, (2|3) )\n",
    "            ok: ((2|3), 1, (4,5))\n",
    "            This should be the outcome in get_choiceSequence():  (2,1,4,5) | (3,1,4,5)\n",
    "            '''\n",
    "\n",
    "            nodes = []\n",
    "            if node.nodes[0].token.type == TokenTypes.CHOICE:\n",
    "                for n in node.nodes:\n",
    "                    current_n = self.visit(n)\n",
    "                    if current_n.node.token.type == TokenTypes.CHOICE:\n",
    "                        nodes.append(current_n.node.nodes)\n",
    "                    else: nodes.append([current_n.node])\n",
    "                return self.get_choiceSequence(nodes)\n",
    "            else: \n",
    "                for n in node.nodes:\n",
    "                    current_n = self.visit(n)\n",
    "                    if current_n.node.token.type == TokenTypes.FAIL:\n",
    "                        # If one node fails in tuple/array, return FailNode\n",
    "                        return VisitorNode(nodeStatus.VALUE_RECEIVABLE, FailNode(Token(TokenTypes.FAIL,TokenTypes.FAIL.value)))          \n",
    "                    nodes.append(current_n.node)\n",
    "                   \n",
    "                return VisitorNode(nodeStatus.VALUE_RECEIVABLE, SequenceNode(Token(TokenTypes.ARRAY_TYPE,TokenTypes.ARRAY_TYPE.value),nodes))          \n",
    "\n",
    "\n",
    "    '''\n",
    "    Gets the nodes from sequence visitor.\n",
    "    Turns a tuple/array sequence of tuples containing choices into a\n",
    "    choice sequence.\n",
    "    Example:\n",
    "    \n",
    "    Tuple/Array with choices: (8|39) , (9|40)\n",
    "    Resulting choice Sequence: ( (8,9) | (8,40) | (39,9) | (39,40) ).\n",
    "    '''\n",
    "    def get_choiceSequence(self,nodes):\n",
    "        finalnodes = []\n",
    "        combined_nodes = list(itertools.product(*nodes))\n",
    "        for cd in combined_nodes:\n",
    "            current_nodes = []\n",
    "            for cd2 in cd:\n",
    "                if cd2.token.type == TokenTypes.ARRAY_TYPE or cd2.token.type == TokenTypes.TUPLE_TYPE:\n",
    "                    for cd3 in cd2.nodes:\n",
    "                        current_nodes.append(cd3)\n",
    "                else: current_nodes.append(cd2) \n",
    "            finalnodes.append(current_nodes)\n",
    "        return VisitorNode(NodeStatus.VALUE_RECEIVABLE,SequenceNode(Token(TokenTypes.CHOICE, TokenTypes.CHOICE.value), finalnodes))\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "    def visit_indexingNode(self, node):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    def visit_failNode(self, node):\n",
    "        return VisitorNode(NodeStatus.VALUE_RECEIVABLE, node)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "class BlockNode(BaseNode):\n",
    "    def __init__(self, nodes:list[BaseNode]) -> None:\n",
    "        self.nodes:list[BaseNode] = nodes\n",
    "         \n",
    "    \n",
    "\n",
    "class ProgramNode(BaseNode):\n",
    "    def __init__(self, node:BlockNode) -> None:\n",
    "        self.node = node\n",
    "\n",
    "class ScopeNode(BaseNode):\n",
    "    def __init__(self, token:Token, nodes:list[BaseNode], type) -> None: #Change into Variable/IdentifierNode\n",
    "        super().__init__(token)\n",
    "        self.nodes = nodes\n",
    "        self.type = type\n",
    "\n",
    "\n",
    "\n",
    "class NumberNode(BaseNode):\n",
    "    def __init__(self, token:Token) -> None:\n",
    "        super().__init__(token)\n",
    "        self.value = token.value\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "         return str(self.value)\n",
    "\n",
    "class OperatorNode(BaseNode):\n",
    "    def __init__(self, token:Token, leftNode: BaseNode, rightNode: BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.leftNode = leftNode\n",
    "        self.rightNode = rightNode\n",
    "\n",
    "class UnaryNode(BaseNode):\n",
    "     def __init__(self, token:Token, node) -> None:\n",
    "        super().__init__(token)\n",
    "        self.node = node\n",
    "\n",
    "class IdentifierNode(BaseNode):\n",
    "    def __init__(self, token:Token) -> None: #Change into Variable/IdentifierNode\n",
    "        super().__init__(token)\n",
    "        \n",
    "class BindingNode(BaseNode):\n",
    "    def __init__(self,token:Token, leftNode:IdentifierNode, rightNode:BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.leftNode = leftNode\n",
    "        self.rightNode = rightNode\n",
    "\n",
    "class TypeNode(BaseNode):\n",
    "    def __init__(self, token:Token) -> None: \n",
    "        super().__init__(token)\n",
    "        self.type = type\n",
    "\n",
    "class SequenceTypeNode(TypeNode):\n",
    "    def __init__(self, token:Token, types:list[TypeNode]) -> None: \n",
    "        super().__init__(token)\n",
    "        self.types = types\n",
    "\n",
    "\n",
    "class ArgumentsNode: \n",
    "    def __init__(self, nodes:list[BaseNode]) -> None: \n",
    "        self.nodes = nodes\n",
    "\n",
    "class FuncCallNode:\n",
    "    def __init__(self,identifier:IdentifierNode, args:ArgumentsNode) -> None:\n",
    "        self.identifier = identifier\n",
    "        self.args = args\n",
    "\n",
    "class ParamsNode:\n",
    "    def __init__(self, nodes:list[ScopeNode]) -> None:\n",
    "        self.nodes = nodes\n",
    "\n",
    "class FuncDeclNode:\n",
    "    def __init__(self,identifier:IdentifierNode, nodes:list[ParamsNode],usesLambda:bool, type:TypeNode, block:BlockNode) -> None:\n",
    "        self.identifier = identifier\n",
    "        self.nodes = nodes\n",
    "        self.usesLambda = usesLambda\n",
    "        self.type = type\n",
    "        self.block = block\n",
    "\n",
    "class ForNode(BaseNode):\n",
    "     def __init__(self, token:Token, node: BaseNode, condition: BaseNode, expr: BaseNode, do: BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.node = node\n",
    "        self.condition = condition\n",
    "        self.expr = expr\n",
    "        self.do = do\n",
    "\n",
    "class IfNode(BaseNode):\n",
    "     def __init__(self, token:Token, if_node: BaseNode, then_node: BaseNode, else_node: BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.if_node = if_node\n",
    "        self.then_node = then_node\n",
    "        self.else_node = else_node\n",
    "\n",
    "class RigidEqNode(BaseNode):\n",
    "     def __init__(self, token:Token, left_node:BaseNode, right_node:BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.left_node = left_node\n",
    "        self.right_node = right_node\n",
    "\n",
    "class FlexibleEqNode(BaseNode):\n",
    "     def __init__(self, token:Token, left_node:BaseNode, right_node:BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.left_node = left_node\n",
    "        self.right_node = right_node\n",
    "\n",
    "class SequenceNode(BaseNode):\n",
    "     def __init__(self, token:Token, nodes:list[BaseNode]) -> None:\n",
    "        super().__init__(token)\n",
    "        self.nodes = nodes\n",
    "        self.seperator = \",\"\n",
    "        \n",
    "     def __repr__(self) -> str:\n",
    "        if self.token.type == TokenTypes.CHOICE:\n",
    "            self.seperator = self.token.value     \n",
    "        return self.seperator.join([repr(n) for n in self.nodes])\n",
    "\n",
    "class IndexingNode(BaseNode):\n",
    "      def __init__(self, token:Token,identifier:IdentifierNode, index:BaseNode) -> None:\n",
    "        super().__init__(token)\n",
    "        self.identifier = identifier\n",
    "        self.index = index\n",
    "\n",
    "class FailNode(BaseNode): # Technically not need, since Fail node is 1 to 1 a BaseNode\n",
    "      def __init__(self, token:Token) -> None:\n",
    "        super().__init__(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Symboltable:\n",
    "    def __init__(self) -> None:\n",
    "        self.symboltable = []\n",
    "    \n",
    "    def __info__(self) -> None:\n",
    "        for t in self.symboltable:\n",
    "            print(\"Symboltable: Name= {}, Value= {}, ParentNode= {}\".format(t[0], t[1], t[2]))\n",
    "    \n",
    "    def check_if_exists(self, name: string, parentNode: BaseNode) -> bool:\n",
    "        for symbol in self.symboltable:\n",
    "            if symbol[0] == name:\n",
    "                if symbol[2] == parentNode:\n",
    "                    return True \n",
    "        return False\n",
    "    \n",
    "    def add(self, name: string, value: BaseNode, parentNode: BaseNode) -> None:\n",
    "        # checks if the name already exists in the current scope. Otherwise add to table.\n",
    "        if self.check_if_exists(name, parentNode) == False:\n",
    "            self.symboltable.append([name, value, parentNode])\n",
    "    \n",
    "    def remove(self, name:string, value: BaseNode, parentNode: BaseNode) -> None:\n",
    "        # checks if the table is empty.\n",
    "        if len(self.symboltable) < 1:\n",
    "            return\n",
    "        \n",
    "        # iterates through and removes the corresponding \n",
    "        for symbol in self.symboltable:\n",
    "            if symbol[0] == name:\n",
    "                if symbol[2] == parentNode:\n",
    "                    self.symboltable.remove([name, value, parentNode]) \n",
    "    \n",
    "    def get_value(self, name: string, parentNode: BaseNode) -> tuple[bool, BaseNode]:\n",
    "        for symbol in self.symboltable:\n",
    "            if symbol[0] == name:\n",
    "                if symbol[2] == parentNode:\n",
    "                    return True, symbol[1]\n",
    "        return False, parentNode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: 7\n"
     ]
    }
   ],
   "source": [
    "table = Symboltable()\n",
    "parentNode = NumberNode(Token(TokenTypes.INTEGER, 6))\n",
    "table.remove(\"x\", NumberNode(Token(TokenTypes.INTEGER, 7)), parentNode)\n",
    "table.add(\"y\", NumberNode(Token(TokenTypes.INTEGER, 7)), parentNode)\n",
    "valid, value = table.get_value(\"y\", parentNode)\n",
    "if valid:\n",
    "    print( \"y: \" + repr(value.visit(value).node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, lexer: lexicon):\n",
    "       self.logger: Logger = Console_Logger()\n",
    "       self.end = False\n",
    "       self.lexer = lexer\n",
    "       self.current_token = lexer.get_token(self.lexer.current_char)\n",
    "       \n",
    "\n",
    "    def parse(self) -> BaseNode:     \n",
    "        node = self.program()\n",
    "        if node.hasSyntaxError or self.current_token.type != TokenTypes.EOF:\n",
    "            self.logger.__log_error__(\"it appears there was a problem\", ErrorType.SyntaxError)\n",
    "        return node.node\n",
    "    \n",
    "\n",
    "       \n",
    "    #####################################\n",
    "    # statements\n",
    "    #####################################\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the program has either statements or function calls.\n",
    "    Rule => statement_list | func_decl (SEMI statement_list | func_decl)*?\n",
    "    \"\"\"\n",
    "    def program(self) -> ParsedNode:\n",
    "        \n",
    "        index = self.lexer.index\n",
    "        token = self.current_token\n",
    "        \n",
    "        #node = self.func_decl()\n",
    "\n",
    "        # checks if start of the program is not a block but a function.\n",
    "        #if(node.hasSyntaxError == True):\n",
    "        #    self.set_to_token(index, token)\n",
    "        node = self.block()\n",
    "        \n",
    "        # checks if the program is not a function either.\n",
    "        if(node.hasSyntaxError == True):\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        nodes = node\n",
    "        \n",
    "        return ParsedNode(ProgramNode(nodes.node), False)\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the program has a list of statements.\n",
    "    Rule => statement_list\n",
    "   \n",
    "    def blockdelete(self) -> ParsedNode:\n",
    "        \n",
    "        nodes = self.statement_list()\n",
    "        if(nodes[0].hasSyntaxError):\n",
    "            return ParsedNode(None, True)\n",
    "        return ParsedNode(BlockNode(nodes), False)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Checks if there are one or more statements.\n",
    "    Rule => statement (SEMI statement)*?   \n",
    "    \"\"\"\n",
    "    def block(self) -> ParsedNode:\n",
    "        node = self.statement()\n",
    "        nodes = []\n",
    "        nodes.append(node)\n",
    "\n",
    "        if(node.hasSyntaxError==False):\n",
    "            if(self.current_token.type == TokenTypes.SEMICOLON):\n",
    "                while(self.current_token.type == TokenTypes.SEMICOLON):\n",
    "                    self.forward()\n",
    "                    node = self.statement()\n",
    "                    if node.hasSyntaxError:\n",
    "                        return ParsedNode(None,True)\n",
    "                    else: nodes.append(node)\n",
    "                return ParsedNode(BlockNode(nodes), False)\n",
    "        return node\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the current node is either an expression statemnts, if statement, for statement, a function call or an assignment statemnt.\n",
    "    Rule => expr | if | for | func_call | assign_statement\n",
    "    \"\"\"\n",
    "    def statement(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "\n",
    "        node: ParsedNode = self.nested_scope()\n",
    "\n",
    "        # checks if current node is not an expression.\n",
    "        if(node.hasSyntaxError == True):\n",
    "             self.set_to_token(index,token)\n",
    "             node = self.flexible_eq()\n",
    "             \n",
    "        if(node.hasSyntaxError == True):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.expr()\n",
    "        \n",
    "        if(node.hasSyntaxError == True):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.func_decl()\n",
    "\n",
    "            \n",
    "       \n",
    "       \n",
    "        \n",
    "        \n",
    "        # checks if current node is not an if statement either.\n",
    "       # if(node.hasSyntaxError == True):\n",
    "        #     self.set_to_token(index)\n",
    "         #    node = self.for_loop()\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    \"\"\"\n",
    "    Flexible Eq Statement (Used only to give something a value)\n",
    "    Rule -> (Identifier EQUAL expr)\n",
    "    \"\"\"\n",
    "    def flexible_eq(self)-> ParsedNode:\n",
    "        left_node = self.identifier()\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.current_token.type == TokenTypes.EQUAL):\n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "                right_node = self.block()\n",
    "                if(right_node.hasSyntaxError == False):\n",
    "                    return ParsedNode(FlexibleEqNode(token,left_node.node,right_node.node), False)\n",
    "        return ParsedNode(None,True)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Rigid Eq Statement (Used only to check if two expr are equals)\n",
    "    Rule -> (expr (EQUAL expr)*?)\n",
    "    \"\"\"\n",
    "    def rigid_eq(self) -> ParsedNode:\n",
    "        left_node = self.block()\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.current_token.type == TokenTypes.EQUAL):\n",
    "                node = ParsedNode(None,True)\n",
    "                while self.current_token.type == TokenTypes.EQUAL:\n",
    "                    token = self.current_token\n",
    "                    self.forward()\n",
    "                    right_node = self.block()\n",
    "                    if(right_node.hasSyntaxError == False):\n",
    "                        if(node.node == None):\n",
    "                                node = RigidEqNode(token,left_node.node,right_node.node)\n",
    "                        if(self.current_token.type == TokenTypes.EQUAL):\n",
    "                            node = RigidEqNode(token, node, right_node)\n",
    "                    else: return ParsedNode(None,True)\n",
    "                return ParsedNode(node,False)\n",
    "            return left_node\n",
    "        return ParsedNode(None,True)\n",
    "   \n",
    "  \n",
    "    \"\"\"\n",
    "    Checks for a function call.\n",
    "    Rule => IDENTIFIER LB (func_call_args)? RB \n",
    "    \"\"\"\n",
    "    def func_call(self) -> ParsedNode:\n",
    "        # RULE --> IDENTIFIER LB (func_call_param)? RB  NOT IMPLEMENTED\n",
    "        node = self.identifier()\n",
    "        if(node.hasSyntaxError):\n",
    "            return ParsedNode(None, True)  \n",
    "        if(self.current_token.type == TokenTypes.LBRACKET):\n",
    "            self.forward()\n",
    "            \n",
    "            # checks if it is an empty function call.\n",
    "            if self.current_token.type == TokenTypes.RBRACKET:\n",
    "                self.forward()\n",
    "                return ParsedNode(FuncCallNode(node, None), False)\n",
    "\n",
    "            params = self.func_call_args()\n",
    "            for param in params:\n",
    "                if param.hasSyntaxError:\n",
    "                    return ParsedNode(None, True)\n",
    "                \n",
    "            if(self.current_token.type == TokenTypes.RBRACKET):\n",
    "                self.forward()\n",
    "                return ParsedNode(FuncCallNode(node, params), False)\n",
    "                \n",
    "        return node\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    Checks for the arguments of the function call.\n",
    "    Rule => expr (COMMA expr)*?  \n",
    "    \"\"\"    \n",
    "    def func_call_args(self) -> list[ParsedNode]:\n",
    "        nodes = []\n",
    "        nodes.append(self.expr())\n",
    "\n",
    "        while True:\n",
    "            if(self.current_token.type == TokenTypes.COMMA):\n",
    "                self.forward()\n",
    "                nodes.append(self.expr())\n",
    "            else:\n",
    "                for node in nodes:\n",
    "                    if node.hasSyntaxError:\n",
    "                        return [ParsedNode(None, True)]\n",
    "                break\n",
    "        \n",
    "        return nodes\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Checks for the declaration of a function.\n",
    "    Rule => IDENTIFIER LB func_dec_param RB (COLON type)? BINDING block\n",
    "           |IDENTIFIER BINDING LB nested_scope LAMBDA expr RB    \n",
    "    \"\"\"\n",
    "    def func_decl(self) -> ParsedNode:\n",
    "        identifier = self.identifier()\n",
    "        if identifier.hasSyntaxError == False:\n",
    "\n",
    "            if self.current_token.type == TokenTypes.LBRACKET:\n",
    "                self.forward()\n",
    "\n",
    "                params = self.func_decl_param()\n",
    "\n",
    "                if self.current_token.type == TokenTypes.RBRACKET:\n",
    "                    self.forward()\n",
    "                    type = None\n",
    "                    if(self.current_token.type == TokenTypes.COLON):\n",
    "                        self.forward()\n",
    "                        type = self.type()\n",
    "                        if(type.hasSyntaxError):\n",
    "                            return ParsedNode(None,True)\n",
    "                        \n",
    "                    if self.current_token.type == TokenTypes.BINDING:\n",
    "                        self.forward()\n",
    "                        block = self.block()\n",
    "                        if(block.hasSyntaxError == False):\n",
    "                            return ParsedNode(FuncDeclNode(identifier,params,False,type,block),False)\n",
    "                return ParsedNode(None,True)\n",
    "            \n",
    "            if self.current_token.type == TokenTypes.BINDING:\n",
    "                self.forward()\n",
    "                if self.current_token.type == TokenTypes.LBRACKET:\n",
    "                    self.forward()\n",
    "                    type = None\n",
    "                    params = self.func_decl_param()\n",
    "                    if(params.hasSyntaxError):\n",
    "                        return ParsedNode(None,True)\n",
    "                    \n",
    "                    if self.current_token.type == TokenTypes.LAMBDA:\n",
    "                        self.forward()                   \n",
    "                        block = self.block()\n",
    "                        if(block.hasSyntaxError == False and self.current_token.type == TokenTypes.RBRACKET):\n",
    "                            self.forward()\n",
    "                            return ParsedNode(FuncDeclNode(identifier,params,True,type,block),False)\n",
    "                    return ParsedNode(None,True)\n",
    "\n",
    "        return ParsedNode(None,True)\n",
    "\n",
    "    \"\"\"\n",
    "    Checks for the arguments of the function declaration.\n",
    "    Rule => nested_scope\n",
    "    \"\"\"\n",
    "    def func_decl_param(self) -> ParsedNode:\n",
    "        nodes:list[ScopeNode] = []\n",
    "        if(self.current_token.type == TokenTypes.RBRACKET):\n",
    "            return ParsedNode(ParamsNode(nodes),False)\n",
    "        \n",
    "        node = self.scope()\n",
    "        if(node.hasSyntaxError == False):\n",
    "            nodes.append(node.node)\n",
    "            while(self.current_token.type == TokenTypes.COMMA):\n",
    "                self.forward()\n",
    "                node = self.scope()\n",
    "                if(node.hasSyntaxError):\n",
    "                    return ParsedNode(None,True)\n",
    "                nodes.append(node.node)\n",
    "            return ParsedNode(ParamsNode(nodes),False)\n",
    "        return ParsedNode(None,True)\n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the statement is an if statement.\n",
    "    Rule => IF LB expr RB THEN CBL block CBR ELSE CBL block CBR\n",
    "          | IF LB expr RB THEN expr ELSE expr  \n",
    "    \"\"\"\n",
    "    def if_statement(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "\n",
    "        if token.type != TokenTypes.IF:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        if self.current_token.type != TokenTypes.LBRACKET:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        if_node = self.rigid_eq()\n",
    "        if if_node.hasSyntaxError == True or self.current_token.type != TokenTypes.RBRACKET:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        if self.current_token.type != TokenTypes.THEN:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "\n",
    "        hasCB:bool = self.current_token.type == TokenTypes.CBL\n",
    "        then_node = ParsedNode(None,True)\n",
    "        else_node = ParsedNode(None,True)\n",
    "\n",
    "        if(hasCB):\n",
    "            self.forward()\n",
    "            then_node = self.block()\n",
    "            if(then_node.hasSyntaxError):\n",
    "                return ParsedNode(None,True)\n",
    "            if(self.current_token.type == TokenTypes.CBR):\n",
    "                self.forward()\n",
    "            else: return ParsedNode(None,True)\n",
    "        else:\n",
    "            then_node = self.expr()\n",
    "            if(then_node.hasSyntaxError):\n",
    "                return ParsedNode(None,True)\n",
    "            \n",
    "        if self.current_token.type != TokenTypes.ELSE:\n",
    "            return ParsedNode(None, True)     \n",
    "        self.forward()\n",
    "\n",
    "        if(hasCB and self.current_token.type == TokenTypes.CBL):\n",
    "            self.forward()\n",
    "            else_node = self.block()\n",
    "            if(then_node.hasSyntaxError):\n",
    "                return ParsedNode(None,True)\n",
    "            if(self.current_token.type == TokenTypes.CBR):\n",
    "                self.forward()\n",
    "            else: return ParsedNode(None,True)\n",
    "        else:\n",
    "            else_node = self.expr()\n",
    "            if(then_node.hasSyntaxError):\n",
    "                return ParsedNode(None,True)\n",
    "        \"\"\"\n",
    "        --Issues with brackets--\n",
    "        \n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "        then_node = self.block()\n",
    "\n",
    "        if then_node.hasSyntaxError:\n",
    "            self.set_to_token(index, token)\n",
    "            if self.current_token.type != TokenTypes.CBL:\n",
    "                return ParsedNode(None, True)\n",
    "            \n",
    "            self.forward()\n",
    "            then_node = self.expr()\n",
    "            if then_node.hasSyntaxError and self.current_token.type != TokenTypes.CBR:\n",
    "                return ParsedNode(None, True)\n",
    "        \n",
    "            self.forward()\n",
    "            if self.current_token.type != TokenTypes.ELSE:\n",
    "                return ParsedNode(None, True)\n",
    "            self.forward()\n",
    "            if self.current_token.type != TokenTypes.CBL:\n",
    "                return ParsedNode(None, True)\n",
    "            \n",
    "            self.forward()\n",
    "            else_node = self.expr()\n",
    "            if else_node.hasSyntaxError and self.current_token.type != TokenTypes.CBR:\n",
    "                return ParsedNode(None, True)\n",
    "            return ParsedNode(IfNode(token, if_node.node, then_node.node, else_node.node),False)\n",
    "\n",
    "        if self.current_token.type != TokenTypes.ELSE:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        else_node = self.block()\n",
    "\n",
    "        if else_node.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "        \"\"\"\n",
    "        return ParsedNode(IfNode(token, if_node.node, then_node.node, else_node.node),False)\n",
    "            \n",
    "\n",
    "    \"\"\"\n",
    "    Checks the 'Then' part of the if-statement.\n",
    "    Rule => expr | (CBL block CBR)\n",
    "    \n",
    "    def then_statement(self) -> ParsedNode:\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "    Checks the 'else' part of the if-statement.\n",
    "    Rule => expr | (CBL block CBR)\n",
    "    \n",
    "    def else_statement(self) -> ParsedNode:\n",
    "        pass\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the statement is a loop expression.\n",
    "    Rule => FOR CBL (scope|expr) (;expr)*? CBR\n",
    "          | FOR LB (scope|expr) (,expr)*? RB DO expr\n",
    "    \"\"\"\n",
    "    def for_loop(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "\n",
    "        if token.type != TokenTypes.FOR:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        # checks if the for loop is defined with a curly bracket.\n",
    "        if self.current_token.type == TokenTypes.CBL:\n",
    "            self.forward()\n",
    "            return self.for_loop_curly()\n",
    "        elif self.current_token.type == TokenTypes.LBRACKET:\n",
    "            self.forward()\n",
    "            return self.for_loop_bracket()\n",
    "\n",
    "        return ParsedNode(None, True)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def for_loop_curly(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "\n",
    "        node = self.scope()\n",
    "        condition: ParsedNode\n",
    "        expression: ParsedNode\n",
    "\n",
    "        # checks if the loop content is not a scope but an expression.\n",
    "        if node.hasSyntaxError:\n",
    "            self.set_to_token(index, token)\n",
    "            node = self.expr()\n",
    "        \n",
    "        # checks if the loop input is invalid.\n",
    "        if node.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        if self.current_token.type == TokenTypes.CBR:\n",
    "            self.forward()\n",
    "            return ParsedNode(ForNode(TokenTypes.FOR, node.node, None, None,None), False)\n",
    "        \n",
    "        self.forward()\n",
    "        condition = self.expr()\n",
    "\n",
    "        if condition.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "\n",
    "        if self.current_token.type == TokenTypes.SEMICOLON:\n",
    "            self.forward()\n",
    "            expression = self.expr()\n",
    "        \n",
    "            if self.current_token.type != TokenTypes.CBR or expression.hasSyntaxError:\n",
    "                return ParsedNode(None, True)\n",
    "        \n",
    "            return ParsedNode(ForNode(TokenTypes.FOR, node.node, condition.node, expression.node),False)\n",
    "        \n",
    "        if self.current_token.type == TokenTypes.CBR:\n",
    "            self.forward()\n",
    "            return ParsedNode(ForNode(TokenTypes.FOR, node.node, None, condition.node, None), False)\n",
    "        \n",
    "        return ParsedNode(None, True)\n",
    "    \n",
    "    def for_loop_bracket(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "        \n",
    "        node = self.scope()\n",
    "        condition: ParsedNode\n",
    "        expression: ParsedNode\n",
    "\n",
    "        # checks if the loop content is not a scope but an expression.\n",
    "        if node.hasSyntaxError:\n",
    "            self.set_to_token(index, token)\n",
    "            node = self.expr()\n",
    "        \n",
    "        # checks if the loop input is invalid.\n",
    "        if node.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        if self.current_token == TokenTypes.RBRACKET:\n",
    "            self.forward()\n",
    "            return ParsedNode(ForNode(TokenTypes.FOR, node.node, None, None,None), False)\n",
    "        \n",
    "        self.forward()\n",
    "        condition = self.expr()\n",
    "\n",
    "        if condition.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "\n",
    "        if self.current_token.type == TokenTypes.SEMICOLON:\n",
    "            self.forward()\n",
    "            expression = self.expr()\n",
    "        \n",
    "            if self.current_token.type != TokenTypes.RBRACKET or expression.hasSyntaxError:\n",
    "                return ParsedNode(None, True)\n",
    "        \n",
    "            self.forward()\n",
    "            if self.current_token.type != TokenTypes.DO:\n",
    "                return ParsedNode(None, True)\n",
    "        \n",
    "            self.forward()\n",
    "            do = self.expr()\n",
    "        \n",
    "            if do.hasSyntaxError:\n",
    "                return ParsedNode(None, True)\n",
    "            \n",
    "            return ParsedNode(ForNode(token, node.node, condition.node, expression.node, do.node), False)\n",
    "        \n",
    "        if self.current_token.type != TokenTypes.RBRACKET:\n",
    "                return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        if self.current_token.type != TokenTypes.DO:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        do = self.expr()\n",
    "        \n",
    "        if do.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "            \n",
    "        return ParsedNode(ForNode(token, node.node, None, condition.node, do.node), False)\n",
    "\n",
    "    \"\"\"\n",
    "    Checks if the statement is a nested scope.\n",
    "    Rule =>  (Identifier COMMA Identifier)* COLON TYPE\n",
    "    \"\"\"\n",
    "    def nested_scope(self) -> ParsedNode:\n",
    "        nodes: list[ParsedNode] = []\n",
    "        nodes.append(self.identifier())\n",
    "\n",
    "        if nodes[0].hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "            \n",
    "        hasComma:bool = False\n",
    "        while True:        \n",
    "            if self.current_token.type == TokenTypes.COMMA:\n",
    "                hasComma = True\n",
    "                self.forward()\n",
    "                nodes.append(self.identifier())\n",
    "            else:\n",
    "                for node in nodes:\n",
    "                    if node.hasSyntaxError:\n",
    "                        return ParsedNode(None, True)\n",
    "                break\n",
    "        \n",
    "        if hasComma == False or self.current_token.type != TokenTypes.COLON:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        type = self.type()\n",
    "\n",
    "        if type.hasSyntaxError == True:\n",
    "            return ParsedNode(None, True)\n",
    "\n",
    "        return ParsedNode(ScopeNode(TokenTypes.COLON, nodes, type), False)\n",
    "        \n",
    "\n",
    "    #####################################\n",
    "    # expressions\n",
    "    #####################################\n",
    "\n",
    "    def expr(self) -> ParsedNode:         \n",
    "        leftNode = self.choice()\n",
    "\n",
    "        if leftNode.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "\n",
    "        if self.current_token.type != TokenTypes.DOT:\n",
    "            return leftNode\n",
    "        \n",
    "        self.forward()\n",
    "        if self.current_token.type != TokenTypes.DOT:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        token = self.current_token\n",
    "        self.forward()\n",
    "        rightNode = self.choice()\n",
    "\n",
    "        if rightNode.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "\n",
    "        return ParsedNode(OperatorNode(token, leftNode.node, rightNode.node), False)\n",
    "    \n",
    "    \n",
    "    def choice(self):\n",
    "        node = self.operation()\n",
    "        token = self.current_token\n",
    "\n",
    "        nodes:list[BaseNode] = []\n",
    "     \n",
    "        if(node.hasSyntaxError==False and self.current_token.type == TokenTypes.CHOICE):\n",
    "                nodes.append(node.node)\n",
    "                while(self.current_token.type == TokenTypes.CHOICE):\n",
    "                    token = self.current_token\n",
    "                    self.forward()\n",
    "                    node = self.operation()\n",
    "                    if(node.hasSyntaxError==False):\n",
    "                        nodes.append(node.node)\n",
    "                    else: return ParsedNode(None,True)\n",
    "                return ParsedNode(SequenceNode(token,nodes), False)\n",
    "        return node\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    This method checks if a token any of the following operations: =, <, >, <=, >=, |, +, -\n",
    "    Since all of this operations have the same priority and same values output, it is not needed to write them in different methods\n",
    "    \"\"\"\n",
    "    def operation(self):\n",
    "        # RULE --> op: term ((GT|LT|GE|LE|EQUAL|CHOICE|PLUS|MINUS) term)*\n",
    "\n",
    "        left_node = self.term()\n",
    "\n",
    "        # Checks if left node has been received and if the following token is one of the following tokens: : =, <, >, <=, >=, |, +, -\n",
    "\n",
    "        if(left_node.hasSyntaxError == False and (self.check_type(self.current_token.type,\n",
    "                [TokenTypes.GREATER,TokenTypes.GREATEREQ,TokenTypes.LOWER,TokenTypes.LOWEREQ, TokenTypes.PLUS,\n",
    "                TokenTypes.MINUS]))):\n",
    "\n",
    "                node = ParsedNode(None,True)\n",
    "                \n",
    "                # The while method \"concatenates\" the operations\n",
    "\n",
    "                while(self.check_type(self.current_token.type,\n",
    "                [TokenTypes.GREATER,TokenTypes.GREATEREQ,TokenTypes.LOWER,TokenTypes.LOWEREQ, TokenTypes.PLUS,\n",
    "                TokenTypes.MINUS])):\n",
    "                \n",
    "                    token = self.current_token\n",
    "                    self.forward()\n",
    "                    right_node = self.term()\n",
    "                    if(right_node.hasSyntaxError):\n",
    "                        return right_node\n",
    "                    \n",
    "                    # Binds found operation to its left node\n",
    "                    if(node.node == None):\n",
    "                       node = ParsedNode(OperatorNode(token,left_node.node,right_node.node),False)\n",
    "                    else: node = ParsedNode(OperatorNode(token,node.node,right_node.node),False)\n",
    "                return node\n",
    "        return left_node\n",
    "\n",
    "    \"\"\"\n",
    "    Checks the same way in operation method but here it checks for *, /\n",
    "    \"\"\"\n",
    "    def term(self) -> ParsedNode:\n",
    "        # RULE --> factor ((MUL|DIV) factor)*\n",
    "        \n",
    "        left_node = self.factor() \n",
    "\n",
    "        if(left_node.hasSyntaxError == False and (self.check_type(self.current_token.type,[TokenTypes.MULTIPLY, TokenTypes.DIVIDE]))):\n",
    "            node = ParsedNode(None,True)\n",
    "\n",
    "             # The while method \"concatenates\" the operations\n",
    "            while(self.check_type(self.current_token.type,[TokenTypes.MULTIPLY, TokenTypes.DIVIDE])):\n",
    "               \n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "                right_node = self.factor()\n",
    "                if(right_node.hasSyntaxError):\n",
    "                    return right_node\n",
    "                \n",
    "                # Binds found operation to its left node\n",
    "                if(node.node == None):\n",
    "                  node = ParsedNode(OperatorNode(token,left_node.node,right_node.node),False)\n",
    "                else: node = ParsedNode(OperatorNode(token,node.node,right_node.node),False)\n",
    "            return node\n",
    "        return left_node\n",
    "    \n",
    "    \"\"\"\n",
    "    Checks for unary operations, Integers, brackets (highest priority)\n",
    "    RULE -->  INTEGER  \n",
    "        : brackets\n",
    "        : (MINUS|PLUS) arith\n",
    "        : func_call x() x\n",
    "        : indexing     NOT IMPLEMENTING\n",
    "        : --> means the same as (brackets|unary|func_call) just like in operation()\n",
    "        only that for each if a different Node may be created not such as only OperationNode like in operation()\n",
    "    \"\"\"\n",
    "    def factor(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "        index = self.lexer.index\n",
    "\n",
    "        #Integer check\n",
    "        if(token.type == TokenTypes.INTEGER):\n",
    "            self.forward()\n",
    "            return ParsedNode(NumberNode(token),False)\n",
    "        \n",
    "        if(token.type == TokenTypes.FAIL):\n",
    "            self.forward()\n",
    "            return ParsedNode(FailNode(token),False)\n",
    "        \n",
    "        #Unary operation check\n",
    "        if(self.check_type(self.current_token.type,[TokenTypes.PLUS, TokenTypes.MINUS])):\n",
    "            self.forward()\n",
    "            node = self.operation()\n",
    "            if(node.hasSyntaxError):        # (--) --> Error needs (-- expr) or (--3)\n",
    "                return ParsedNode(None, True)\n",
    "            return ParsedNode(UnaryNode(token,node.node),False)\n",
    "        \n",
    "        #brackets check\n",
    "        node = self.brackets()\n",
    "\n",
    "        #if node has failed check for loop\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.indexing()\n",
    "\n",
    "        #if node has failed check for loop\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.scope()\n",
    "\n",
    "         #if node has failed check for loop\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.binding()\n",
    "\n",
    "        #if node has failed check indexing\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.func_call()\n",
    "        \n",
    "        #if node has failed check for loop\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.for_loop()\n",
    "\n",
    "        #if node has failed check if statement\n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.if_statement()\n",
    "        \n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.sequence()\n",
    "            \n",
    "        if(node.hasSyntaxError):\n",
    "            self.set_to_token(index,token)\n",
    "            node = self.identifier()\n",
    "        return node\n",
    "    \n",
    "    \"\"\"\n",
    "    Checks for brackets (highest priority)\n",
    "    RULE --> brackets: LB expr RB\n",
    "    \"\"\"\n",
    "    def brackets(self) -> ParsedNode: \n",
    "        if(self.current_token.type == TokenTypes.LBRACKET):\n",
    "            self.forward()\n",
    "            node = self.block()\n",
    "        \n",
    "            if(self.current_token.type == TokenTypes.RBRACKET):\n",
    "                self.forward()\n",
    "                return node\n",
    "        return ParsedNode(None,True)\n",
    "        \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    y := 8 y:=(x:int)  y:= method(...)...\n",
    "    RULE --> scope BINDING expr\n",
    "    \"\"\"\n",
    "    def binding(self) -> ParsedNode:\n",
    "        left_node = self.identifier()\n",
    "\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.check_type(self.current_token.type,[TokenTypes.BINDING])):\n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "                right_node = self.expr()\n",
    "                if(right_node.hasSyntaxError == False):\n",
    "                    return ParsedNode(BindingNode(token,left_node.node,right_node.node), False)\n",
    "                else: return ParsedNode(None,True)\n",
    "        return ParsedNode(None,True)\n",
    "\n",
    "    \"\"\"\n",
    "    x:int\n",
    "    RULE --> identifier COLON type \n",
    "    \"\"\"\n",
    "    def scope(self) -> ParsedNode:\n",
    "        left_node = self.identifier()\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.check_type(self.current_token.type,[TokenTypes.COLON])):\n",
    "                token = self.current_token\n",
    "                self.forward()\n",
    "                type = self.type()\n",
    "                if(type.hasSyntaxError == False):\n",
    "                    return ParsedNode(ScopeNode(token,[left_node.node],type.node),False) # Return Scope Node\n",
    "                else: return ParsedNode(None,True)\n",
    "        return ParsedNode(None,True)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    variable/method name\n",
    "    RULE --> identifier            NEED UPDATE\n",
    "    \"\"\"\n",
    "    def identifier(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "        if(token.type == TokenTypes.IDENTIFIER):\n",
    "            self.forward()\n",
    "            return ParsedNode(IdentifierNode(token), False)\n",
    "        return ParsedNode(None, True) \n",
    "        \n",
    "    \"\"\"\n",
    "    int or tuple(int,int) or array{int}\n",
    "    RULE -->  INT                        \n",
    "            : TUPLE LB type (,type)* RB \n",
    "    \"\"\"\n",
    "    def type(self) -> ParsedNode:\n",
    "        # RULE -->  INT                        \n",
    "        #        : TUPLE LB type (,type)* RB    \n",
    "\n",
    "        token = self.current_token\n",
    "        if(token.type == TokenTypes.INT_TYPE):\n",
    "            self.forward()\n",
    "            return ParsedNode(TypeNode(token),False)\n",
    "        \n",
    "        if(token.type == TokenTypes.TUPLE_TYPE):\n",
    "            self.forward()\n",
    "            if(self.current_token.type == TokenTypes.LBRACKET):\n",
    "                self.forward()\n",
    "                types:list[TypeNode] = []\n",
    "\n",
    "                type = self.type()\n",
    "                if(type.hasSyntaxError == False):\n",
    "                    types.append(type.node)\n",
    "                    if(self.check_type(self.current_token.type, [TokenTypes.COMMA])):\n",
    "                        while(self.current_token.type == TokenTypes.COMMA):\n",
    "\n",
    "                            self.forward()\n",
    "                            t = self.type()\n",
    "\n",
    "                            if(t.hasSyntaxError):  #If on error\n",
    "                                return ParsedNode(None,True)\n",
    "                            types.append(t.node) #else append to list of types\n",
    "                     \n",
    "            if(self.current_token.type == TokenTypes.RBRACKET):  \n",
    "                self.forward()\n",
    "                return ParsedNode(SequenceTypeNode(TokenTypes.TUPLE_TYPE,types), False)\n",
    "            \n",
    "        return ParsedNode(None, True) \n",
    "        \n",
    "    \"\"\"\n",
    "    a[i:int]\n",
    "    # RULE --> identifier SBL expr SBR\n",
    "    \"\"\"\n",
    "    def indexing(self) -> ParsedNode:\n",
    "        left_node = self.identifier()\n",
    "        if(left_node.hasSyntaxError == False):\n",
    "            if(self.current_token.type == TokenTypes.SBL):\n",
    "                self.forward()\n",
    "                expr_node = self.expr()\n",
    "          \n",
    "                if(expr_node.hasSyntaxError == False and self.current_token.type == TokenTypes.SBR):\n",
    "                     self.forward()\n",
    "                     return ParsedNode(IndexingNode(left_node.node.token,left_node.node,expr_node.node),False)\n",
    "                return ParsedNode(None,True)\n",
    "        return ParsedNode(None,True)\n",
    "    \n",
    "    \"\"\"\n",
    "    RUKE --> LB (expr COMMA expr)* RB                  --> tuple (n1,...)\n",
    "             array CBL expr (COMMA expr)*? CBR         --> long-form syntax and singleton tuple/array array{n1} oder array{n1,...}\n",
    "    \"\"\"\n",
    "    def sequence(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "\n",
    "        nodes:list[BaseNode] = []\n",
    "\n",
    "        # Tuple\n",
    "        if(token.type == TokenTypes.LBRACKET):\n",
    "            self.forward()\n",
    "            node = self.expr()\n",
    "            if(node.hasSyntaxError==False):\n",
    "                nodes.append(node.node)\n",
    "                while(self.current_token.type == TokenTypes.COMMA):\n",
    "                    self.forward()\n",
    "                    node = self.expr()\n",
    "                    if(node.hasSyntaxError==False):\n",
    "                        nodes.append(node.node)\n",
    "                    else: return ParsedNode(None,True)\n",
    "                if(len(nodes) > 1 and self.current_token.type == TokenTypes.RBRACKET):\n",
    "                    self.forward()\n",
    "                    return ParsedNode(SequenceNode(Token(TokenTypes.TUPLE_TYPE,TokenTypes.TUPLE_TYPE.value),nodes), False)\n",
    "\n",
    "\n",
    "        # Array\n",
    "        if(token.type == TokenTypes.ARRAY_TYPE):\n",
    "                self.forward()\n",
    "                if(self.current_token.type == TokenTypes.CBL):\n",
    "                    self.forward()\n",
    "                    node = self.expr()\n",
    "                    if(node.hasSyntaxError == False):\n",
    "                        nodes.append(node.node)\n",
    "                        while(self.current_token.type == TokenTypes.COMMA):\n",
    "                              self.forward()\n",
    "                              node = self.expr()\n",
    "                              if(node.hasSyntaxError==False):\n",
    "                                nodes.append(node.node)\n",
    "                              else: return ParsedNode(None,True)\n",
    "                        if(self.current_token.type == TokenTypes.CBR):\n",
    "                            self.forward()\n",
    "                            return ParsedNode(SequenceNode(Token(TokenTypes.TUPLE_TYPE,TokenTypes.TUPLE_TYPE.value),nodes), False)\n",
    "                        \n",
    "        return ParsedNode(None, True)\n",
    "                \n",
    "\n",
    "    \"\"\"\n",
    "    Moves forward in the tokens list\n",
    "    \"\"\"\n",
    "    def forward(self) -> None:\n",
    "        print(self.current_token.__info__())\n",
    "        self.lexer.forward()\n",
    "        self.current_token = lexer.get_token(self.lexer.current_char)\n",
    "        if self.current_token.type == TokenTypes.EOF:\n",
    "            self.end = True\n",
    "        \n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    Checks if a type exists in the following types list\n",
    "    \"\"\"\n",
    "    def check_type(self,type:TokenTypes,types:list[TokenTypes]) -> bool:\n",
    "        return type in types\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Sets current token back if a certain path lead to failure (Wrong syntax)\n",
    "    May need it for later\n",
    "    \"\"\"\n",
    "    def set_to_token(self,index, token): \n",
    "        self.current_token = token\n",
    "        self.lexer.index = index\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        def if_statement(self) -> ParsedNode:\n",
    "        token = self.current_token\n",
    "\n",
    "        if token.type != TokenTypes.IF:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        if self.current_token != TokenTypes.LBRACKET:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        if_node = self.expr()\n",
    "        if if_node.hasSyntaxError == True or self.current_token != TokenTypes.RBRACKET:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        if self.current_token != TokenTypes.THEN:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        then_node = self.then_statement()\n",
    "        if then_node.hasSyntaxError == True or self.current_token != TokenTypes.ELSE:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        self.forward()\n",
    "        else_node = self.else_statement()\n",
    "\n",
    "        if else_node.hasSyntaxError:\n",
    "            return ParsedNode(None, True)\n",
    "        \n",
    "        return ParsedNode(IfNode(token, if_node, then_node, else_node))\n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpreter:\n",
    "    def __init__(self, parser: Parser):\n",
    "        self.parser = parser\n",
    "\n",
    "    def interpret(self):\n",
    "        tree = self.parser.parse()\n",
    "        \n",
    "        return tree.visit(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (1|2) + ((3|4) + 5|36)\n",
    "            \n",
    "            (8|39) , (9|40)\n",
    "\n",
    "            ( (8,9) | (8,40) | (39,9) | (39,40) )\n",
    "\n",
    "  -->(1|2) + ( (8,9) | (8,40) | (39,9) | (39,40) )\n",
    "\n",
    "      ((9,10) | (9,41) | (40,10) | (40,41))  ,  ((10,11) | (10,42) | (41,11) | (41,42))\n",
    "\n",
    "      ((9,10) | (10,11) , (9,10) | (10,42)...)\n",
    "            \n",
    "\n",
    "( (1|8), (2|9), (3|10) )\n",
    "\n",
    "     1|8   2,3 | 2,10\n",
    "\n",
    "     1|(2,3) 1,2,10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "block{\n",
    "\n",
    "x := z;                       x !       0                       x = 3 0\n",
    "z := 3;                          z = 3;  z scope  0             \n",
    "d:int                           d scope 0                       \n",
    " f(b:int):=  (y: = b + x; d = y)        f!     b scope 0; y! d! y   \n",
    "  f(1)                              f! b = 1  0 y = 4; d = 4 0     \n",
    "x + d                           x + d x! d!  3 + 4\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenTypes.LBRACKET: (\n",
      "TokenTypes.LBRACKET: (\n",
      "TokenTypes.INTEGER: 2\n",
      "TokenTypes.CHOICE: |\n",
      "TokenTypes.INTEGER: 3\n",
      "TokenTypes.RBRACKET: )\n",
      "TokenTypes.LBRACKET: (\n",
      "TokenTypes.LBRACKET: (\n",
      "TokenTypes.INTEGER: 2\n",
      "TokenTypes.CHOICE: |\n",
      "TokenTypes.INTEGER: 3\n",
      "TokenTypes.RBRACKET: )\n",
      "TokenTypes.COMMA: ,\n",
      "TokenTypes.INTEGER: 1\n",
      "TokenTypes.COMMA: ,\n",
      "TokenTypes.LBRACKET: (\n",
      "TokenTypes.INTEGER: 4\n",
      "TokenTypes.LBRACKET: (\n",
      "TokenTypes.INTEGER: 4\n",
      "TokenTypes.COMMA: ,\n",
      "TokenTypes.INTEGER: 5\n",
      "TokenTypes.RBRACKET: )\n",
      "TokenTypes.RBRACKET: )\n",
      "[2, 1, 4, 5]|[3, 1, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "text = \"((2|3), 1, (4,5))\" \n",
    "lexer = lexicon(text)      \n",
    "parser = Parser(lexer)      \n",
    "interpreter = Interpreter(parser)\n",
    "result = interpreter.interpret()\n",
    "print(repr(result.node))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 2, 3, 10, 11, 12]\n",
      "[1, 5, 2, 10, 10, 11, 12]\n",
      "[1, 5, 9, 3, 10, 11, 12]\n",
      "[1, 5, 9, 10, 10, 11, 12]\n",
      "[8, 5, 2, 3, 10, 11, 12]\n",
      "[8, 5, 2, 10, 10, 11, 12]\n",
      "[8, 5, 9, 3, 10, 11, 12]\n",
      "[8, 5, 9, 10, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "e0 = NumberNode(Token(TokenTypes.INTEGER,3))\n",
    "e1 = NumberNode(Token(TokenTypes.INTEGER,20))\n",
    "e2 = NumberNode(Token(TokenTypes.INTEGER,10))\n",
    "\n",
    "choice = SequenceNode(Token(TokenTypes.CHOICE,TokenTypes.CHOICE.value),[e1,e2])\n",
    "\n",
    "add = OperatorNode(Token(TokenTypes.PLUS,TokenTypes.PLUS.value),e0,choice)\n",
    "\n",
    "nodes = []\n",
    "for c in add.rightNode.nodes:\n",
    "    node = add.leftNode.token.value + c.value\n",
    "    nodes.append(node)\n",
    "\n",
    "for c in nodes:\n",
    "  print(c)\n",
    "\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "xc = [a,b]\n",
    "def f(xs:list) -> int:\n",
    "  for x in xs:\n",
    "    yield x\n",
    "\n",
    "for c in xc:\n",
    "   for s in f(c):\n",
    "      print(s)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "      # (1|2) , (3|4), (5,6)\n",
    "      # (1,2,(3|4))\n",
    "\n",
    "import itertools\n",
    "\n",
    "choiceToken = Token(TokenTypes.CHOICE,TokenTypes.CHOICE.value)\n",
    "arrayToken = Token(TokenTypes.ARRAY_TYPE,TokenTypes.ARRAY_TYPE.value) \n",
    "\n",
    "n1 = NumberNode(Token(TokenTypes.INTEGER,1))\n",
    "n2 = NumberNode(Token(TokenTypes.INTEGER,2))\n",
    "\n",
    "c1 = SequenceNode(choiceToken, [NumberNode(Token(TokenTypes.INTEGER,1)),NumberNode(Token(TokenTypes.INTEGER,8))])\n",
    "\n",
    "n3 = NumberNode(Token(TokenTypes.INTEGER,5))\n",
    "\n",
    "c2 = SequenceNode(choiceToken, [NumberNode(Token(TokenTypes.INTEGER,2)),NumberNode(Token(TokenTypes.INTEGER,9))])\n",
    "c3 = SequenceNode(choiceToken, [NumberNode(Token(TokenTypes.INTEGER, 3)), NumberNode(Token(TokenTypes.INTEGER, 10))])\n",
    "\n",
    "a1 = SequenceNode(arrayToken, [NumberNode(Token(TokenTypes.INTEGER, 10)), NumberNode(Token(TokenTypes.INTEGER, 11))])\n",
    "n4 = NumberNode(Token(TokenTypes.INTEGER,12))\n",
    "\n",
    "array = SequenceNode(arrayToken, [c1,n3,c2,c3,a1,n4])\n",
    "\n",
    "def f ():\n",
    "    nodes = []\n",
    "    if array.nodes[0].token.type == TokenTypes.CHOICE:\n",
    "      for x in array.nodes:\n",
    "          if x.token.type == TokenTypes.CHOICE:\n",
    "              nodes.append(x.nodes)\n",
    "          else: nodes.append([x])\n",
    "    return nodes\n",
    "\n",
    "# (8|39) , (9|40)\n",
    "# ( (8,9) | (8,40) | (39,9) | (39,40) )  \n",
    "# ((3|4),5,(6|7),(8|9),(10,11),12)\n",
    "\n",
    "\n",
    "\n",
    "nodes = f()\n",
    "\n",
    "def get(xs):\n",
    "  finalnodes = []\n",
    "  combined_nodes = list(itertools.product(*xs))\n",
    "  for cd in combined_nodes:\n",
    "    current_nodes = []\n",
    "    for cd2 in cd:\n",
    "       if cd2.token.type == TokenTypes.ARRAY_TYPE:\n",
    "          for cd22 in cd2.nodes:\n",
    "             current_nodes.append(cd22)\n",
    "       else: current_nodes.append(cd2) \n",
    "    finalnodes.append(current_nodes)\n",
    "  return SequenceNode(choiceToken, finalnodes)\n",
    "\n",
    "\n",
    "seq = get(nodes)\n",
    "for i in seq.nodes:\n",
    "   print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testcases\n",
    "\n",
    "Unary\n",
    "--(2 + 3)\n",
    "-2\n",
    "+5\n",
    "--4\n",
    "--(-32)\n",
    "+-4\n",
    "-+67\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a01c28328f65be720e9d0443b68bfc03fdde5263d5f6e7c10f8af6f0ef832734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
